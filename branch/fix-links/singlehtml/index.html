

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HPDA-Python documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
      <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
      <link rel="stylesheet" type="text/css" href="_static/sphinx_lesson.css" />
      <link rel="stylesheet" type="text/css" href="_static/term_role_formatting.css" />
      <link rel="stylesheet" type="text/css" href="_static/sphinx_rtd_theme_ext_color_contrast.css" />
      <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
      <link rel="stylesheet" type="text/css" href="_static/overrides.css" />

  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js"></script>
      <script src="_static/doctools.js"></script>
      <script src="_static/sphinx_highlight.js"></script>
      <script src="_static/clipboard.min.js"></script>
      <script src="_static/copybutton.js"></script>
      <script src="_static/minipres.js"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="_static/togglebutton.js"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="_static/tabs.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            HPDA-Python
              <img src="_static/ENCCS.jpg" class="logo" alt="Logo"/>
          </a>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Preparation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-setup">Installation and HPC access</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-motivation">Motivation</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-scientific-data">Scientific data</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-stack">Efficient array computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-parallel-computing">Parallel computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-optimization">Profiling and optimizing</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-performance-boosting">Performance boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-dask">Dask for scalable analytics</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Optional material</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-setup-eurohpc">Installation in EuroHPC systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-pandas-extra">Optional: more on Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-GPU-computing">GPU computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-parallel-computing_opt">More on parallel computing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-guide">Instructor’s guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">HPDA-Python</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">HPDA-Python  documentation</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ENCCS/hpda-python/blob/main/content/index" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="high-performance-data-analytics-in-python">
<h1>High Performance Data Analytics in Python<a class="headerlink" href="#high-performance-data-analytics-in-python" title="Link to this heading"></a></h1>
<p>Scientists, engineers and professionals from many sectors are seeing an enormous
growth in the size and number of datasets relevant to their domains.
Professional titles have emerged to describe specialists working with data,
such as data scientists and data engineers, but also other experts are finding
it necessary to learn tools and techniques to work with big data. Typical tasks
include preprocessing, analysing, modeling and visualising data.</p>
<p>Python is an industry-standard programming language for working with data on
all levels of the data analytics pipeline. This is in large part because of the rich
ecosystem of libraries ranging from generic numerical libraries to
special-purpose and/or domain-specific packages, often supported by large developer
communities and stable funding sources.</p>
<p>This lesson is meant to give an overview of working with research data in
Python using general libraries for storing, processing, analysing and sharing data.
The focus is on high performance. After covering tools for performant
processing on single workstations the focus shifts to profiling and optimising, parallel
and distributed computing.</p>
<div class="admonition-prerequisites prerequisites admonition" id="prerequisites-0">
<p class="admonition-title">Prerequisites</p>
<ul class="simple">
<li><p>Basic experience with Python</p></li>
<li><p>Basic experience in working in a Linux-like terminal</p></li>
<li><p>Some prior experience in working with large or small datasets</p></li>
</ul>
</div>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>15 min</p></td>
<td><p><a class="reference internal" href="#document-motivation"><span class="doc">Motivation</span></a></p></td>
</tr>
<tr class="row-even"><td><p>60 min</p></td>
<td><p><a class="reference internal" href="#document-scientific-data"><span class="doc">Scientific data</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>90 min</p></td>
<td><p><a class="reference internal" href="#document-stack"><span class="doc">Efficient array computing</span></a></p></td>
</tr>
<tr class="row-even"><td><p>90 min</p></td>
<td><p><a class="reference internal" href="#document-parallel-computing"><span class="doc">Parallel computing</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>90 min</p></td>
<td><p><a class="reference internal" href="#document-optimization"><span class="doc">Profiling and optimizing</span></a></p></td>
</tr>
<tr class="row-even"><td><p>90 min</p></td>
<td><p><a class="reference internal" href="#document-performance-boosting"><span class="doc">Performance boosting</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>90 min</p></td>
<td><p><a class="reference internal" href="#document-dask"><span class="doc">Dask for scalable analytics</span></a></p></td>
</tr>
</tbody>
</table>
<div class="toctree-wrapper compound">
<span id="document-setup"></span><section id="installation-and-hpc-access">
<h2>Installation and HPC access<a class="headerlink" href="#installation-and-hpc-access" title="Link to this heading"></a></h2>
<p>This page contains instructions for installing the required dependencies on a local computer
as well as instructions for logging into a EuroHPC system.</p>
<section id="local-installation">
<h3>Local installation<a class="headerlink" href="#local-installation" title="Link to this heading"></a></h3>
<p>If you already have a preferred way to manage Python versions and
libraries, you can stick to that. If not, we recommend that you install
Python3 and all libraries using
<a class="reference external" href="https://conda-forge.org/download/">Miniforge</a>, a free
minimal installer for the package, dependency and environment manager
<a class="reference external" href="https://docs.conda.io/en/latest/index.html">conda</a>.</p>
<p>Please follow the installation instructions on
<a class="reference external" href="https://conda-forge.org/download/">https://conda-forge.org/download/</a> to install Miniforge.</p>
<p>Make sure that conda is correctly installed:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>conda<span class="w"> </span>--version
<span class="go">conda 24.11.2</span>
</pre></div>
</div>
<p>With conda installed, install the required dependencies by running:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>conda<span class="w"> </span>env<span class="w"> </span>create<span class="w"> </span>--yes<span class="w"> </span>-f<span class="w"> </span>https://raw.githubusercontent.com/ENCCS/hpda-python/main/content/env/environment.yml
</pre></div>
</div>
<p>This will create a new environment <code class="docutils literal notranslate"><span class="pre">pyhpda</span></code> which you need to activate by:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>conda<span class="w"> </span>activate<span class="w"> </span>pyhpda
</pre></div>
</div>
<p>Ensure that the Python version is fairly recent:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python<span class="w"> </span>--version
<span class="go">Python 3.12.8</span>
</pre></div>
</div>
<p>Finally, open Jupyter-Lab in your browser:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>jupyter-lab
</pre></div>
</div>
</section>
<section id="lumi">
<h3>LUMI<a class="headerlink" href="#lumi" title="Link to this heading"></a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Go to LUMI <a class="reference external" href="https://www.lumi.csc.fi/pun/sys/dashboard/">open OnDemand portal</a></p>
</div>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-motivation"></span><section id="motivation">
<span id="id1"></span><h2>Motivation<a class="headerlink" href="#motivation" title="Link to this heading"></a></h2>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Become familiar with the term “big data”</p></li>
<li><p>Know what to expect from this course</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>10 min teaching/type-along</p></li>
</ul>
</div>
<section id="big-data">
<h3>Big data<a class="headerlink" href="#big-data" title="Link to this heading"></a></h3>
<div class="admonition-how-large-is-your-data discussion important admonition" id="discussion-0">
<p class="admonition-title">How large is your data?</p>
<p>How large is the data you are working with? Are you experiencing performance bottlenecks
when you try to analyse it?</p>
</div>
<p><em>“Big data refers to data sets that are too large or complex to be dealt with by
traditional data-processing application software. […]
Big data analysis challenges include capturing data, data storage, data analysis,
search, sharing, transfer, visualization, querying, updating, information privacy,
and data source.”</em> (from <a class="reference external" href="https://en.wikipedia.org/wiki/Big_data">Wikipedia</a>)</p>
<p>“Big data” is a current buzzword used heavily in the tech industry, but many scientific
research communities are increasingly adopting high-throughput data production methods
which lead to very large datasets. One driving force behind this development is the advent
of powerful machine learning methods which enable researchers to derive novel scientific
insights from large datasets. Another is the strong development of high performance
computing (HPC) hardware and the accompanying development of software libraries and
packages which can efficiently take advantage of the hardware.</p>
<p>This course focuses on high-performace data analytics (HPDA), a subset of high-performance
computing which focuses on working with large data.
The data can come from either computer models and simulations or from experiments and
observations, and the goal is to preprocess, analyse and visualise it to generate
scientific results.</p>
</section>
<section id="python">
<h3>Python<a class="headerlink" href="#python" title="Link to this heading"></a></h3>
<div class="admonition-performance-bottlenecks-in-python discussion important admonition" id="discussion-1">
<p class="admonition-title">Performance bottlenecks in Python</p>
<p>Have you ever written Python scripts that look something like this?</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;mydata.dat&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
    <span class="n">fields</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">fields</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">fields</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">fields</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="c1"># some analysis with x, y and z</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>Compared to C/C++/Fortran, this for-loop will probably be orders of magnitude slower!</p>
</div>
<p>Despite early design choices of the Python language which made it significantly slower
than conventional HPC languages, a rich and growing ecosystem of open source libraries
have established Python as an industry-standard programming language for working with
data on all levels of the data analytics pipeline.
These range from generic numerical libraries to special-purpose and/or domain-specific
packages. This lesson is focused on introducing modern packages from the Python
ecosystem to work with large data. Specifically, we will learn to use:</p>
<ul class="simple">
<li><p>Numpy</p></li>
<li><p>Scipy</p></li>
<li><p>Pandas</p></li>
<li><p>Xarray</p></li>
<li><p>Numba</p></li>
<li><p>Cython</p></li>
<li><p>multithreading</p></li>
<li><p>multiprocessing</p></li>
<li><p>Dask</p></li>
</ul>
</section>
<section id="what-you-will-learn">
<h3>What you will learn<a class="headerlink" href="#what-you-will-learn" title="Link to this heading"></a></h3>
<p>This lesson provides a broad overview of methods to work with large
datasets using tools and libraries from the Python ecosystem. Since this field is fairly
extensive we will not have time to go into much depth. Instead, the objective is to expose
just enough details on each topic for you to get a good idea of the big picture and an
understanding of what combination of tools and libraries will work well for your particular
use case.</p>
<p>Specifically, the lesson covers:</p>
<ul class="simple">
<li><p>Tools for efficiently storing data and writing/reading data to/from disk</p></li>
<li><p>How to share datasets and mint digital object identifiers (DOI)</p></li>
<li><p>Main methods of efficiently working with tabular data and multidimensional arrays</p></li>
<li><p>How to measure performance and boost performance of time consuming Python functions</p></li>
<li><p>Various methods to parallelise Python code</p></li>
</ul>
<p>The lesson does not cover the following:</p>
<ul class="simple">
<li><p>Visualisation techniques</p></li>
<li><p>Machine learning</p></li>
<li><p>GPU related</p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Datasets are getting larger across nearly all scientific and engineering domains</p></li>
<li><p>The Python ecosystem has many libraries and packages for working with big data efficiently</p></li>
</ul>
</div>
</section>
</section>
<span id="document-scientific-data"></span><section id="scientific-data">
<span id="id1"></span><h2>Scientific data<a class="headerlink" href="#scientific-data" title="Link to this heading"></a></h2>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Get an overview of different formats for scientific data</p></li>
<li><p>Understand performance pitfalls when working with big data</p></li>
<li><p>Learn how to work with the NetCDF format through Xarray</p></li>
<li><p>Know the pros and cons of open science</p></li>
<li><p>Learn how to mint a DOI for your project or dataset</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>30 min teaching/type-along</p></li>
<li><p>20 min exercises</p></li>
</ul>
</div>
<section id="types-of-scientific-data">
<h3>Types of scientific data<a class="headerlink" href="#types-of-scientific-data" title="Link to this heading"></a></h3>
<section id="bit-and-byte">
<h4>Bit and Byte<a class="headerlink" href="#bit-and-byte" title="Link to this heading"></a></h4>
<p>The smallest building block of storage in the computer is a <strong>bit</strong>,
which stores either a 0 or 1.
Normally a number of 8 bits are combined in a group to make a <strong>byte</strong>.
One byte (8 bits) can represent/hold at most <span class="math notranslate nohighlight">\(2^8\)</span> distinct values.
Organising bytes in different ways can represent
different types of information, i.e. data.</p>
</section>
<section id="numerical-data">
<h4>Numerical Data<a class="headerlink" href="#numerical-data" title="Link to this heading"></a></h4>
<p>Different numerical data types (e.g. integer and floating-point numbers)
can be represented by bytes.
The more bytes we use for each value, the larger is the range or precision we get,
but more bytes require more memory.</p>
<p>For example, integers stored with 1 byte (8 bits) have a range from
[-128, 127], while with 2 bytes (16 bits) the range becomes [-32768, 32767].
Integers are whole numbers and can be represented exactly given enough bytes.
However, for floating-point numbers the decimal fractions
can not be represented exactly as binary (base 2) fractions in most cases
which is known as the <em>representation error</em>. Arithmetic operations will
further propagate this error. That is why in scientific computing,
numerical algorithms have to be carefully designed to not accumulate errors, and
floating-point numbers are usually allocated with 8 bytes
to make sure the inaccuracy is under control and does not lead to unsteady solutions.</p>
<div class="admonition-single-vs-double-precision discussion important admonition" id="discussion-0">
<p class="admonition-title">Single vs double precision</p>
<p>In many computational modeling domains, it is common practice to use single precision in
some parts of the modeling to achieve better performance at an affordable cost to the
accuracy. For example in climate simulations, molecular dynamics and machine learning.</p>
<p>Have you used single precision in your modeling? Did you observe higher performance?</p>
</div>
</section>
<section id="text-data">
<h4>Text Data<a class="headerlink" href="#text-data" title="Link to this heading"></a></h4>
<p>When it comes to text data, the simplest character encoding
is ASCII (American Standard Code for Information Interchange) and was the most
common character encodings until 2008 when UTF-8 took over.
The original ASCII uses only 7 bits for representing each character and
therefore encodes only 128 specified characters. Later it became common
to use an 8-bit byte to store each character in memory, providing an extended ASCII.</p>
<p>As computers became more powerful and the need for including more characters
from other languages like Chinese, Greek and Arabic became more pressing, UTF-8 became
the most common encoding. UTF-8 uses a minimum of one byte and up to four bytes per character.</p>
</section>
<section id="data-and-storage-format">
<h4>Data and storage format<a class="headerlink" href="#data-and-storage-format" title="Link to this heading"></a></h4>
<p>In real scientific applications, data is complex and structured and usually contains both numerical and text data.
Here we list a few of the data and file storage formats commonly used.</p>
<section id="tabular-data">
<h5>Tabular Data<a class="headerlink" href="#tabular-data" title="Link to this heading"></a></h5>
<p>A very common type of data is “tabular data”. Tabular data is structured
into rows and columns. Each column usually has a name and a specific data type
while each row is a distinct sample which provides data according to each column (including missing values).
The simplest and most common way to save tabular data is via the so-called CSV (comma-separated values) file.</p>
</section>
<section id="gridded-data">
<h5>Gridded Data<a class="headerlink" href="#gridded-data" title="Link to this heading"></a></h5>
<p>Gridded data is another very common data type in which numerical data is normally saved
in a multi-dimensional rectangular grid. Most probably it is saved in one of the following formats:</p>
<ul class="simple">
<li><p>Hierarchical Data Format (HDF5) - Container for many arrays</p></li>
<li><p>Network Common Data Form (NetCDF) - Container for many arrays which conform to the NetCDF data model</p></li>
<li><p>Zarr - New cloud-optimized format for array storage</p></li>
</ul>
</section>
<section id="metadata">
<h5>Metadata<a class="headerlink" href="#metadata" title="Link to this heading"></a></h5>
<p>Metadata consists of various information about the data.
Different types of data may have different metadata conventions.</p>
<p>In Earth and Environmental science, there are widespread robust practices around metadata.
For NetCDF files, metadata can be embedded directly into the data files.
The most common metadata convention is Climate and Forecast (CF) Conventions,
commonly used with NetCDF data.</p>
<p>When it comes to data storage, there are many types of storage formats used
in scientific computing and data analysis. There isn’t one data storage format that
works in all cases, so choose a file format that best suits your data.</p>
</section>
<section id="csv-comma-separated-values">
<h5>CSV (comma-separated values)<a class="headerlink" href="#csv-comma-separated-values" title="Link to this heading"></a></h5>
<div class="admonition-key-features admonition">
<p class="admonition-title">Key features</p>
<ul class="simple">
<li><p><strong>Type:</strong> Text format</p></li>
<li><p><strong>Packages needed:</strong> NumPy, Pandas</p></li>
<li><p><strong>Space efficiency:</strong> Bad</p></li>
<li><p><strong>Good for sharing/archival:</strong> Yes</p></li>
<li><dl class="simple">
<dt>Tidy data:</dt><dd><ul>
<li><p>Speed: Bad</p></li>
<li><p>Ease of use: Great</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Array data:</dt><dd><ul>
<li><p>Speed: Bad</p></li>
<li><p>Ease of use: Ok for one or two dimensional data. Bad for anything higher.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><strong>Best use cases:</strong> Sharing data. Small data. Data that needs to be human-readable.</p></li>
</ul>
</div>
<p>CSV is by far the most popular file format, as it is human-readable and easily shareable.
However, it is not the best format to use when you’re working with big data.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>When working with floating point numbers, you should be careful to save the data
with enough decimal places so that you won’t lose precision.</p>
<ol class="arabic simple">
<li><p>You may lose data precision simply because you do not save the data with enough decimals</p></li>
<li><p>CSV writing routines in Pandas and NumPy try to avoid such problems
by writing floating point numbers with enough precision, but they are not perfect.</p></li>
<li><p>Storage of high-precision CSV files is usually very inefficient storage-wise.</p></li>
<li><p>Binary files, where floating point numbers are represented in their native binary format,
do not suffer from these problems.</p></li>
</ol>
</div>
</section>
<section id="hdf5-hierarchical-data-format-version-5">
<h5>HDF5 (Hierarchical Data Format version 5)<a class="headerlink" href="#hdf5-hierarchical-data-format-version-5" title="Link to this heading"></a></h5>
<div class="admonition-key-features admonition">
<p class="admonition-title">Key features</p>
<ul class="simple">
<li><p><strong>Type:</strong> Binary format</p></li>
<li><p><strong>Packages needed:</strong> Pandas, PyTables, h5py</p></li>
<li><p><strong>Space efficiency:</strong> Good for numeric data.</p></li>
<li><p><strong>Good for sharing/archival:</strong> Yes, if datasets are named well.</p></li>
<li><dl class="simple">
<dt>Tidy data:</dt><dd><ul>
<li><p>Speed: Ok</p></li>
<li><p>Ease of use: Good</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Array data:</dt><dd><ul>
<li><p>Speed: Great</p></li>
<li><p>Ease of use: Good</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><strong>Best use cases:</strong> Working with big datasets in array data format.</p></li>
</ul>
</div>
<p>HDF5 is a high performance storage format for storing large amounts of data in multiple datasets in a single file.
It is especially popular in fields where you need to store big multidimensional arrays such as physical sciences.</p>
</section>
<section id="netcdf4-network-common-data-form-version-4">
<h5>NetCDF4 (Network Common Data Form version 4)<a class="headerlink" href="#netcdf4-network-common-data-form-version-4" title="Link to this heading"></a></h5>
<div class="admonition-key-features admonition">
<p class="admonition-title">Key features</p>
<ul class="simple">
<li><p><strong>Type</strong>: Binary format</p></li>
<li><p><strong>Packages needed:</strong> Pandas, netCDF4/h5netcdf, xarray</p></li>
<li><p><strong>Space efficiency:</strong> Good for numeric data.</p></li>
<li><p><strong>Good for sharing/archival:</strong> Yes.</p></li>
<li><dl class="simple">
<dt>Tidy data:</dt><dd><ul>
<li><p>Speed: Ok</p></li>
<li><p>Ease of use: Good</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Array data:</dt><dd><ul>
<li><p>Speed: Good</p></li>
<li><p>Ease of use: Great</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><strong>Best use cases:</strong> Working with big datasets in array data format. Especially useful if the dataset
contains spatial or temporal dimensions. Archiving or sharing those datasets.</p></li>
</ul>
</div>
<p>NetCDF4 is a data format that uses HDF5 as its file format, but it has standardized structure of
datasets and metadata related to these datasets. This makes it possible to be read from various different programs.</p>
<p>NetCDF4 is by far the most common format for storing large data from big simulations in physical sciences.</p>
<p>The advantage of NetCDF4 compared to HDF5 is that one can easily add additional metadata, e.g. spatial
dimensions (<code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">z</span></code>) or timestamps (<code class="docutils literal notranslate"><span class="pre">t</span></code>) that tell where the grid-points are situated.
As the format is standardized, many programs can use this metadata for visualization and further analysis.</p>
</section>
<section id="there-s-more">
<h5>There’s more<a class="headerlink" href="#there-s-more" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p><a class="reference external" href="https://arrow.apache.org/docs/python/feather.html">Feather</a>: a portable file format
for storing Arrow tables or data frames (from languages like Python or R)</p></li>
<li><p><a class="reference external" href="https://arrow.apache.org/docs/python/parquet.html">Parquet</a>: a standardized open-source
columnar storage format for use in data analysis systems</p></li>
<li><p><a class="reference external" href="https://numpy.org/doc/stable/reference/routines.io.html">npy</a>: numpy array format for
saving and loading numpy arrays.</p></li>
</ul>
</section>
<section id="xarray">
<h5>Xarray<a class="headerlink" href="#xarray" title="Link to this heading"></a></h5>
<p><a class="reference external" href="https://docs.xarray.dev/en/stable/">Xarray</a> is a Python package that builds on NumPy but adds <em>labels</em> to
multi-dimensional arrays. It also borrows heavily from the Pandas package for labelled tabular data and
integrates tightly with dask for parallel computing. NumPy, Pandas and Dask will be covered in later episodes.</p>
<p>Xarray is particularly tailored to working with NetCDF files. It reads and writes to NetCDF files using the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">open_dataset()</span></code> / <code class="xref py py-meth docutils literal notranslate"><span class="pre">open_dataarray()</span></code> functions and the <code class="xref py py-meth docutils literal notranslate"><span class="pre">to_netcdf()</span></code> method. Explore these in the
exercise below!</p>
</section>
</section>
</section>
<section id="sharing-data">
<h3>Sharing data<a class="headerlink" href="#sharing-data" title="Link to this heading"></a></h3>
<p>The Open Science movement encourages researchers to share research output beyond the contents of a
published academic article (and possibly supplementary information).</p>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/Open_Science_Principles.png"><img alt="_images/Open_Science_Principles.png" src="_images/Open_Science_Principles.png" style="width: 632.0px; height: 288.0px;" />
</a>
</figure>
<section id="pros-and-cons-of-sharing-data-from-wikipedia">
<h4>Pros and cons of sharing data (<a class="reference external" href="https://en.wikipedia.org/wiki/Open_science">from Wikipedia</a>)<a class="headerlink" href="#pros-and-cons-of-sharing-data-from-wikipedia" title="Link to this heading"></a></h4>
<p>In favor:</p>
<ul class="simple">
<li><p>Open access publication of research reports and data allows for rigorous peer-review</p></li>
<li><p>Science is publicly funded so all results of the research should be publicly available</p></li>
<li><p>Open Science will make science more reproducible and transparent</p></li>
<li><p>Open Science has more impact</p></li>
<li><p>Open Science will help answer uniquely complex questions</p></li>
</ul>
<p>Against:</p>
<ul class="simple">
<li><p>Too much unsorted information overwhelms scientists</p></li>
<li><p>Potential misuse</p></li>
<li><p>The public will misunderstand science data</p></li>
<li><p>Increasing the scale of science will make verification of any discovery more difficult</p></li>
<li><p>Low-quality science</p></li>
</ul>
</section>
<section id="fair-principles">
<h4>FAIR principles<a class="headerlink" href="#fair-principles" title="Link to this heading"></a></h4>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/8-fair-principles.jpg"><img alt="_images/8-fair-principles.jpg" src="_images/8-fair-principles.jpg" style="width: 526.1999999999999px; height: 391.34999999999997px;" />
</a>
</figure>
<p>(This image was created by <a class="reference external" href="https://www.scriberia.com">Scriberia</a> for <a class="reference external" href="https://book.the-turing-way.org/">The
Turing Way</a> community and is used under a
CC-BY licence. The image was obtained from
<a class="reference external" href="https://zenodo.org/record/3332808">https://zenodo.org/record/3332808</a>)</p>
<p>“FAIR” is the current buzzword for data management. You may be asked
about it in, for example, making data management plans for grants:</p>
<ul class="simple">
<li><p>Findable</p>
<ul>
<li><p>Will anyone else know that your data exists?</p></li>
<li><p>Solutions: put it in a standard repository, or at least a
description of the data. Get a digital object identifier (DOI).</p></li>
</ul>
</li>
<li><p>Accessible</p>
<ul>
<li><p>Once someone knows that the data exists, can they get it?</p></li>
<li><p>Usually solved by being in a repository, but for non-open data,
may require more procedures.</p></li>
</ul>
</li>
<li><p>Interoperable</p>
<ul>
<li><p>Is your data in a format that can be used by others, like csv
instead of PDF?</p></li>
<li><p>Or better than csv. Example: <a class="reference external" href="https://5stardata.info/en/">5-star open data</a></p></li>
</ul>
</li>
<li><p>Reusable</p>
<ul>
<li><p>Is there a license allowing others to re-use?</p></li>
</ul>
</li>
</ul>
<p>Even though this is usually referred to as “open data”, it means
considering and making good decisions, even if non-open.</p>
<p>FAIR principles are usually discussed in the context of data,
but they apply also for research software.</p>
<p>Note that FAIR principles do not require data/software to be open.</p>
<div class="admonition-think-about-open-science-in-your-own-situation discussion important admonition" id="discussion-1">
<p class="admonition-title">Think about open science in your own situation</p>
<ul class="simple">
<li><p>Do you share any other research outputs besides published articles and possibly source code?</p></li>
<li><p>Is there any particular reason which stops you from sharing research data?</p></li>
</ul>
</div>
</section>
<section id="services-for-sharing-and-collaborating-on-research-data">
<h4>Services for sharing and collaborating on research data<a class="headerlink" href="#services-for-sharing-and-collaborating-on-research-data" title="Link to this heading"></a></h4>
<p>To find a research data repository for your data, you can search on the
<a class="reference external" href="https://www.re3data.org/">Registry of Research Data Repositories re3data</a>
platform and filter by country, content type, discipline, etc.</p>
<p><strong>International:</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://zenodo.org/">Zenodo</a>: A general-purpose open access repository
created by OpenAIRE and CERN. Integration with GitHub, allows
researchers to upload files up to 50 GB.</p></li>
<li><p><a class="reference external" href="https://figshare.com/">Figshare</a>: Online digital repository where researchers
can preserve and share their research outputs (figures, datasets, images and videos).
Users can make all of their research outputs available in a citable,
shareable and discoverable manner.</p></li>
<li><p><a class="reference external" href="https://eudat.eu">EUDAT</a>: European platform for researchers and practitioners from any research discipline to preserve, find, access, and process data in a trusted environment.</p></li>
<li><p><a class="reference external" href="https://datadryad.org/">Dryad</a>: A general-purpose home for a wide diversity of datatypes,
governed by a nonprofit membership organization.
A curated resource that makes the data underlying scientific publications discoverable,
freely reusable, and citable.</p></li>
<li><p><a class="reference external" href="https://osf.io/">The Open Science Framework</a>: Gives free accounts for collaboration
around files and other research artifacts. Each account can have up to 5 GB of files
without any problem, and it remains private until you make it public.</p></li>
</ul>
<p><strong>Sweden:</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.icos-sweden.se/">ICOS for climate data</a></p></li>
<li><p><a class="reference external" href="https://bolin.su.se/data/">Bolin center climate / geodata</a></p></li>
<li><p><a class="reference external" href="https://nbis.se/">NBIS for life science, sequence –omics data</a></p></li>
<li><p><a class="reference external" href="https://dataguru.lu.se/">DataGURU for environmental and climate data</a></p></li>
</ul>
</section>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-use-xarray-to-work-with-netcdf-files exercise important admonition" id="exercise-0">
<p class="admonition-title">Use Xarray to work with NetCDF files</p>
<p>This exercise is derived from <a class="reference external" href="https://tutorial.xarray.dev/intro.html">Xarray Tutorials</a>,
which is distributed under an Apache-2.0 License.</p>
<p>First create an Xarray dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">xarray</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">xr</span>

<span class="n">ds1</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span>
    <span class="n">data_vars</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="p">((</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
        <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="p">((</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span>
    <span class="p">},</span>
    <span class="n">coords</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
        <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="s2">&quot;z&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="p">},</span>
<span class="p">)</span>
<span class="n">ds2</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span>
    <span class="n">data_vars</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="p">((</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
        <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="p">((</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)),</span>
    <span class="p">},</span>
    <span class="n">coords</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span>
        <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
        <span class="s2">&quot;z&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then write the datasets to disk using <code class="xref py py-meth docutils literal notranslate"><span class="pre">to_netcdf()</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds1</span><span class="o">.</span><span class="n">to_netcdf</span><span class="p">(</span><span class="s2">&quot;ds1.nc&quot;</span><span class="p">)</span>
<span class="n">ds2</span><span class="o">.</span><span class="n">to_netcdf</span><span class="p">(</span><span class="s2">&quot;ds2.nc&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can read an individual file from disk by using <code class="xref py py-meth docutils literal notranslate"><span class="pre">open_dataset()</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds3</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_dataset</span><span class="p">(</span><span class="s2">&quot;ds1.nc&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>or using the <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_dataset()</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds4</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;ds1.nc&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Tasks:</p>
<ul class="simple">
<li><p>Explore the hierarchical structure of the <code class="docutils literal notranslate"><span class="pre">ds1</span></code> and <code class="docutils literal notranslate"><span class="pre">ds2</span></code> datasets in a Jupyter notebook by typing the
variable names in a code cell and execute. Click the disk-looking objects on the right to expand the fields.</p></li>
<li><p>Explore <code class="docutils literal notranslate"><span class="pre">ds3</span></code> and <code class="docutils literal notranslate"><span class="pre">ds4</span></code> datasets, and compare them with <code class="docutils literal notranslate"><span class="pre">ds1</span></code>. What are the differences?</p></li>
</ul>
</div>
<div class="admonition-get-a-doi-by-connecting-your-repository-to-zenodo exercise important admonition" id="exercise-1">
<p class="admonition-title">Get a DOI by connecting your repository to Zenodo</p>
<p>Digital object identifiers (DOI) are the backbone of the academic
reference and metrics system. In this exercise you will see how to
make a GitHub repository citable by archiving it on the
<a class="reference external" href="https://about.zenodo.org/">Zenodo</a> archiving service. Zenodo is a
general-purpose open access repository created by OpenAIRE and CERN.</p>
<p>For this exercise you need to have a GitHub account and at least one public
repository that you can use for testing. If you need a new repository, you
can fork for example <a class="reference external" href="https://github.com/enccs/word-count-hpda">this one</a> (click the “fork” button
in the top right corner and fork it to your username).</p>
<ol class="arabic simple">
<li><p>Sign in to Zenodo using your GitHub account. For this exercise, use the
sandbox service: <a class="reference external" href="https://sandbox.zenodo.org/login/">https://sandbox.zenodo.org/login/</a>. This is a test version of the real Zenodo platform.</p></li>
<li><p>Go to <a class="reference external" href="https://sandbox.zenodo.org/account/settings/github/">https://sandbox.zenodo.org/account/settings/github/</a> and log in with your GitHub account.</p></li>
<li><p>Find the repository you wish to publish, and flip the switch to ON.</p></li>
<li><p>Go to GitHub and create a <strong>release</strong>  by clicking the <cite>Create a new release</cite> on the
right-hand side (a release is based on a Git tag, but is a higher-level GitHub feature).</p></li>
<li><p>Creating a new release will trigger Zenodo into archiving your repository,
and a DOI badge will be displayed next to your repository after a minute
or two.</p></li>
<li><p>You can include the DOI badge in your repository’s README file by clicking the
DOI badge and copy the relevant format (Markdown, RST, HTML).</p></li>
</ol>
</div>
</section>
<section id="see-also">
<h3>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://fair-software.eu/">Five recommendations for fair software</a></p></li>
<li><p><a class="reference external" href="https://github.com/the-turing-way/the-turing-way/">The Turing way</a></p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>File formats matter. For large datasets, use HDF5, NetCDF or similar.</p></li>
<li><p>The Xarray package provides high-level methods to work with data in NetCDF format.</p></li>
<li><p>Consider sharing other research outputs than articles. It is easy to mint DOIs and get cited!</p></li>
</ul>
</div>
</section>
</section>
<span id="document-stack"></span><section id="efficient-array-computing">
<span id="stack"></span><h2>Efficient array computing<a class="headerlink" href="#efficient-array-computing" title="Link to this heading"></a></h2>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand limitations of Python’s standard library for large data processing</p></li>
<li><p>Understand the logic behind NumPy ndarrays and learn to use some NumPy numerical computing tools</p></li>
<li><p>Learn to use data structures and analysis tools from Pandas</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>30 min teaching/type-along</p></li>
<li><p>20 min exercises</p></li>
</ul>
</div>
<p>This episode is partly based on material from this
<a class="reference external" href="https://github.com/csc-training/hpc-python">repository on HPC-Python from CSC</a> and
this <a class="reference external" href="https://aaltoscicomp.github.io/python-for-scicomp/">Python for Scientific Computing lesson</a>,
distributed under MIT and CC-BY-4.0 licenses, respectively.</p>
<section id="why-can-python-be-slow">
<h3>Why can Python be slow?<a class="headerlink" href="#why-can-python-be-slow" title="Link to this heading"></a></h3>
<p>Computer programs are nowadays practically always written in a high-level
human readable programming language and then translated to the actual machine
instructions that a processor understands. There are two main approaches for
this translation:</p>
<blockquote>
<div><ul class="simple">
<li><p>For <strong>compiled</strong> programming languages, the translation is done by
a compiler before the execution of the program</p></li>
<li><p>For <strong>interpreted</strong> languages, the translation is done by an interpreter
during the execution of the program</p></li>
</ul>
</div></blockquote>
<p>Compiled languages are typically more efficient, but the behaviour of
the program during runtime is more static than with interpreted languages.
The compilation step can also be time consuming, so the software cannot
always be tested as rapidly during development as with interpreted
languages.</p>
<p>Python is an interpreted language, and many features that make development
rapid with Python are a result of that, with the price of reduced performance
in many cases.</p>
<section id="dynamic-typing">
<h4>Dynamic typing<a class="headerlink" href="#dynamic-typing" title="Link to this heading"></a></h4>
<p>Python is a <em>dynamic</em> language. Variables get a type only during the
runtime when values (Python objects) are assigned to them, so it is more difficult
for the interpreter to optimize the execution. In comparison, a compiler can
make extensive analysis and optimization before the execution. Even though there has
in recent years been a lot of progress in just-in-time (JIT)
compilation techniques that allow programs to be optimized at runtime, the
inherent, dynamic nature of the Python programming language remains one
of its main performance bottlenecks.</p>
</section>
<section id="flexible-data-structures">
<h4>Flexible data structures<a class="headerlink" href="#flexible-data-structures" title="Link to this heading"></a></h4>
<p>The built-in data structures of Python, such as lists and dictionaries,
are very flexible, but they are also very generic which makes them not
well suited for extensive numerical computations. Even though the implementation
of data structures is often quite efficient when processing
different types of data, there is a lot of overhead due to the
generic nature of these data structures when processing only a single type of data.</p>
<p>In summary, the flexibility and dynamic nature of Python, which enhances
programmer productivity greatly, is also the main cause for the
performance problems. Fortunately, as we
discuss in the course, many of the bottlenecks can be circumvented.</p>
</section>
</section>
<section id="numpy">
<h3>NumPy<a class="headerlink" href="#numpy" title="Link to this heading"></a></h3>
<p>As probably the most fundamental building block of the scientific computing ecosystem in Python,
NumPy offers comprehensive mathematical functions, random number generators,
linear algebra routines, Fourier transforms, and more.</p>
<p>NumPy is based on well-optimized C code, which gives much better performace than regular Python.
In particular, by using homogeneous
data structures, NumPy <em>vectorizes</em> mathematical operations where fast pre-compiled code
can be applied to a sequence of data instead of using traditional <code class="docutils literal notranslate"><span class="pre">for</span></code> loops.</p>
<section id="arrays">
<h4>Arrays<a class="headerlink" href="#arrays" title="Link to this heading"></a></h4>
<p>The core of NumPy is the NumPy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> (n-dimensional array). Compared to a Python list,
an ndarray is similar in terms of serving as a data container.
Some differences between the two are:</p>
<ul class="simple">
<li><p>ndarrays can have multiple dimensions, e.g. a 1-D array is a vector, a 2-D array is a matrix</p></li>
<li><p>ndarrays are fast only when all data elements are of the same type</p></li>
<li><p>ndarray operations are fast when vectorized</p></li>
<li><p>ndarrays are slower for certain operations, e.g. appending elements</p></li>
</ul>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/list-vs-array.svg"><img alt="_images/list-vs-array.svg" src="_images/list-vs-array.svg" style="width: 1339.0px; height: 618.0px;" />
</a>
</figure>
</section>
<section id="data-types">
<h4>Data types<a class="headerlink" href="#data-types" title="Link to this heading"></a></h4>
<p>NumPy supports a much greater variety of numerical types (<code class="docutils literal notranslate"><span class="pre">dtype</span></code>) than Python does.
There are 5 basic numerical types representing booleans (<code class="docutils literal notranslate"><span class="pre">bool</span></code>), integers (<code class="docutils literal notranslate"><span class="pre">int</span></code>),
unsigned integers (<code class="docutils literal notranslate"><span class="pre">uint</span></code>) floating point (<code class="docutils literal notranslate"><span class="pre">float</span></code>) and complex (<code class="docutils literal notranslate"><span class="pre">complex</span></code>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># create float32 variable</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="c1"># array with uint8 unsigned integers</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="c1"># convert array to floats</span>
<span class="n">z</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="creating-numpy-arrays">
<h4>Creating NumPy arrays<a class="headerlink" href="#creating-numpy-arrays" title="Link to this heading"></a></h4>
<p>One way to create a NumPy array is to convert from a Python list, but make sure that the list is homogeneous
(contains same data type) otherwise performace will be downgraded.
Since appending elements to an existing array is slow, it is a common practice to preallocate the necessary space
with <code class="docutils literal notranslate"><span class="pre">np.zeros</span></code> or <code class="docutils literal notranslate"><span class="pre">np.empty</span></code> when converting from a Python list is not possible.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="nb">float</span><span class="p">)</span>
<span class="n">a</span>
<span class="c1"># array([ 1., 2., 3., 4.])</span>

<span class="n">list1</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span>
<span class="n">mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">list1</span><span class="p">,</span> <span class="nb">complex</span><span class="p">)</span>
<span class="c1"># create complex array, with imaginary part equal to zero</span>
<span class="n">mat</span>
<span class="c1"># array([[ 1.+0.j, 2.+0.j, 3.+0.j],</span>
<span class="c1">#       [ 4.+0.j, 5.+0.j, 6.+0.j]])</span>

<span class="n">mat</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># (2, 3)</span>

<span class="n">mat</span><span class="o">.</span><span class="n">size</span>
<span class="c1"># 6</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">arange</span></code> and <code class="docutils literal notranslate"><span class="pre">linspace</span></code> can generate ranges of numbers:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">a</span>
<span class="c1"># array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
<span class="n">b</span>
<span class="c1"># array([0.1 , 0.12, 0.14, 0.16, 0.18])</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">c</span>
<span class="c1"># array([-4.5 , -2.25, 0. , 2.25, 4.5 ])</span>
</pre></div>
</div>
<p>Array with given shape initialized to <code class="docutils literal notranslate"><span class="pre">zeros</span></code>, <code class="docutils literal notranslate"><span class="pre">ones</span></code>, arbitrary value (<code class="docutils literal notranslate"><span class="pre">full</span></code>)
or unitialized (<code class="docutils literal notranslate"><span class="pre">empty</span></code>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="nb">float</span><span class="p">)</span>
<span class="n">a</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># (4, 6)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">b</span>
<span class="c1"># array([[ 1., 1., 1., 1.],</span>
<span class="c1">#       [ 1., 1., 1., 1.]])</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mf">4.2</span><span class="p">)</span>
<span class="n">c</span>
<span class="c1"># array([[4.2, 4.2, 4.2],</span>
<span class="c1">#       [4.2, 4.2, 4.2]])</span>

<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="c1"># array([[0.00000000e+000, 1.03103236e-259],</span>
<span class="c1">#       [0.00000000e+000, 9.88131292e-324]])</span>
</pre></div>
</div>
<p>Similar arrays as an existing array:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="nb">float</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mf">9.1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="array-operations-and-manipulations">
<h4>Array Operations and Manipulations<a class="headerlink" href="#array-operations-and-manipulations" title="Link to this heading"></a></h4>
<p>All the familiar arithmetic operators in NumPy are applied elementwise:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">1D</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">2D</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>

<span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/np_add_1d_new.svg" src="_images/np_add_1d_new.svg" />
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span><span class="o">/</span><span class="n">b</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/np_div_1d_new.svg" src="_images/np_div_1d_new.svg" />
</figure>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>

<span class="n">a</span> <span class="o">+</span> <span class="n">b</span>                       <span class="c1"># array([[11, 12, 13],</span>
                            <span class="c1">#        [14, 15, 16]])</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/np_add_2d.svg" src="_images/np_add_2d.svg" />
</figure>
</div></div>
</section>
<section id="array-indexing">
<h4>Array Indexing<a class="headerlink" href="#array-indexing" title="Link to this heading"></a></h4>
<p>Basic indexing is similar to Python lists.
Note that advanced indexing creates copies of arrays.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">1D</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">2D</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/np_ind_0.svg" src="_images/np_ind_0.svg" />
</figure>
<p><strong>Integer indexing:</strong></p>
<figure class="align-default">
<img alt="_images/np_ind_integer.svg" src="_images/np_ind_integer.svg" />
</figure>
<p><strong>Fancy indexing:</strong></p>
<figure class="align-default">
<img alt="_images/np_ind_fancy.svg" src="_images/np_ind_fancy.svg" />
</figure>
<p><strong>Boolean indexing:</strong></p>
<figure class="align-default">
<img alt="_images/np_ind_boolean.svg" src="_images/np_ind_boolean.svg" />
</figure>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/np_ind2d_data.svg" src="_images/np_ind2d_data.svg" />
</figure>
<p><strong>Integer indexing:</strong></p>
<figure class="align-default">
<img alt="_images/np_ind2d_integer.svg" src="_images/np_ind2d_integer.svg" />
</figure>
<p><strong>Fancy indexing:</strong></p>
<figure class="align-default">
<img alt="_images/np_ind2d_fancy.svg" src="_images/np_ind2d_fancy.svg" />
</figure>
<p><strong>Boolean indexing:</strong></p>
<figure class="align-default">
<img alt="_images/np_ind2d_boolean.svg" src="_images/np_ind2d_boolean.svg" />
</figure>
</div></div>
</section>
<section id="array-aggregation">
<h4>Array Aggregation<a class="headerlink" href="#array-aggregation" title="Link to this heading"></a></h4>
<p>Apart from aggregating values, one can also aggregate across rows or columns by using the <code class="docutils literal notranslate"><span class="pre">axis</span></code> parameter:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/np_max_2d.svg" src="_images/np_max_2d.svg" />
</figure>
<figure class="align-default">
<img alt="_images/np_sum_2d.svg" src="_images/np_sum_2d.svg" />
</figure>
<figure class="align-default">
<img alt="_images/np_min_2d_ax0.svg" src="_images/np_min_2d_ax0.svg" />
</figure>
<figure class="align-default">
<img alt="_images/np_min_2d_ax1.svg" src="_images/np_min_2d_ax1.svg" />
</figure>
</section>
<section id="array-reshaping">
<h4>Array Reshaping<a class="headerlink" href="#array-reshaping" title="Link to this heading"></a></h4>
<p>Sometimes, you need to change the dimension of an array.
One of the most common need is to transposing the matrix
during the dot product. Switching the dimensions of
a NumPy array is also quite common in more advanced cases.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">])</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/np_reshape0.svg" src="_images/np_reshape0.svg" />
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/np_reshape43.svg" src="_images/np_reshape43.svg" />
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/np_reshape34.svg" src="_images/np_reshape34.svg" />
</figure>
</section>
<section id="views-and-copies-of-arrays">
<h4>Views and copies of arrays<a class="headerlink" href="#views-and-copies-of-arrays" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Simple assignment creates <strong>references</strong> to arrays</p></li>
<li><p>Slicing creates <strong>views</strong> to the arrays</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">copy</span></code> for real copying of arrays</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span>              <span class="c1"># reference, changing values in b changes a</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>       <span class="c1"># true copy</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>         <span class="c1"># view, changing c changes elements [1:4] of a</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># true copy of subarray</span>
</pre></div>
</div>
</section>
<section id="i-o-with-numpy">
<h4>I/O with NumPy<a class="headerlink" href="#i-o-with-numpy" title="Link to this heading"></a></h4>
<ul>
<li><p>Numpy provides functions for reading data from file and for writing data
into the files</p></li>
<li><p>Simple text files</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.loadtxt()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.savetxt()</span></code></p></li>
<li><p>Data in regular column layout</p></li>
<li><p>Can deal with comments and different column delimiters</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="random-numbers">
<h4>Random numbers<a class="headerlink" href="#random-numbers" title="Link to this heading"></a></h4>
<ul>
<li><p>The module <code class="docutils literal notranslate"><span class="pre">numpy.random</span></code> provides several functions for constructing
random arrays</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">random()</span></code>: uniform random numbers</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">normal()</span></code>: normal distribution</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">choice()</span></code>: random sample from given array</p></li>
<li><p>…</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy.random</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">rnd</span>
<span class="n">rnd</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="c1"># array([[ 0.02909142, 0.90848 ],</span>
<span class="c1">#       [ 0.9471314 , 0.31424393]])</span>

<span class="n">rnd</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1"># array([0, 1, 1, 2, 1, 1, 2, 0, 2, 3])</span>
</pre></div>
</div>
</section>
<section id="polynomials">
<h4>Polynomials<a class="headerlink" href="#polynomials" title="Link to this heading"></a></h4>
<ul>
<li><p>Polynomial is defined by an array of coefficients p
<code class="docutils literal notranslate"><span class="pre">p(x,</span> <span class="pre">N)</span> <span class="pre">=</span> <span class="pre">p[0]</span> <span class="pre">x^{N-1}</span> <span class="pre">+</span> <span class="pre">p[1]</span> <span class="pre">x^{N-2}</span> <span class="pre">+</span> <span class="pre">...</span> <span class="pre">+</span> <span class="pre">p[N-1]</span></code></p></li>
<li><p>For example:</p>
<blockquote>
<div><ul class="simple">
<li><p>Least square fitting: <code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.polyfit()</span></code></p></li>
<li><p>Evaluating polynomials: <code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.polyval()</span></code></p></li>
<li><p>Roots of polynomial: <code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.roots()</span></code></p></li>
</ul>
</div></blockquote>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">rnd</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">p</span>
<span class="c1"># array([ 0.96869003, -0.01157275, 0.69352514])</span>
</pre></div>
</div>
</section>
<section id="linear-algebra">
<h4>Linear algebra<a class="headerlink" href="#linear-algebra" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>NumPy can calculate matrix and vector products efficiently: <code class="xref py py-meth docutils literal notranslate"><span class="pre">dot()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">vdot()</span></code>, …</p></li>
<li><p>Eigenproblems: <code class="xref py py-meth docutils literal notranslate"><span class="pre">linalg.eig()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">linalg.eigvals()</span></code>, …</p></li>
<li><p>Linear systems and matrix inversion: <code class="xref py py-meth docutils literal notranslate"><span class="pre">linalg.solve()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">linalg.inv()</span></code></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(((</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">),</span> <span class="p">(</span><span class="mf">4.2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)))</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="c1"># solve C x = b</span>
<span class="c1"># array([ 0.04453441, 0.06882591])</span>
</pre></div>
</div>
<ul>
<li><p>Normally, NumPy utilises high performance libraries in linear algebra
operations</p></li>
<li><p>Example: matrix multiplication C = A * B matrix dimension 1000</p>
<blockquote>
<div><ul class="simple">
<li><p>pure python:           522.30 s</p></li>
<li><p>naive C:                 1.50 s</p></li>
<li><p>numpy.dot:               0.04 s</p></li>
<li><p>library call from C:     0.04 s</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
</section>
<section id="pandas">
<h3>Pandas<a class="headerlink" href="#pandas" title="Link to this heading"></a></h3>
<p>Pandas is a Python package that provides high-performance and easy to use
data structures and data analysis tools. Built on NumPy arrays, Pandas is
particularly well suited to analyze tabular and time series data.
Although NumPy could in principle deal with structured arrays
(arrays with mixed data types), it is not efficient.</p>
<p>The core data structures of Pandas are Series and Dataframes.</p>
<ul class="simple">
<li><p>A Pandas <strong>series</strong> is a one-dimensional NumPy array with an index
which we could use to access the data</p></li>
<li><p>A <strong>dataframe</strong> consist of a table of values with labels for each row and column.
A dataframe can combine multiple data types, such as numbers and text,
but the data in each column is of the same type.</p></li>
<li><p>Each column of a dataframe is a series object - a dataframe is thus a collection of series.</p></li>
</ul>
<img alt="_images/01_table_dataframe.svg" src="_images/01_table_dataframe.svg" />
<section id="tidy-vs-untidy-data">
<h4>Tidy vs untidy data<a class="headerlink" href="#tidy-vs-untidy-data" title="Link to this heading"></a></h4>
<p>Let’s first look at the following two dataframes:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">Untidy data format</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">Tidy data format</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">runners</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span>
      <span class="p">{</span><span class="s1">&#39;Runner&#39;</span><span class="p">:</span> <span class="s1">&#39;Runner 1&#39;</span><span class="p">,</span> <span class="mi">400</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">800</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">1200</span><span class="p">:</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">1500</span><span class="p">:</span> <span class="mi">240</span><span class="p">},</span>
      <span class="p">{</span><span class="s1">&#39;Runner&#39;</span><span class="p">:</span> <span class="s1">&#39;Runner 2&#39;</span><span class="p">,</span> <span class="mi">400</span><span class="p">:</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">800</span><span class="p">:</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">1200</span><span class="p">:</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">1500</span><span class="p">:</span> <span class="mi">300</span><span class="p">},</span>
      <span class="p">{</span><span class="s1">&#39;Runner&#39;</span><span class="p">:</span> <span class="s1">&#39;Runner 3&#39;</span><span class="p">,</span> <span class="mi">400</span><span class="p">:</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">800</span><span class="p">:</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">1200</span><span class="p">:</span> <span class="mi">288</span><span class="p">,</span> <span class="mi">1500</span><span class="p">:</span> <span class="mi">360</span><span class="p">},</span>
   <span class="p">])</span>
<span class="n">runners</span>

<span class="c1"># returns:</span>

<span class="c1">#      Runner  400  800  1200  1500</span>
<span class="c1"># 0  Runner 1   64  128   192   240</span>
<span class="c1"># 1  Runner 2   80  160   240   300</span>
<span class="c1"># 2  Runner 3   96  192   288   360</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># &quot;melt&quot; the data (opposite of &quot;pivot&quot;)</span>
<span class="n">runners</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">runners</span><span class="p">,</span> <span class="n">id_vars</span><span class="o">=</span><span class="s2">&quot;Runner&quot;</span><span class="p">,</span>
                  <span class="n">value_vars</span><span class="o">=</span><span class="p">[</span><span class="mi">400</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">1200</span><span class="p">,</span> <span class="mi">1500</span><span class="p">],</span>
                  <span class="n">var_name</span><span class="o">=</span><span class="s2">&quot;distance&quot;</span><span class="p">,</span>
                  <span class="n">value_name</span><span class="o">=</span><span class="s2">&quot;time&quot;</span>
                  <span class="p">)</span>
<span class="c1"># returns:</span>

<span class="c1">#       Runner distance  time</span>
<span class="c1"># 0   Runner 1      400    64</span>
<span class="c1"># 1   Runner 2      400    80</span>
<span class="c1"># 2   Runner 3      400    96</span>
<span class="c1"># 3   Runner 1      800   128</span>
<span class="c1"># 4   Runner 2      800   160</span>
<span class="c1"># 5   Runner 3      800   192</span>
<span class="c1"># 6   Runner 1     1200   192</span>
<span class="c1"># 7   Runner 2     1200   240</span>
<span class="c1"># 8   Runner 3     1200   288</span>
<span class="c1"># 9   Runner 1     1500   240</span>
<span class="c1"># 10  Runner 2     1500   300</span>
<span class="c1"># 11  Runner 3     1500   360</span>
</pre></div>
</div>
</div></div>
<p>Most tabular data is either in a tidy format or a untidy format
(some people refer them as the long format or the wide format).</p>
<ul class="simple">
<li><p>In untidy (wide) format, each row represents an observation
consisting of multiple variables and each variable has its own column.
This is intuitive and easy for us to understand
and  make comparisons across different variables, calculate statistics, etc.</p></li>
<li><p>In tidy (long) format , i.e. column-oriented format, each row represents
only one variable of the observation, and can be considered “computer readable”.</p></li>
</ul>
<p>When it comes to data analysis using Pandas, the tidy format is recommended:</p>
<ul class="simple">
<li><p>Each column can be stored as a vector and this not only saves memory
but also allows for vectorized calculations which are much faster.</p></li>
<li><p>It’s easier to filter, group, join and aggregate the data.</p></li>
</ul>
<p>The name “tidy data” comes from <a class="reference external" href="https://vita.had.co.nz/papers/tidy-data.pdf">Wickham’s paper (2014)</a>
which describes the ideas in great detail.</p>
</section>
<section id="data-analysis-workflow">
<h4>Data analysis workflow<a class="headerlink" href="#data-analysis-workflow" title="Link to this heading"></a></h4>
<p>Pandas is a powerful tool for many steps of a data analysis pipeline:</p>
<ul class="simple">
<li><p>Downloading and reading in datasets</p></li>
<li><p>Initial exploration of data</p></li>
<li><p>Pre-processing and cleaning data</p>
<ul>
<li><p>renaming, reshaping, reordering, type conversion, handling duplicate/missing/invalid data</p></li>
</ul>
</li>
<li><p>Analysis</p></li>
</ul>
<p>To explore some of the capabilities, we start with an
example dataset containing the passenger list from the Titanic, which is often used in
Kaggle competitions and data science tutorials. First step is to load Pandas and download
the dataset into a dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv&quot;</span>
<span class="c1"># set the index to the &quot;Name&quot; column</span>
<span class="n">titanic</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">&quot;Name&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Pandas also understands multiple other formats, for example <code class="xref py py-meth docutils literal notranslate"><span class="pre">read_excel()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">read_hdf()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">read_json()</span></code>, etc. (and corresponding methods to write to file:
<code class="xref py py-meth docutils literal notranslate"><span class="pre">to_csv()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">to_excel()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">to_hdf()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">to_json()</span></code>, …)</p>
<p>We can now view the dataframe to get an idea of what it contains and
print some summary statistics of its numerical data:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># print the first 5 lines of the dataframe</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1"># print some information about the columns</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>

<span class="c1"># print summary statistics for each column</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
<p>Ok, so we have information on passenger names, survival (0 or 1), age,
ticket fare, number of siblings/spouses, etc. With the summary statistics we
see that the average age is 29.7 years, maximum ticket price is 512 USD,
38% of passengers survived, etc.</p>
<p>Unlike a NumPy array, a dataframe can combine multiple data types, such as
numbers and text, but the data in each column is of the same type. So we say a
column is of type <code class="docutils literal notranslate"><span class="pre">int64</span></code> or of type <code class="docutils literal notranslate"><span class="pre">object</span></code>.</p>
</section>
<section id="indexing">
<h4>Indexing<a class="headerlink" href="#indexing" title="Link to this heading"></a></h4>
<p>Let’s inspect one column of the dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">titanic</span><span class="p">[</span><span class="s2">&quot;Age&quot;</span><span class="p">]</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">Age</span>          <span class="c1"># same as above</span>
</pre></div>
</div>
<p>The columns have names. Here’s how to get them:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">titanic</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
<p>However, the rows also have names! This is what Pandas calls the <strong>index</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">titanic</span><span class="o">.</span><span class="n">index</span>
</pre></div>
</div>
<p>We saw above how to select a single column, but there are many ways of
selecting (and setting) single or multiple rows, columns and elements. We can
refer to columns and rows either by number or by their name:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">titanic</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Lam, Mr. Ali&quot;</span><span class="p">,</span><span class="s2">&quot;Age&quot;</span><span class="p">]</span>          <span class="c1"># select single value by row and column</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Lam, Mr. Ali&quot;</span><span class="p">,</span><span class="s2">&quot;Survived&quot;</span><span class="p">:</span><span class="s2">&quot;Age&quot;</span><span class="p">]</span>  <span class="c1"># slice the dataframe by row and column *names*</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">692</span><span class="p">,</span><span class="mi">3</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span>                      <span class="c1"># same slice as above by row and column *numbers*</span>

<span class="n">titanic</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="s2">&quot;Lam, Mr. Ali&quot;</span><span class="p">,</span><span class="s2">&quot;Age&quot;</span><span class="p">]</span>           <span class="c1"># select single value by row and column *name* (fast)</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="s2">&quot;Lam, Mr. Ali&quot;</span><span class="p">,</span><span class="s2">&quot;Age&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">42</span>      <span class="c1"># set single value by row and column *name* (fast)</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">iat</span><span class="p">[</span><span class="mi">692</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>                         <span class="c1"># select same value by row and column *number* (fast)</span>

<span class="n">titanic</span><span class="p">[</span><span class="s2">&quot;somecolumns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;somevalue&quot;</span>       <span class="c1"># set a whole column</span>
</pre></div>
</div>
<p>Dataframes also support boolean indexing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">titanic</span><span class="p">[</span><span class="n">titanic</span><span class="p">[</span><span class="s2">&quot;Age&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">70</span><span class="p">]</span>
<span class="c1"># &quot;.str&quot; creates a string object from a column</span>
<span class="n">titanic</span><span class="p">[</span><span class="n">titanic</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&quot;Margaret&quot;</span><span class="p">)]</span>
</pre></div>
</div>
</section>
<section id="missing-invalid-data">
<h4>Missing/invalid data<a class="headerlink" href="#missing-invalid-data" title="Link to this heading"></a></h4>
<p>What if your dataset has missing data? Pandas uses the value <code class="docutils literal notranslate"><span class="pre">np.nan</span></code>
to represent missing data, and by default does not include it in any computations.
We can find missing values, drop them from our dataframe, replace them
with any value we like or do forward or backward filling:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">titanic</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span>                    <span class="c1"># returns boolean mask of NaN values</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>                  <span class="c1"># drop missing values</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s2">&quot;any&quot;</span><span class="p">)</span>         <span class="c1"># or how=&quot;all&quot;</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Cabin&quot;</span><span class="p">])</span>  <span class="c1"># only drop NaNs from one column</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>                 <span class="c1"># replace NaNs with zero</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;ffill&#39;</span><span class="p">)</span>    <span class="c1"># forward-fill NaNs</span>
<span class="n">titanic</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;bfill&#39;</span><span class="p">)</span>    <span class="c1"># backward-fill NaNs</span>
</pre></div>
</div>
</section>
<section id="groupby">
<h4>Groupby<a class="headerlink" href="#groupby" title="Link to this heading"></a></h4>
<p><code class="xref py py-meth docutils literal notranslate"><span class="pre">groupby()</span></code> is a powerful method which splits a dataframe and aggregates data
in groups. To see what’s possible, let’s
test the old saying “Women and children first”. We start by creating a new
column <code class="docutils literal notranslate"><span class="pre">Child</span></code> to indicate whether a passenger was a child or not, based on
the existing <code class="docutils literal notranslate"><span class="pre">Age</span></code> column. For this example, let’s assume that you are a
child when you are younger than 12 years:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">titanic</span><span class="p">[</span><span class="s2">&quot;Child&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">[</span><span class="s2">&quot;Age&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">12</span>
</pre></div>
</div>
<p>Now we can test the saying by grouping the data on <code class="docutils literal notranslate"><span class="pre">Sex</span></code> and then creating
further sub-groups based on <code class="docutils literal notranslate"><span class="pre">Child</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">titanic</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;Sex&quot;</span><span class="p">,</span> <span class="s2">&quot;Child&quot;</span><span class="p">])[</span><span class="s2">&quot;Survived&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<p>Here we chose to summarize the data by its mean, but many other common
statistical functions are available as dataframe methods, like
<code class="xref py py-meth docutils literal notranslate"><span class="pre">std()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">min()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">max()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">cumsum()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">median()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">skew()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">var()</span></code> etc.</p>
<p>The workflow of <code class="xref py py-meth docutils literal notranslate"><span class="pre">groupby()</span></code> can be divided into three general steps:</p>
<ul class="simple">
<li><p>Splitting: Partition the data into different groups based on some criterion.</p></li>
<li><p>Applying: Do some caclulation within each group.
Different kinds of calulations might be aggregation, transformation, filtration.</p></li>
<li><p>Combining: Put the results back together into a single object.</p></li>
</ul>
<img alt="_images/groupby.png" src="_images/groupby.png" />
<p>(Image source from lecture Earth and Environmental Data Science <a class="reference external" href="https://earth-env-data-science.github.io/intro.html">https://earth-env-data-science.github.io/intro.html</a>)</p>
<p>For an overview of other data wrangling methods built into Pandas, have a look
at <a class="reference internal" href="#document-pandas-extra"><span class="doc">Optional: more on Pandas</span></a>.</p>
</section>
</section>
<section id="scipy">
<h3>Scipy<a class="headerlink" href="#scipy" title="Link to this heading"></a></h3>
<p><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/">SciPy</a> is a library that builds
on top of NumPy. It contains a lot of interfaces to battle-tested numerical routines
written in Fortran or C, as well as Python implementations of many common algorithms.</p>
<section id="what-s-in-scipy">
<h4>What’s in SciPy?<a class="headerlink" href="#what-s-in-scipy" title="Link to this heading"></a></h4>
<p>Briefly, it contains functionality for</p>
<ul class="simple">
<li><p>Special functions (Bessel, Gamma, etc.)</p></li>
<li><p>Numerical integration</p></li>
<li><p>Optimization</p></li>
<li><p>Interpolation</p></li>
<li><p>Fast Fourier Transform (FFT)</p></li>
<li><p>Signal processing</p></li>
<li><p>Linear algebra (more complete than in NumPy)</p></li>
<li><p>Sparse matrices</p></li>
<li><p>Statistics</p></li>
<li><p>More I/O routine, e.g. Matrix Market format for sparse matrices,
MATLAB files (.mat), etc.</p></li>
</ul>
<p>Many of these are not written specifically for SciPy, but use
the best available open source C or Fortran libraries.  Thus, you get
the best of Python and the best of compiled languages.</p>
<p>Most functions are documented very well from a scientific
standpoint: you aren’t just using some unknown function, but have a
full scientific description and citation to the method and
implementation.</p>
<p>Let us look more closely into one out of the countless useful functions available
in SciPy. <code class="xref py py-meth docutils literal notranslate"><span class="pre">curve_fit()</span></code> is a non-linear least squares fitting function. NumPy
has least-squares fitting via the <code class="xref py py-meth docutils literal notranslate"><span class="pre">np.linalg.lstsq()</span></code> function, but we need to
go to SciPy to find non-linear curve fitting.
This example fits a power-law to a vector:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">curve_fit</span>

<span class="k">def</span><span class="w"> </span><span class="nf">powerlaw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">A</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

<span class="c1"># data</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">9115</span><span class="p">,</span> <span class="mi">8368</span><span class="p">,</span> <span class="mi">7711</span><span class="p">,</span> <span class="mi">5480</span><span class="p">,</span> <span class="mi">3492</span><span class="p">,</span> <span class="mi">3376</span><span class="p">,</span> <span class="mi">2884</span><span class="p">,</span> <span class="mi">2792</span><span class="p">,</span> <span class="mi">2703</span><span class="p">,</span> <span class="mi">2701</span><span class="p">])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1.0</span>

<span class="c1"># initial guess for variables</span>
<span class="n">p0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># fit data</span>
<span class="n">params</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">powerlaw</span><span class="p">,</span> <span class="n">xdata</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">ydata</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A =&quot;</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;+/-&quot;</span><span class="p">,</span> <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;s =&quot;</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;+/-&quot;</span><span class="p">,</span> <span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># optionally plot</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">powerlaw</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>In an exercise below, you will learn to perform an operation like curve fitting
on all rows of a pandas dataframe in an effective manner.</p>
</section>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-working-effectively-with-dataframes exercise important admonition" id="exercise-0">
<p class="admonition-title">Working effectively with dataframes</p>
<p>Recall the <code class="xref py py-meth docutils literal notranslate"><span class="pre">curve_fit()</span></code> method from SciPy discussed above, and imagine that we
want to fit powerlaws to every row in a large dataframe. How can this be done effectively?</p>
<p>First define the <code class="xref py py-meth docutils literal notranslate"><span class="pre">powerlaw()</span></code> function and another function for fitting a row of numbers:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">curve_fit</span>

<span class="k">def</span><span class="w"> </span><span class="nf">powerlaw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">A</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">fit_powerlaw</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1.0</span>
    <span class="n">params</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">powerlaw</span><span class="p">,</span> <span class="n">xdata</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">ydata</span><span class="o">=</span><span class="n">row</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>Next load a dataset with multiple rows similar to the one used in the example above:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/ENCCS/hpda-python/main/content/data/results.csv&quot;</span><span class="p">)</span>
<span class="c1"># print first few rows</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<p>Now consider these four different ways of fitting a powerlaw to each row of the dataframe:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">Loop</button><button aria-controls="panel-3-3-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-1" name="3-1" role="tab" tabindex="-1"><code class="xref py py-meth docutils literal notranslate"><span class="pre">iterrows()</span></code></button><button aria-controls="panel-3-3-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-2" name="3-2" role="tab" tabindex="-1"><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply()</span></code></button><button aria-controls="panel-3-3-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-3" name="3-3" role="tab" tabindex="-1"><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply()</span></code> with <code class="docutils literal notranslate"><span class="pre">raw=True</span></code></button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">powers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">row_indx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">row_indx</span><span class="p">,</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">fit_powerlaw</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">powers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-1" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-1" name="3-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">powers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">row_indx</span><span class="p">,</span><span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">fit_powerlaw</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">powers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-2" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-2" name="3-2" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">powers</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fit_powerlaw</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-3" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-3" name="3-3" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># raw=True passes numpy ndarrays instead of series to fit_powerlaw</span>
<span class="n">powers</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fit_powerlaw</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">raw</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<p>Which one do you think is most efficient? You can measure the execution time
by adding <code class="docutils literal notranslate"><span class="pre">%%timeit</span></code> to the first line of a Jupyter code cell. More on timing
and profiling in a later episode.</p>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<p>The execution time drops as you go from the version in the left tab to the right tab:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-4-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-4-4-0" name="4-0" role="tab" tabindex="0">Loop</button><button aria-controls="panel-4-4-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-1" name="4-1" role="tab" tabindex="-1"><code class="xref py py-meth docutils literal notranslate"><span class="pre">iterrows()</span></code></button><button aria-controls="panel-4-4-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-2" name="4-2" role="tab" tabindex="-1"><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply()</span></code></button><button aria-controls="panel-4-4-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-3" name="4-3" role="tab" tabindex="-1"><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply()</span></code> with <code class="docutils literal notranslate"><span class="pre">raw=True</span></code></button></div><div aria-labelledby="tab-4-4-0" class="sphinx-tabs-panel" id="panel-4-4-0" name="4-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">timeit</span>
<span class="n">powers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">row_indx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
   <span class="n">row</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">row_indx</span><span class="p">,</span><span class="mi">1</span><span class="p">:]</span>
   <span class="n">p</span> <span class="o">=</span> <span class="n">fit_powerlaw</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
   <span class="n">powers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="c1"># 33.6 ms ± 682 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-1" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-1" name="4-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">timeit</span>
<span class="n">powers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">row_indx</span><span class="p">,</span><span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
   <span class="n">p</span> <span class="o">=</span> <span class="n">fit_powerlaw</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
   <span class="n">powers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="c1"># 28.7 ms ± 947 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-2" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-2" name="4-2" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">timeit</span>
<span class="n">powers</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fit_powerlaw</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># 26.1 ms ± 1.19 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-3" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-3" name="4-3" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">timeit</span>
<span class="n">powers</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fit_powerlaw</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">raw</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 24 ms ± 1.27 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
</div></div>
</div>
</div>
<div class="admonition-further-analysis-of-the-titanic-passenger-list-dataset exercise important admonition" id="exercise-1">
<p class="admonition-title">Further analysis of the Titanic passenger list dataset</p>
<p>Consider the titanic dataset. If you haven’t done so already, load it into a dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv&quot;</span>
<span class="n">titanic</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">&quot;Name&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p>Compute the mean age of the first 10 passengers by slicing and the <code class="docutils literal notranslate"><span class="pre">mean</span></code> method</p></li>
<li><p>Using boolean indexing, compute the survival rate
(mean of “Survived” values) among passengers over and under the average age.</p></li>
</ol>
<p>Now investigate the family size of the passengers (i.e. the “SibSp” column):</p>
<ol class="arabic simple" start="3">
<li><p>What different family sizes exist in the passenger list? Hint: try the <code class="xref py py-meth docutils literal notranslate"><span class="pre">unique()</span></code> method</p></li>
<li><p>What are the names of the people in the largest family group?</p></li>
<li><p>(Advanced) Create histograms showing the distribution of family sizes for
passengers split by the fare, i.e. one group of high-fare passengers (where
the fare is above average) and one for low-fare passengers
(Hint: instead of an existing column name, you can give a lambda function
as a parameter to <code class="docutils literal notranslate"><span class="pre">hist</span></code> to compute a value on the fly. For example
<code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">x:</span> <span class="pre">&quot;Poor&quot;</span> <span class="pre">if</span> <span class="pre">titanic[&quot;Fare&quot;].loc[x]</span> <span class="pre">&lt;</span> <span class="pre">titanic[&quot;Fare&quot;].mean()</span> <span class="pre">else</span> <span class="pre">&quot;Rich&quot;</span></code>).</p></li>
</ol>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<ol class="arabic simple">
<li><p>Mean age of the first 10 passengers: <code class="docutils literal notranslate"><span class="pre">titanic.iloc[:10,:][&quot;Age&quot;].mean()</span></code>
or <code class="docutils literal notranslate"><span class="pre">titanic.iloc[:10,4].mean()</span></code> or
<code class="docutils literal notranslate"><span class="pre">titanic.loc[:&quot;Nasser,</span> <span class="pre">Mrs.</span> <span class="pre">Nicholas</span> <span class="pre">(Adele</span> <span class="pre">Achem)&quot;,</span> <span class="pre">&quot;Age&quot;].mean()</span></code>.</p></li>
<li><p>Survival rate among passengers over and under average age:
<code class="docutils literal notranslate"><span class="pre">titanic[titanic[&quot;Age&quot;]</span> <span class="pre">&gt;</span> <span class="pre">titanic[&quot;Age&quot;].mean()][&quot;Survived&quot;].mean()</span></code> and
<code class="docutils literal notranslate"><span class="pre">titanic[titanic[&quot;Age&quot;]</span> <span class="pre">&lt;</span> <span class="pre">titanic[&quot;Age&quot;].mean()][&quot;Survived&quot;].mean()</span></code>.</p></li>
<li><p>Existing family sizes: <code class="docutils literal notranslate"><span class="pre">titanic[&quot;SibSp&quot;].unique()</span></code></p></li>
<li><p>Names of members of largest family(ies): <code class="docutils literal notranslate"><span class="pre">titanic[titanic[&quot;SibSp&quot;]</span> <span class="pre">==</span> <span class="pre">8].index</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">titanic.hist(&quot;SibSp&quot;,</span> <span class="pre">lambda</span> <span class="pre">x:</span> <span class="pre">&quot;Poor&quot;</span> <span class="pre">if</span> <span class="pre">titanic[&quot;Fare&quot;].loc[x]</span> <span class="pre">&lt;</span> <span class="pre">titanic[&quot;Fare&quot;].mean()</span> <span class="pre">else</span> <span class="pre">&quot;Rich&quot;,</span> <span class="pre">rwidth=0.9)</span></code></p></li>
</ol>
</div>
</div>
</section>
<section id="see-also">
<h3>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>NumPy <a class="reference external" href="https://numpy.org/doc/stable/">documentation</a></p></li>
<li><p>Pandas  <a class="reference external" href="https://pandas.pydata.org/getting_started.html">getting started guide</a></p></li>
<li><p>Pandas <a class="reference external" href="https://pandas.pydata.org/docs/">documentation</a> containing a user guide,
API reference and contribution guide.</p></li>
<li><p>Pandas <a class="reference external" href="https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf">cheatsheet</a></p></li>
<li><p>Pandas <a class="reference external" href="https://pandas.pydata.org/docs/user_guide/cookbook.html#cookbook">cookbook</a>.</p></li>
<li><p>Scipy <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/">documentation</a></p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>NumPy provides a static array data structure, fast mathematical operations for
arrays and tools for linear algebra and random numbers</p></li>
<li><p>Pandas dataframes are a good data structure for tabular data</p></li>
<li><p>Dataframes allow both simple and advanced analysis in very compact form</p></li>
<li><p>SciPy contains a lot of interfaces to battle-tested numerical routines</p></li>
</ul>
</div>
</section>
</section>
<span id="document-parallel-computing"></span><section id="parallel-computing">
<span id="id1"></span><h2>Parallel computing<a class="headerlink" href="#parallel-computing" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What is the Global Interpreter Lock in Python?</p></li>
<li><p>How can Python code be parallelised?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Become familiar with different types of parallelism</p></li>
<li><p>Learn the basics of parallel workflows, multiprocessing and distributed memory parallelism</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>40 min teaching/type-along</p></li>
<li><p>40 min exercises</p></li>
</ul>
</div>
<p>The performance of a single CPU core has stagnated over the last ten years
and most of the speed-up in modern CPUs is coming from using multiple
CPU cores, i.e. parallel processing. Parallel processing is normally based
either on multiple threads or multiple processes.</p>
<p>There are three main models of parallel computing:</p>
<ul class="simple">
<li><p><strong>“Embarrassingly” parallel:</strong> the code does not need to synchronize/communicate
with other instances, and you can run
multiple instances of the code separately, and combine the results
later.  If you can do this, great!</p></li>
<li><p><strong>Shared memory parallelism (multithreading):</strong></p>
<ul>
<li><p>Parallel threads do separate work and communicate via the same memory and write to shared variables.</p></li>
<li><p>Multiple threads in a single Python program cannot execute at the same time (see GIL below)</p></li>
<li><p>Running multiple threads in Python is <em>only effective for certain I/O-bound tasks</em></p></li>
<li><p>External libraries in other languages (e.g. C) which are called from Python can still use multithreading</p></li>
</ul>
</li>
<li><p><strong>Distributed memory parallelism (multiprocessing):</strong> Different processes manage their own memory segments and
share data by communicating (passing messages) as needed.</p>
<ul>
<li><p>A process can contain one or more threads</p></li>
<li><p>Two processes can run on different CPU cores and different computers</p></li>
<li><p>Processes have more overhead than threads (creating and destroying processes takes more time)</p></li>
<li><p>Running multiple processes is <em>only effective for CPU-bound tasks</em></p></li>
</ul>
</li>
</ul>
<p>In the next episode we will look at <a class="reference external" href="https://dask.org/">Dask</a>, an array model extension and task scheduler,
which combines multiprocessing with (embarrassingly) parallel workflows and “lazy” execution.</p>
<p>In the Python world, it is common to see the word <cite>concurrency</cite> denoting any type of simultaneous
processing, including <em>threads</em>, <em>tasks</em> and <em>processes</em>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Parallel programming requires that we adopt a different mental model compared to serial programming.
Many things can go wrong and one can get unexpected results or difficult-to-debug
problems. It is important to understand the possible pitfalls before embarking
on code parallelisation. For an entertaining take on this, see
<a class="reference external" href="https://www.youtube.com/watch?v=Bv25Dwe84g0">Raymond Hettinger’s PyCon2016 presentation</a>.</p>
</div>
<section id="the-global-interpreter-lock">
<h3>The Global Interpreter Lock<a class="headerlink" href="#the-global-interpreter-lock" title="Link to this heading"></a></h3>
<p>The designers of the Python language made the choice
that <strong>only one thread in a process can run actual Python code</strong>
by using the so-called <strong>global interpreter lock (GIL)</strong>.
This means that approaches that may work in other languages (C, C++, Fortran),
may not work in Python without being a bit careful.
The reason GIL is needed is because part of the Python implementation related to
the memory management is not thread-safe.
At first glance, this is bad for parallelism.  But one can avoid GIL through the folowing:</p>
<ul class="simple">
<li><p>External libraries (NumPy, SciPy, Pandas, etc), written in C or other
languages, can release the lock and run multi-threaded.</p></li>
<li><p>Most input/output tasks release the GIL.</p></li>
<li><p>There are several Python libraries that side-step the GIL, e.g. by using
<em>multiprocessing</em> instead of <em>threading</em>.</p></li>
</ul>
</section>
<section id="multithreading">
<h3>Multithreading<a class="headerlink" href="#multithreading" title="Link to this heading"></a></h3>
<p>Due to the GIL only one thread can execute Python code at once, and this makes
threading rather useless for <em>compute-bound</em> problems in pure Python.
However, multithreading is still relevant in two situations:</p>
<ul class="simple">
<li><p>External libraries written in non-Python languages can take advantage of multithreading</p></li>
<li><p>Multithreading can be useful for running <em>multiple I/O-bound tasks simultaneously</em>.</p></li>
</ul>
<section id="multithreaded-libraries">
<h4>Multithreaded libraries<a class="headerlink" href="#multithreaded-libraries" title="Link to this heading"></a></h4>
<p>NumPy and SciPy are built on external libraries such as LAPACK, FFTW append BLAS,
which provide optimized routines for linear algebra, Fourier transforms etc.
These libraries are written in C, C++ or Fortran and are thus not limited
by the GIL, so they typically support actual multihreading during the execution.
It might be a good idea to use multiple threads during calculations
like matrix operations or frequency analysis.</p>
<p>Depending on configuration, NumPy will often use multiple threads by default,
but we can use the environment variable <code class="docutils literal notranslate"><span class="pre">OMP_NUM_THREADS</span></code> to set the number
of threads manually:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">OMP_NUM_THREADS</span><span class="o">=</span>&lt;N&gt;
</pre></div>
</div>
<p>After setting this environment variable we continue as usual
and multithreading will be turned on.</p>
<div class="admonition-demo-multithreading-numpy demo admonition" id="demo-0">
<p class="admonition-title">Demo: Multithreading NumPy</p>
<p>Here is an example which does a symmetrical matrix inversion of size 4000 by 4000.
To run it, we can save it in a file named <cite>omp_test.py</cite> or download from <a class="reference download internal" download="" href="_downloads/fa12034be4aa763ead435ee5e89e5785/omp_test.py"><code class="xref download docutils literal notranslate"><span class="pre">here</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">4000</span><span class="p">,</span><span class="mi">4000</span><span class="p">))</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span>
<span class="n">time_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">time_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;time spent for inverting A is&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">time_end</span> <span class="o">-</span> <span class="n">time_start</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Let us test it with 1 and 4 threads:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="m">1</span>
<span class="gp">$ </span>python<span class="w"> </span>omp_test.py

<span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="m">4</span>
<span class="gp">$ </span>python<span class="w"> </span>omp_test.py
</pre></div>
</div>
</div>
</section>
<section id="multithreaded-i-o">
<h4>Multithreaded I/O<a class="headerlink" href="#multithreaded-i-o" title="Link to this heading"></a></h4>
<p>This is how an I/O-bound application might look:</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="_images/IOBound.png"><img alt="_images/IOBound.png" src="_images/IOBound.png" style="width: 694.8000000000001px; height: 214.8px;" />
</a>
<figcaption>
<p><span class="caption-text">From <a class="reference external" href="https://realpython.com/">https://realpython.com/</a>, distributed via a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported licence</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>The <a class="reference external" href="https://docs.python.org/dev/library/threading.html#">threading library</a>
provides an API for creating and working with threads. The simplest approach to
create and manage threads is to use the <code class="docutils literal notranslate"><span class="pre">ThreadPoolExecutor</span></code> class.
An example use case could be to download data from multiple websites using
multiple threads:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">concurrent.futures</span>

<span class="k">def</span><span class="w"> </span><span class="nf">download_all_sites</span><span class="p">(</span><span class="n">sites</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
        <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">my_download_function</span><span class="p">,</span> <span class="n">sites</span><span class="p">)</span>
</pre></div>
</div>
<p>The speedup gained from multithreading I/O bound problems can be understood from the following image.</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="_images/Threading.png"><img alt="_images/Threading.png" src="_images/Threading.png" style="width: 598.5px; height: 268.5px;" />
</a>
<figcaption>
<p><span class="caption-text">From <a class="reference external" href="https://realpython.com/">https://realpython.com/</a>, distributed via a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported licence</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Further details on threading in Python can be found in the <strong>See also</strong> section below.</p>
</section>
</section>
<section id="multiprocessing">
<h3>Multiprocessing<a class="headerlink" href="#multiprocessing" title="Link to this heading"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> module in Python supports spawning processes using an API
similar to the <code class="docutils literal notranslate"><span class="pre">threading</span></code> module. It effectively side-steps the GIL by using
<em>subprocesses</em> instead of threads, where each subprocess is an independent Python
process.</p>
<p>One of the simplest ways to use <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> is via <code class="docutils literal notranslate"><span class="pre">Pool</span></code> objects and
the parallel <code class="xref py py-meth docutils literal notranslate"><span class="pre">Pool.map()</span></code> function, similarly to what we saw for multithreading above.
In the following code, we define a <code class="xref py py-meth docutils literal notranslate"><span class="pre">square()</span></code>
function, call the <code class="xref py py-meth docutils literal notranslate"><span class="pre">cpu_count()</span></code> method to get the number of CPUs on the machine,
and then initialize a Pool object in a context manager and inside of it call the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">Pool.map()</span></code> method to parallelize the computation.
We can save the code in a file named <cite>mp_map.py</cite> or download from <a class="reference download internal" download="" href="_downloads/9407ea9591fa1132c0f7ae31cb0c4eb0/mp_map.py"><code class="xref download docutils literal notranslate"><span class="pre">here</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mp</span>
</span>   
<span class="k">def</span><span class="w"> </span><span class="nf">square</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
   
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">nprocs</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of CPU cores: </span><span class="si">{</span><span class="n">nprocs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
   
    <span class="c1"># use context manager to allocate and release the resources automatically</span>
<span class="hll">    <span class="k">with</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">nprocs</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
</span><span class="hll">        <span class="n">result</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>    
</span>    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    
</pre></div>
</div>
<p>For functions that take multiple arguments one can instead use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">Pool.starmap()</span></code>
function (save as <cite>mp_starmap.py</cite> or download <a class="reference download internal" download="" href="_downloads/4b1cd1e34588fb0e0e9162c7f99ed0ad/mp_starmap.py"><code class="xref download docutils literal notranslate"><span class="pre">here</span></code></a>)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mp</span>
</span>
<span class="k">def</span><span class="w"> </span><span class="nf">power_n</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="n">n</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">nprocs</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of CPU cores: </span><span class="si">{</span><span class="n">nprocs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="hll">    <span class="k">with</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">nprocs</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
</span><span class="hll">        <span class="n">result</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">starmap</span><span class="p">(</span><span class="n">power_n</span><span class="p">,</span> <span class="p">[(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)])</span>
</span>    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    
</pre></div>
</div>
<div class="admonition-interactive-environments callout admonition" id="callout-0">
<p class="admonition-title">Interactive environments</p>
<p>Functionality within multiprocessing requires that the <code class="docutils literal notranslate"><span class="pre">__main__</span></code> module be
importable by children processes. This means that for example <code class="docutils literal notranslate"><span class="pre">multiprocessing.Pool</span></code>
will not work in the interactive interpreter. A fork of multiprocessing, called
<code class="docutils literal notranslate"><span class="pre">multiprocess</span></code>, can be used in interactive environments like Jupyter.</p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> has a number of other methods which can be useful for certain
use cases, including <code class="docutils literal notranslate"><span class="pre">Process</span></code> and <code class="docutils literal notranslate"><span class="pre">Queue</span></code> which make it possible to have direct
control over individual processes. Refer to the <a class="reference internal" href="#see-also">See also</a> section below for a list
of external resources that cover these methods.</p>
<p>At the end of this episode you can turn your attention back to the word-count problem
and practice using <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> pools of processes.</p>
</section>
<section id="mpi">
<h3>MPI<a class="headerlink" href="#mpi" title="Link to this heading"></a></h3>
<p>The message passing interface (MPI) is a standard workhorse of parallel computing. Nearly
all major scientific HPC applications use MPI. Like <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code>, MPI belongs to the
distributed-memory paradigm.</p>
<p>The idea behind MPI is that:</p>
<ul class="simple">
<li><p>Tasks have a rank and are numbered 0, 1, 2, 3, …</p></li>
<li><p>Each task manages its own memory</p></li>
<li><p>Each task can run multiple threads</p></li>
<li><p>Tasks communicate and share data by sending messages.</p></li>
<li><p>Many higher-level functions exist to distribute information to other tasks
and gather information from other tasks.</p></li>
<li><p>All tasks typically <em>run the entire code</em> and we have to be careful to avoid
that all tasks do the same thing.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">mpi4py</span></code> provides Python bindings for the Message Passing Interface (MPI) standard.
This is how a hello world MPI program looks like in Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Hello from process </span><span class="si">{}</span><span class="s1"> out of </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MPI.COMM_WORLD</span></code> is the <cite>communicator</cite> - a group of processes that can talk to each other</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Get_rank</span></code> returns the individual rank (0, 1, 2, …) for each task that calls it</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Get_size</span></code> returns the total number of ranks.</p></li>
</ul>
<p>To run this code with a specific number of processes we use the <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> command which
comes with the MPI library:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>mpirun<span class="w"> </span>-np<span class="w"> </span><span class="m">4</span><span class="w"> </span>python<span class="w"> </span>hello.py

<span class="gp"># </span>Hello<span class="w"> </span>from<span class="w"> </span>process<span class="w"> </span><span class="m">1</span><span class="w"> </span>out<span class="w"> </span>of<span class="w"> </span><span class="m">4</span>
<span class="gp"># </span>Hello<span class="w"> </span>from<span class="w"> </span>process<span class="w"> </span><span class="m">0</span><span class="w"> </span>out<span class="w"> </span>of<span class="w"> </span><span class="m">4</span>
<span class="gp"># </span>Hello<span class="w"> </span>from<span class="w"> </span>process<span class="w"> </span><span class="m">2</span><span class="w"> </span>out<span class="w"> </span>of<span class="w"> </span><span class="m">4</span>
<span class="gp"># </span>Hello<span class="w"> </span>from<span class="w"> </span>process<span class="w"> </span><span class="m">3</span><span class="w"> </span>out<span class="w"> </span>of<span class="w"> </span><span class="m">4</span>
</pre></div>
</div>
<section id="point-to-point-and-collective-communication">
<h4>Point-to-point and collective communication<a class="headerlink" href="#point-to-point-and-collective-communication" title="Link to this heading"></a></h4>
<p>The MPI standard contains a <a class="reference external" href="https://mpi4py.readthedocs.io/en/stable/index.html">lot of functionality</a>,
but in principle one can get away with only point-to-point communication (<code class="docutils literal notranslate"><span class="pre">MPI.COMM_WORLD.send</span></code> and
<code class="docutils literal notranslate"><span class="pre">MPI.COMM_WORLD.recv</span></code>). However, collective communication can sometimes require less effort as you
will learn in an exercise below.
In any case, it is good to have a mental model of different communication patterns in MPI.</p>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="_images/send-recv.png"><img alt="_images/send-recv.png" src="_images/send-recv.png" style="width: 525.0px; height: 162.0px;" />
</a>
<figcaption>
<p><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">send</span></code> and <code class="docutils literal notranslate"><span class="pre">recv</span></code>: blocking point-to-point communication between two ranks.</span><a class="headerlink" href="#id5" title="Link to this image"></a></p>
</figcaption>
</figure>
<figure class="align-right" id="id6">
<a class="reference internal image-reference" href="_images/gather.png"><img alt="_images/gather.png" src="_images/gather.png" style="width: 240.0px; height: 198.4px;" />
</a>
<figcaption>
<p><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">gather</span></code>: all ranks send data to rank <code class="docutils literal notranslate"><span class="pre">root</span></code>.</span><a class="headerlink" href="#id6" title="Link to this image"></a></p>
</figcaption>
</figure>
<figure class="align-center" id="id7">
<a class="reference internal image-reference" href="_images/scatter.png"><img alt="_images/scatter.png" src="_images/scatter.png" style="width: 240.0px; height: 198.4px;" />
</a>
<figcaption>
<p><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">scatter</span></code>: data on rank 0 is split into chunks and sent to other ranks</span><a class="headerlink" href="#id7" title="Link to this image"></a></p>
</figcaption>
</figure>
<figure class="align-left" id="id8">
<a class="reference internal image-reference" href="_images/broadcast.png"><img alt="_images/broadcast.png" src="_images/broadcast.png" style="width: 240.0px; height: 198.4px;" />
</a>
<figcaption>
<p><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">bcast</span></code>: broadcast message to all ranks</span><a class="headerlink" href="#id8" title="Link to this image"></a></p>
</figcaption>
</figure>
<figure class="align-center" id="id9">
<a class="reference internal image-reference" href="_images/reduction.png"><img alt="_images/reduction.png" src="_images/reduction.png" style="width: 309.0px; height: 163.0px;" />
</a>
<figcaption>
<p><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">reduce</span></code>: ranks send data which are reduced on rank <code class="docutils literal notranslate"><span class="pre">root</span></code></span><a class="headerlink" href="#id9" title="Link to this image"></a></p>
</figcaption>
</figure>
<section id="examples">
<h5>Examples<a class="headerlink" href="#examples" title="Link to this heading"></a></h5>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">send/recv</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">isend/irecv</button><button aria-controls="panel-0-0-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-2" name="0-2" role="tab" tabindex="-1">broadcast</button><button aria-controls="panel-0-0-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-3" name="0-3" role="tab" tabindex="-1">gather</button><button aria-controls="panel-0-0-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-4" name="0-4" role="tab" tabindex="-1">scatter</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
<span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># All ranks other than 0 should send a message</span>
    <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;Hello World, I&#39;m rank </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
<span class="hll">    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class="k">else</span><span class="p">:</span>
    <span class="c1"># Rank 0 will receive each message and print them</span>
    <span class="k">for</span> <span class="n">sender</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_ranks</span><span class="p">):</span>
<span class="hll">        <span class="n">message</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">sender</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span>        <span class="nb">print</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
<span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># All ranks other than 0 should send a message</span>
    <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;Hello World, I&#39;m rank </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
<span class="hll">    <span class="n">req</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">isend</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span>    <span class="n">req</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Rank 0 will receive each message and print them</span>
    <span class="k">for</span> <span class="n">sender</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_ranks</span><span class="p">):</span>
<span class="hll">        <span class="n">req</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">irecv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">sender</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span>        <span class="n">message</span> <span class="o">=</span> <span class="n">req</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-2" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-2" name="0-2" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
<span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

<span class="c1"># Rank 0 will broadcast message to all other ranks</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">send_message</span> <span class="o">=</span> <span class="s2">&quot;Hello World from rank 0&quot;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">send_message</span> <span class="o">=</span> <span class="kc">None</span>

<span class="hll"><span class="n">receive_message</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">bcast</span><span class="p">(</span><span class="n">send_message</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> received message: </span><span class="si">{</span><span class="n">receive_message</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-3" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-3" name="0-3" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
<span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

<span class="c1"># Use gather to send all messages to rank 0</span>
<span class="n">send_message</span> <span class="o">=</span> <span class="s2">&quot;Hello World, I&#39;m rank </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
<span class="hll"><span class="n">receive_message</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">send_message</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_ranks</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">receive_message</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-4" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-4" name="0-4" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">sendbuf</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
        <span class="n">sendbuf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Hello World from rank 0 to rank </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">sendbuf</span> <span class="o">=</span> <span class="kc">None</span>

<span class="hll"><span class="n">recvbuf</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sendbuf</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> received message: </span><span class="si">{</span><span class="n">recvbuf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div><p>MPI excels for problems which can be divided up into some sort of subdomains and
communication is required between the subdomains between e.g. timesteps or iterations.
The word-count problem is simpler than that and MPI is somewhat overkill, but in an exercise
below you will learn to use point-to-point communication to parallelize it.</p>
</div>
<p>In addition to the lower-case methods <code class="xref py py-meth docutils literal notranslate"><span class="pre">send()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">recv()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">broadcast()</span></code> etc., there
are also <em>upper-case</em> methods <code class="xref py py-meth docutils literal notranslate"><span class="pre">Send()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Recv()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Broadcast()</span></code>. These work with
<em>buffer-like</em> objects (including strings and NumPy arrays) which have known memory location and size.
Upper-case methods are faster and are strongly recommended for large numeric data.</p>
</section>
</section>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-compute-numerical-integrals exercise important admonition" id="exercise-0">
<p class="admonition-title">Compute numerical integrals</p>
<p>The primary objective of this exercise is to compute integrals <span class="math notranslate nohighlight">\(\int_0^1 x^{3/2} \, dx\)</span> numerically.</p>
</div>
<p>One approach to integration is by establishing a grid along the x-axis. Specifically, the integration range
is divided into ‘n’ segments or bins. Below is a basic serial code.</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># Grid size</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100000000</span>

<span class="k">def</span><span class="w"> </span><span class="nf">integration_serial</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">mysum</span> <span class="o">=</span> <span class="mf">0.0</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">mysum</span> <span class="o">+=</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">h</span> <span class="o">*</span> <span class="n">mysum</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">starttime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">integral</span> <span class="o">=</span> <span class="n">integration_serial</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">endtime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Integral value is </span><span class="si">%e</span><span class="s2">, Error is </span><span class="si">%e</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">integral</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">integral</span> <span class="o">-</span> <span class="mi">2</span><span class="o">/</span><span class="mi">5</span><span class="p">)))</span>  <span class="c1"># The correct integral value is 2/5</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time spent: </span><span class="si">%.2f</span><span class="s2"> sec&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">endtime</span><span class="o">-</span><span class="n">starttime</span><span class="p">))</span>

<span class="c1"># 13.63 sec</span>
</pre></div>
</div>
<p>Think about how to parallelize the code using multithreading and multiprocessing.</p>
<div class="admonition-full-source-code solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Full source code</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">concurrent.futures</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># Grid size</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100000000</span>
<span class="c1"># Number of threads</span>
<span class="n">numthreads</span> <span class="o">=</span> <span class="mi">4</span>

<span class="k">def</span><span class="w"> </span><span class="nf">integration_concurrent</span><span class="p">(</span><span class="n">threadindex</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">numthreads</span><span class="o">=</span><span class="n">numthreads</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>  
    <span class="n">mysum</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">workload</span> <span class="o">=</span> <span class="n">n</span><span class="o">/</span><span class="n">numthreads</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">workload</span><span class="o">*</span><span class="n">threadindex</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">workload</span><span class="o">*</span><span class="p">(</span><span class="n">threadindex</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">mysum</span> <span class="o">+=</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">h</span> <span class="o">*</span> <span class="n">mysum</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">numthreads</span><span class="si">}</span><span class="s2"> threads&quot;</span><span class="p">)</span>
    <span class="n">starttime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="n">numthreads</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
        <span class="n">partial_integrals</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">integration_concurrent</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">numthreads</span><span class="p">)))</span>

    <span class="n">integral</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">partial_integrals</span><span class="p">)</span>
    <span class="n">endtime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Integral value is </span><span class="si">%e</span><span class="s2">, Error is </span><span class="si">%e</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">integral</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">integral</span> <span class="o">-</span> <span class="mi">2</span><span class="o">/</span><span class="mi">5</span><span class="p">)))</span>  <span class="c1"># The correct integral value is 2/5</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time spent: </span><span class="si">%.2f</span><span class="s2"> sec&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">endtime</span><span class="o">-</span><span class="n">starttime</span><span class="p">))</span>


<span class="c1"># 50.17 sec </span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># Grid size</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100000000</span>
<span class="n">nprocs</span> <span class="o">=</span> <span class="mi">4</span>

<span class="k">def</span><span class="w"> </span><span class="nf">integration_process</span><span class="p">(</span><span class="n">pool_index</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">numprocesses</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>  
    <span class="n">mysum</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">workload</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="n">numprocesses</span>

    <span class="n">begin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">workload</span> <span class="o">*</span> <span class="n">pool_index</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">workload</span> <span class="o">*</span> <span class="p">(</span><span class="n">pool_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">mysum</span> <span class="o">+=</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">h</span> <span class="o">*</span> <span class="n">mysum</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">nprocs</span><span class="si">}</span><span class="s2"> processes&quot;</span><span class="p">)</span>

    <span class="n">starttime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">nprocs</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
        <span class="n">partial_integrals</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">starmap</span><span class="p">(</span><span class="n">integration_process</span><span class="p">,</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">nprocs</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nprocs</span><span class="p">)])</span>

    <span class="n">integral</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">partial_integrals</span><span class="p">)</span>
    <span class="n">endtime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Integral value is </span><span class="si">%e</span><span class="s2">, Error is </span><span class="si">%e</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">integral</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">integral</span> <span class="o">-</span> <span class="mi">2</span><span class="o">/</span><span class="mi">5</span><span class="p">)))</span>  <span class="c1"># The correct integral value is 2/5</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time spent: </span><span class="si">%.2f</span><span class="s2"> sec&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">endtime</span> <span class="o">-</span> <span class="n">starttime</span><span class="p">))</span>

<span class="c1"># 3.53 sec</span>
</pre></div>
</div>
</div>
</div></blockquote>
<div class="admonition-word-autocorrelation-example-project exercise important admonition" id="exercise-1">
<p class="admonition-title">Word-autocorrelation example project</p>
<p>Inspired by a study of <a class="reference external" href="https://www.scirp.org/journal/paperinformation.aspx?paperid=92643">dynamic correlations of words in written text</a>,
we decide to investigate autocorrelations (ACFs) of words in our database of book texts
in the <a class="reference external" href="https://github.com/enccs/word-count-hpda">word-count project</a>.
Many of the exercises below are based on working with the following
word-autocorrelation code, so let us get familiar with it.</p>
<div class="admonition-full-source-code solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Full source code</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">wordcount</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_word_counts</span><span class="p">,</span> <span class="n">load_text</span><span class="p">,</span> <span class="n">DELIMITERS</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">def</span><span class="w"> </span><span class="nf">preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Remove delimiters, split lines into words and remove whitespaces, </span>
<span class="sd">    and make lowercase. Return list of all words in the text.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">clean_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">purge</span> <span class="ow">in</span> <span class="n">DELIMITERS</span><span class="p">:</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">purge</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>    
        <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">clean_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">clean_text</span>

<span class="k">def</span><span class="w"> </span><span class="nf">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate word-autocorrelation function for given word </span>
<span class="sd">    in a text. Each word in the text corresponds to one &quot;timestep&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">==</span><span class="n">word</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
    <span class="n">nwords_chosen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">nwords_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nwords_total</span><span class="o">-</span><span class="n">t</span><span class="p">):</span>
            <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">t</span><span class="p">]</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">/=</span> <span class="n">nwords_chosen</span>      
    <span class="k">return</span> <span class="n">acf</span>
    
<span class="k">def</span><span class="w"> </span><span class="nf">ave_word_acf</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate an average word-autocorrelation function </span>
<span class="sd">    for a list of words in a text.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">acf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="n">nwords</span> <span class="o">=</span> <span class="mi">16</span><span class="p">):</span>
    <span class="c1"># load book text and preprocess it</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">load_text</span><span class="p">(</span><span class="n">book</span><span class="p">)</span>
    <span class="n">clean_text</span> <span class="o">=</span> <span class="n">preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="c1"># load precomputed word counts and select top words</span>
    <span class="n">word_count</span> <span class="o">=</span> <span class="n">load_word_counts</span><span class="p">(</span><span class="n">wc_book</span><span class="p">)</span>
    <span class="n">top_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_count</span><span class="p">[:</span><span class="n">nwords</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">clean_text</span><span class="p">,</span> <span class="n">top_words</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">book</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">wc_book</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>    

    <span class="n">nwords</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">timesteps</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">clean_text</span><span class="p">,</span> <span class="n">top_words</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="n">nwords</span><span class="p">)</span>

    <span class="c1"># compute average autocorrelation and time the execution</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">acf_ave</span> <span class="o">=</span> <span class="n">ave_word_acf</span><span class="p">(</span><span class="n">top_words</span><span class="p">,</span> <span class="n">clean_text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>        

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;serial time: </span><span class="si">{</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">101</span><span class="p">),</span> <span class="n">acf_ave</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>The script takes three command-line arguments: the path of a datafile (book text),
the path to the processed word-count file, and the output filename for the
computed autocorrelation function.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">__main__</span></code> block calls the <code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code> function to preprocess the text
(remove delimiters etc.) and load the pre-computed word-count results.</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">word_acf()</span></code> computes the word ACF in a text for a given word using simple
for-loops (you will learn to speed it up later).</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">ave_word_acf()</span></code> loops over a list of words and computes their average ACF.</p></li>
</ul>
<p>To run this code for one book e.g. <em>pg99.txt</em>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/word-count-hpda.git
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>word-count-hpda
<span class="gp">$ </span>python<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/pg99.txt<span class="w"> </span>processed_data/pg99.dat
<span class="gp">$ </span>python<span class="w"> </span>source/autocorrelation.py<span class="w"> </span>data/pg99.txt<span class="w"> </span>processed_data/pg99.dat<span class="w"> </span>results/acf_pg99.dat
</pre></div>
</div>
<p>It will print out the time it took to calculate the ACF.</p>
</div>
<div class="admonition-parallelize-word-autocorrelation-code-with-multiprocessing exercise important admonition" id="exercise-2">
<p class="admonition-title">Parallelize word-autocorrelation code with multiprocessing</p>
<p>A serial version of the code is available in the
<a class="reference external" href="https://github.com/ENCCS/word-count-hpda/blob/main/source/autocorrelation.py">source/autocorrelation.py</a>
script in the word-count repository. The full script can be viewed above,
but we focus on the <code class="xref py py-meth docutils literal notranslate"><span class="pre">word_acf()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">ave_word_acf()</span></code> functions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate word-autocorrelation function for given word </span>
<span class="sd">    in a text. Each word in the text corresponds to one &quot;timestep&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">==</span><span class="n">word</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
    <span class="n">nwords_chosen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">nwords_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nwords_total</span><span class="o">-</span><span class="n">t</span><span class="p">):</span>
            <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">t</span><span class="p">]</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">/=</span> <span class="n">nwords_chosen</span>      
    <span class="k">return</span> <span class="n">acf</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">ave_word_acf</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate an average word-autocorrelation function </span>
<span class="sd">    for a list of words in a text.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">acf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Think about what this code is doing and try to find a good place to parallelize it using
a pool of processes.</p></li>
<li><p>With or without having a look at the hints below, try to parallelize
the code using <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> and use <code class="xref py py-meth docutils literal notranslate"><span class="pre">time.time()</span></code> to measure the speedup when running
it for one book.</p></li>
<li><p><strong>Note</strong>: You will not be able to use Jupyter for this task due to the above-mentioned limitation of <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code>.</p></li>
</ul>
<div class="admonition-hints solution important dropdown admonition" id="solution-2">
<p class="admonition-title">Hints</p>
<p>The most time-consuming parts of this code is the double-loop inside
<code class="xref py py-meth docutils literal notranslate"><span class="pre">word_acf()</span></code> (you can confirm this in an exercise in the next episode).
This function is called 16 times in the <code class="xref py py-meth docutils literal notranslate"><span class="pre">ave_word_acf()</span></code>
function, once for each word in the top-16 list. This looks like a perfect place to use a multiprocessing
pool of processes!</p>
<p>We would like to do something like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">word_autocorr</span><span class="p">,</span> <span class="n">words</span><span class="p">)</span>
</pre></div>
</div>
<p>However, there’s an issue with this because <code class="xref py py-meth docutils literal notranslate"><span class="pre">word_acf()</span></code> takes 3 arguments <code class="docutils literal notranslate"><span class="pre">(word,</span> <span class="pre">text,</span> <span class="pre">timesteps)</span></code>.
We could solve this using the <code class="xref py py-meth docutils literal notranslate"><span class="pre">Pool.starmap()</span></code> function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">starmap</span><span class="p">(</span><span class="n">word_acf</span><span class="p">,</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="mi">10</span><span class="o">*</span><span class="p">[</span><span class="n">text</span><span class="p">],</span> <span class="mi">10</span><span class="o">*</span><span class="p">[</span><span class="n">timestep</span><span class="p">])]</span>
</pre></div>
</div>
<p>But this might be somewhat inefficient because <code class="docutils literal notranslate"><span class="pre">10*[text]</span></code> might take up quite a lot of memory.
One workaround is to use the <code class="docutils literal notranslate"><span class="pre">partial</span></code> method from <code class="docutils literal notranslate"><span class="pre">functools</span></code> which returns a new function with
partial application of the given arguments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="n">word_acf_partial</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">word_autocorr</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">)</span>
<span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">word_acf_partial</span><span class="p">,</span> <span class="n">words</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-3">
<p class="admonition-title">Solution</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">wordcount</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_word_counts</span><span class="p">,</span> <span class="n">load_text</span><span class="p">,</span> <span class="n">DELIMITERS</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pool</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>

<span class="k">def</span><span class="w"> </span><span class="nf">preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Remove delimiters, split lines into words and remove whitespaces, </span>
<span class="sd">    and make lowercase. Return list of all words in the text.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">clean_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">purge</span> <span class="ow">in</span> <span class="n">DELIMITERS</span><span class="p">:</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">purge</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>    
        <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">clean_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">clean_text</span>

<span class="k">def</span><span class="w"> </span><span class="nf">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate word-autocorrelation function for given word </span>
<span class="sd">    in a text. Each word in the text corresponds to one &quot;timestep&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">==</span><span class="n">word</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
    <span class="n">nwords_chosen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">nwords_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nwords_total</span><span class="o">-</span><span class="n">t</span><span class="p">):</span>
            <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">t</span><span class="p">]</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">/=</span> <span class="n">nwords_chosen</span>      
    <span class="k">return</span> <span class="n">acf</span>
    
<span class="k">def</span><span class="w"> </span><span class="nf">ave_word_acf</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate an average word-autocorrelation function </span>
<span class="sd">    for a list of words in a text.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">acf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">ave_word_acf_pool</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">nproc</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate an average word-autocorrelation function </span>
<span class="sd">    for a list of words in a text using multiprocessing.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">word_acf_partial</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">word_acf</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="n">nproc</span><span class="p">)</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">word_acf_partial</span><span class="p">,</span> <span class="n">words</span><span class="p">)</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">acf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="n">nwords</span> <span class="o">=</span> <span class="mi">16</span><span class="p">):</span>
    <span class="c1"># load book text and preprocess it</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">load_text</span><span class="p">(</span><span class="n">book</span><span class="p">)</span>
    <span class="n">clean_text</span> <span class="o">=</span> <span class="n">preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="c1"># load precomputed word counts and select top words</span>
    <span class="n">word_count</span> <span class="o">=</span> <span class="n">load_word_counts</span><span class="p">(</span><span class="n">wc_book</span><span class="p">)</span>
    <span class="n">top_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_count</span><span class="p">[:</span><span class="n">nwords</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">clean_text</span><span class="p">,</span> <span class="n">top_words</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>

    <span class="n">book</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">wc_book</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>    

    <span class="n">nwords</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">timesteps</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">clean_text</span><span class="p">,</span> <span class="n">top_words</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="n">nwords</span><span class="p">)</span>

    <span class="c1"># compute average autocorrelation and time the execution</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">acf_ave</span> <span class="o">=</span> <span class="n">ave_word_acf</span><span class="p">(</span><span class="n">top_words</span><span class="p">,</span> <span class="n">clean_text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>        
    <span class="n">nproc</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">acf_pool_ave</span> <span class="o">=</span> <span class="n">ave_word_acf_pool</span><span class="p">(</span><span class="n">top_words</span><span class="p">,</span> <span class="n">clean_text</span><span class="p">,</span> <span class="n">nproc</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
    <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>        

    <span class="c1"># assert that multiprocessing solution gives correct results</span>
    <span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_equal</span><span class="p">(</span><span class="n">acf_ave</span><span class="p">,</span> <span class="n">acf_pool_ave</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;serial time: </span><span class="si">{</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;parallel map time: </span><span class="si">{</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">101</span><span class="p">),</span> <span class="n">acf_ave</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-write-an-mpi-version-of-word-autocorrelation exercise important admonition" id="exercise-3">
<p class="admonition-title">Write an MPI version of word-autocorrelation</p>
<p>Just like with <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code>, the most natural MPI solution parallelizes over
the words used to compute the word-autocorrelation.
For educational purposes, both point-to-point and collective communication
implementations will be demonstrated here.</p>
<p>Start by importing mpi4py (<code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">mpi4py</span> <span class="pre">import</span> <span class="pre">MPI</span></code>) at the top of the script.</p>
<p>Here is a new function which takes care of managing MPI tasks.
The problem needs to be split up between <code class="docutils literal notranslate"><span class="pre">N</span></code> ranks, and the method needs to be general
enough to handle cases where the number of words is not a multiple of the number of ranks.
Below we see a standard algorithm to accomplish this. The function also calls
two functions which implement point-to-point and collective communication, respectively, to collect
individual results to one rank which computes the average</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mpi_acf</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="n">nwords</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> <span class="n">timesteps</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
    <span class="c1"># initialize MPI</span>
    <span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
    <span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

    <span class="c1"># load book text and preprocess it</span>
    <span class="n">clean_text</span><span class="p">,</span> <span class="n">top_words</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="n">nwords</span><span class="p">)</span>
    
    <span class="c1"># distribute words among MPI tasks</span>
<span class="hll">    <span class="n">count</span> <span class="o">=</span> <span class="n">nwords</span> <span class="o">//</span> <span class="n">n_ranks</span>
</span><span class="hll">    <span class="n">remainder</span> <span class="o">=</span> <span class="n">nwords</span> <span class="o">%</span> <span class="n">n_ranks</span>
</span>    <span class="c1"># first &#39;remainder&#39; ranks get &#39;count + 1&#39; tasks each</span>
<span class="hll">    <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">remainder</span><span class="p">:</span>
</span><span class="hll">        <span class="n">first</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">*</span> <span class="p">(</span><span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span class="hll">        <span class="n">last</span> <span class="o">=</span> <span class="n">first</span> <span class="o">+</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>
</span>    <span class="c1"># remaining &#39;nwords - remainder&#39; ranks get &#39;count&#39; task each</span>
<span class="hll">    <span class="k">else</span><span class="p">:</span>
</span><span class="hll">        <span class="n">first</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">*</span> <span class="n">count</span> <span class="o">+</span> <span class="n">remainder</span>
</span><span class="hll">        <span class="n">last</span> <span class="o">=</span> <span class="n">first</span> <span class="o">+</span> <span class="n">count</span> 
</span>    <span class="c1"># each rank gets unique words</span>
    <span class="n">my_words</span> <span class="o">=</span> <span class="n">top_words</span><span class="p">[</span><span class="n">first</span><span class="p">:</span><span class="n">last</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;My rank number is </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> and first, last = </span><span class="si">{</span><span class="n">first</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">last</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># use collective function</span>
    <span class="n">acf_tot</span> <span class="o">=</span> <span class="n">ave_word_acf_gather</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="n">my_words</span><span class="p">,</span> <span class="n">clean_text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>

    <span class="c1"># use p2p function</span>
    <span class="c1">#acf_tot = ave_word_acf_p2p(comm, my_words, clean_text, timesteps)</span>

    <span class="c1"># only rank 0 has the averaged data</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">acf_tot</span> <span class="o">/</span> <span class="n">nwords</span>
</pre></div>
</div>
<div class="admonition-what-type-of-communication-can-we-use discussion important admonition" id="discussion-0">
<p class="admonition-title">What type of communication can we use?</p>
<p>The end result should be an average of all the word-autocorrelation functions.
What type of communication can be used to collect the results on one rank which
computes the average and prints it to file?</p>
</div>
<p>Study the two “faded” MPI function implementations below, one using point-to-point communication and the other using
collective communication. Try to figure out what you should replace the <code class="docutils literal notranslate"><span class="pre">____</span></code> with.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">Point-to-point</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">Collective</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">ave_word_acf_p2p</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="n">my_words</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
    <span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>
    <span class="c1"># each rank computes its own set of acfs</span>
    <span class="n">my_acfs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">____</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_words</span><span class="p">):</span>
        <span class="n">my_acfs</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">____</span> <span class="o">==</span> <span class="n">____</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># append own results</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">my_acfs</span><span class="p">)</span>
        <span class="c1"># receive data from other ranks and append to results</span>
        <span class="k">for</span> <span class="n">sender</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">____</span><span class="p">):</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">comm</span><span class="o">.</span><span class="n">____</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">sender</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">12</span><span class="p">))</span>
        <span class="c1"># compute total</span>
        <span class="n">acf_tot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">____</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                <span class="n">acf_tot</span> <span class="o">+=</span> <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">acf_tot</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># send data</span>
        <span class="n">comm</span><span class="o">.</span><span class="n">____</span><span class="p">(</span><span class="n">my_acfs</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="n">____</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">ave_word_acf_gather</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="n">my_words</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
    <span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>
    <span class="c1"># each rank computes its own set of acfs</span>
    <span class="n">my_acfs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">____</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_words</span><span class="p">):</span>
        <span class="n">my_acfs</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>

    <span class="c1"># gather results on rank 0</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">____</span><span class="p">(</span><span class="n">____</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># loop over ranks and results. result is a list of lists of ACFs</span>
    <span class="k">if</span> <span class="n">____</span> <span class="o">==</span> <span class="n">____</span><span class="p">:</span>
        <span class="n">acf_tot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_ranks</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                <span class="n">acf_tot</span> <span class="o">+=</span> <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">acf_tot</span>
</pre></div>
</div>
</div></div>
<p>After implementing one or both of these functions, run your code and time the result for different number of tasks!</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">time</span><span class="w"> </span>mpirun<span class="w"> </span>-np<span class="w"> </span>&lt;N&gt;<span class="w"> </span>python<span class="w"> </span>source/autocorrelation.py<span class="w"> </span>data/pg58.txt<span class="w"> </span>processed_data/pg58.dat<span class="w"> </span>results/pg58_acf.csv
</pre></div>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-4">
<p class="admonition-title">Solution</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">wordcount</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_word_counts</span><span class="p">,</span> <span class="n">load_text</span><span class="p">,</span> <span class="n">DELIMITERS</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>


<span class="k">def</span><span class="w"> </span><span class="nf">preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Remove delimiters, split lines into words and remove whitespaces, </span>
<span class="sd">    and make lowercase. Return list of all words in the text.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">clean_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">purge</span> <span class="ow">in</span> <span class="n">DELIMITERS</span><span class="p">:</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">purge</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>    
        <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">clean_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">clean_text</span>

<span class="k">def</span><span class="w"> </span><span class="nf">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate word-autocorrelation function for given word </span>
<span class="sd">    in a text. Each word in the text corresponds to one &quot;timestep&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">==</span><span class="n">word</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
    <span class="n">nwords_chosen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">nwords_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nwords_total</span><span class="o">-</span><span class="n">t</span><span class="p">):</span>
            <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">t</span><span class="p">]</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">/=</span> <span class="n">nwords_chosen</span>      
    <span class="k">return</span> <span class="n">acf</span>
    
<span class="k">def</span><span class="w"> </span><span class="nf">ave_word_acf</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate an average word-autocorrelation function </span>
<span class="sd">    for a list of words in a text.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">acf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">ave_word_acf_p2p</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="n">my_words</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
    <span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>
    <span class="c1"># each rank computes its own set of acfs</span>
    <span class="n">my_acfs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">my_words</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_words</span><span class="p">):</span>
        <span class="n">my_acfs</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># append own results</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">my_acfs</span><span class="p">)</span>
        <span class="c1"># receive data from other ranks and append to results</span>
        <span class="k">for</span> <span class="n">sender</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_ranks</span><span class="p">):</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">sender</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">12</span><span class="p">))</span>
        <span class="c1"># compute total </span>
        <span class="n">acf_tot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_ranks</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                <span class="n">acf_tot</span> <span class="o">+=</span> <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">acf_tot</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># send data</span>
        <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">my_acfs</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">ave_word_acf_gather</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="n">my_words</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
    <span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span> 
    <span class="c1"># each rank computes its own set of acfs</span>
    <span class="n">my_acfs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">my_words</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_words</span><span class="p">):</span>
        <span class="n">my_acfs</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>

    <span class="c1"># gather results on rank 0</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">my_acfs</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># loop over ranks and results. result is a list of lists of ACFs</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">acf_tot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_ranks</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                <span class="n">acf_tot</span> <span class="o">+=</span> <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">acf_tot</span>

<span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="n">nwords</span> <span class="o">=</span> <span class="mi">16</span><span class="p">):</span>
    <span class="c1"># load book text and preprocess it</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">load_text</span><span class="p">(</span><span class="n">book</span><span class="p">)</span>
    <span class="n">clean_text</span> <span class="o">=</span> <span class="n">preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="c1"># load precomputed word counts and select top words</span>
    <span class="n">word_count</span> <span class="o">=</span> <span class="n">load_word_counts</span><span class="p">(</span><span class="n">wc_book</span><span class="p">)</span>
    <span class="n">top_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_count</span><span class="p">[:</span><span class="n">nwords</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">clean_text</span><span class="p">,</span> <span class="n">top_words</span>

<span class="k">def</span><span class="w"> </span><span class="nf">mpi_acf</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="n">nwords</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> <span class="n">timesteps</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
    <span class="c1"># initialize MPI</span>
    <span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
    <span class="n">n_ranks</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

    <span class="c1"># load book text and preprocess it</span>
    <span class="n">clean_text</span><span class="p">,</span> <span class="n">top_words</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="n">nwords</span><span class="p">)</span>
    
    <span class="c1"># distribute words among MPI tasks</span>
    <span class="n">count</span> <span class="o">=</span> <span class="n">nwords</span> <span class="o">//</span> <span class="n">n_ranks</span>
    <span class="n">remainder</span> <span class="o">=</span> <span class="n">nwords</span> <span class="o">%</span> <span class="n">n_ranks</span>
    <span class="c1"># first &#39;remainder&#39; ranks get &#39;count + 1&#39; tasks each</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">remainder</span><span class="p">:</span>
        <span class="n">first</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">*</span> <span class="p">(</span><span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">last</span> <span class="o">=</span> <span class="n">first</span> <span class="o">+</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="c1"># remaining &#39;nwords - remainder&#39; ranks get &#39;count&#39; task each</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">first</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">*</span> <span class="n">count</span> <span class="o">+</span> <span class="n">remainder</span>
        <span class="n">last</span> <span class="o">=</span> <span class="n">first</span> <span class="o">+</span> <span class="n">count</span> 
    <span class="c1"># each rank gets unique words</span>
    <span class="n">my_words</span> <span class="o">=</span> <span class="n">top_words</span><span class="p">[</span><span class="n">first</span><span class="p">:</span><span class="n">last</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;My rank number is </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> and first, last = </span><span class="si">{</span><span class="n">first</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">last</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># use collective function</span>
    <span class="n">acf_tot</span> <span class="o">=</span> <span class="n">ave_word_acf_gather</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="n">my_words</span><span class="p">,</span> <span class="n">clean_text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>

    <span class="c1"># use p2p function</span>
    <span class="c1">#acf_tot = ave_word_acf_p2p(comm, my_words, clean_text, timesteps)</span>

    <span class="c1"># only rank 0 has the averaged data</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">acf_tot</span> <span class="o">/</span> <span class="n">nwords</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1"># load book text and preprocess it</span>
    <span class="n">book</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">wc_book</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>    
    <span class="n">acf</span> <span class="o">=</span> <span class="n">mpi_acf</span><span class="p">(</span><span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

    <span class="n">rank</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">nsteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">acf</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nsteps</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">acf</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="see-also">
<span id="id2"></span><h3>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://wiki.python.org/moin/GlobalInterpreterLock">More on the global interpreter lock</a></p></li>
<li><p><a class="reference external" href="https://realpython.com/python-concurrency/">RealPython concurrency overview</a></p></li>
<li><p><a class="reference external" href="https://realpython.com/intro-to-python-threading/">RealPython threading tutorial</a></p></li>
<li><p>Parallel programming in Python with multiprocessing,
<a class="reference external" href="https://www.kth.se/blogs/pdc/2019/02/parallel-programming-in-python-multiprocessing-part-1/">part 1</a>
and <a class="reference external" href="https://www.kth.se/blogs/pdc/2019/03/parallel-programming-in-python-multiprocessing-part-2/">part 2</a></p></li>
<li><p>Parallel programming in Python with mpi4py, <a class="reference external" href="https://www.kth.se/blogs/pdc/2019/08/parallel-programming-in-python-mpi4py-part-1/">part 1</a>
and <a class="reference external" href="https://www.kth.se/blogs/pdc/2019/11/parallel-programming-in-python-mpi4py-part-2/">part 2</a></p></li>
<li><p><a class="reference external" href="https://ipyparallel.readthedocs.io/en/latest/">ipyparallel documentation</a></p></li>
<li><p><a class="reference external" href="https://blog.jupyter.org/ipython-parallel-in-2021-2945985c032a">IPython Parallel in 2021</a></p></li>
<li><p><a class="reference external" href="https://github.com/DaanVanHauwermeiren/ipyparallel-tutorial">ipyparallel tutorial</a></p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>1 Beaware of GIL and its impact on performance</p></li>
<li><p>2 Use threads for I/O-bound tasks</p></li>
</ul>
</div>
</section>
</section>
<span id="document-optimization"></span><section id="profiling-and-optimizing">
<span id="performance"></span><h2>Profiling and optimizing<a class="headerlink" href="#profiling-and-optimizing" title="Link to this heading"></a></h2>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Learn how to benchmark and profile Python code</p></li>
<li><p>Understand how optimization can be algorithmic or based on CPU or memory usage</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>20 min teaching/type-along</p></li>
<li><p>20 min exercises</p></li>
</ul>
</div>
<p>Once your code is working reliably, you can start thinking of optimizing it.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Always measure the code before you start optimization. Don’t base your optimization
on theoretical consideration, otherwise you’ll have surprises.</p>
</div>
<section id="profilers">
<h3>Profilers<a class="headerlink" href="#profilers" title="Link to this heading"></a></h3>
<section id="time">
<h4>time<a class="headerlink" href="#time" title="Link to this heading"></a></h4>
<p>One of the easy way to profile the program is to use the time function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="c1"># start the timer</span>
<span class="n">start_time</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="c1"># here are the code you would like to profile</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span> <span class="o">**</span> <span class="mi">2</span>
<span class="c1"># stop the timer</span>
<span class="n">end_time</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Runtime: </span><span class="si">{:.4f}</span><span class="s2"> seconds&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>
<span class="c1"># Runtime: 0.0001 seconds</span>
</pre></div>
</div>
</section>
<section id="timeit">
<h4>Timeit<a class="headerlink" href="#timeit" title="Link to this heading"></a></h4>
<p>If you’re using a Jupyter notebook, the best choice will be to use
<a class="reference external" href="https://docs.python.org/library/timeit.html">%timeit</a> to time a small piece of code:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> a ** 2
<span class="c1"># 1.4 µs ± 25.1 ns per loop</span>
</pre></div>
</div>
<p>One can also use the cell magic <code class="docutils literal notranslate"><span class="pre">%%timeit</span></code> to benchmark a full cell.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For long running calls, using <code class="docutils literal notranslate"><span class="pre">%time</span></code> instead of <code class="docutils literal notranslate"><span class="pre">%timeit</span></code>; it is
less precise but faster</p>
</div>
</section>
<section id="cprofile">
<h4>cProfile<a class="headerlink" href="#cprofile" title="Link to this heading"></a></h4>
<p>For more complex code, one can use the <a class="reference external" href="https://docs.python.org/3/library/profile.html">built-in python profilers</a>, <code class="docutils literal notranslate"><span class="pre">cProfile</span></code> or <code class="docutils literal notranslate"><span class="pre">profile</span></code>.</p>
<p>As a demo, let us consider the following code which simulates a random walk in one dimension
(we can save it as <code class="docutils literal notranslate"><span class="pre">walk.py</span></code> or download from <a class="reference download internal" download="" href="_downloads/29ba0b7fa786ae9bb9e84eb4c820c5e4/walk.py"><code class="xref download docutils literal notranslate"><span class="pre">here</span></code></a>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">():</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
    <span class="k">return</span> <span class="mf">1.</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">.5</span> <span class="k">else</span> <span class="o">-</span><span class="mf">1.</span>

<span class="k">def</span><span class="w"> </span><span class="nf">walk</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">n</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">x_new</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">dx</span> <span class="o">*</span> <span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">x_new</span> <span class="o">&gt;</span> <span class="mf">5e-3</span><span class="p">:</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_new</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">100000</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">walk</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
<p>We can profile it with <code class="docutils literal notranslate"><span class="pre">cProfile</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$  </span>python<span class="w"> </span>-m<span class="w"> </span>cProfile<span class="w"> </span>-s<span class="w"> </span><span class="nb">time</span><span class="w"> </span>walk.py
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">-s</span></code> switch sorts the results by <code class="docutils literal notranslate"><span class="pre">time</span></code>. Other options include
e.g. function name, cumulative time, etc. However, this will print a lot of
output which is difficult to read.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python<span class="w"> </span>-m<span class="w"> </span>cProfile<span class="w"> </span>-o<span class="w"> </span>walk.prof<span class="w"> </span>walk.py
</pre></div>
</div>
<p>It’s also possible to write the profile
to a file with the <code class="docutils literal notranslate"><span class="pre">-o</span></code> flag and view it with <a class="reference external" href="https://docs.python.org/3/library/profile.html#module-pstats">profile pstats module</a>
or profile visualisation tools like
<a class="reference external" href="https://jiffyclub.github.io/snakeviz/">Snakeviz</a>
or <a class="reference external" href="https://pypi.org/project/profile-viewer/">profile-viewer</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Similar functionality is available in interactive IPython or Jupyter sessions with the
magic command <a class="reference external" href="https://ipython.readthedocs.io/en/stable/interactive/magics.html">%%prun</a>.</p>
</div>
</section>
<section id="line-profiler">
<h4>Line-profiler<a class="headerlink" href="#line-profiler" title="Link to this heading"></a></h4>
<p>The cProfile tool tells us which function takes most of the time but it does not give us a
line-by-line breakdown of where time is being spent. For this information, we can use the
<a class="reference external" href="https://github.com/pyutils/line_profiler/">line_profiler</a> tool.</p>
<div class="admonition-demo-line-profiling demo admonition" id="demo-0">
<p class="admonition-title">Demo: line profiling</p>
<p>For line-profiling source files from the command line, we can add a decorator <code class="docutils literal notranslate"><span class="pre">&#64;profile</span></code>
to the functions of interests. If we do this for the <code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">walk()</span></code> function
in the example above, we can then run the script using the <cite>kernprof.py</cite> program which comes with
<code class="docutils literal notranslate"><span class="pre">line_profiler</span></code>, making sure to include the switches <code class="docutils literal notranslate"><span class="pre">-l,</span> <span class="pre">--line-by-line</span></code> and <code class="docutils literal notranslate"><span class="pre">-v,</span> <span class="pre">--view</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kernprof<span class="w"> </span>-l<span class="w"> </span>-v<span class="w"> </span>walk.py
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">line_profiler</span></code> also works in a Jupyter notebook. First one needs to load the extension:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> line_profiler
</pre></div>
</div>
<p>If the <code class="xref py py-meth docutils literal notranslate"><span class="pre">walk()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code> functions are defined in code cells, we can get the line-profiling
information by:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">lprun</span> -f walk -f step walk(10000)
</pre></div>
</div>
<ul class="simple">
<li><p>Based on the output, can you spot a mistake which is affecting performance?</p></li>
</ul>
<div class="admonition-line-profiling-output solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Line-profiling output</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Wrote profile results to walk.py.lprof</span>
<span class="go">Timer unit: 1e-06 s</span>

<span class="go">Total time: 0.113249 s</span>
<span class="go">File: walk.py</span>
<span class="go">Function: step at line 4</span>

<span class="go">Line #      Hits         Time  Per Hit   % Time  Line Contents</span>
<span class="go">==============================================================</span>
<span class="go">   4                                           @profile</span>
<span class="go">   5                                           def step():</span>
<span class="go">   6     99999      57528.0      0.6     50.8      import random</span>
<span class="go">   7     99999      55721.0      0.6     49.2      return 1. if random.random() &gt; .5 else -1.</span>

<span class="go">Total time: 0.598811 s</span>
<span class="go">File: walk.py</span>
<span class="go">Function: walk at line 9</span>

<span class="go">Line #      Hits         Time  Per Hit   % Time  Line Contents</span>
<span class="go">==============================================================</span>
<span class="go">   9                                           @profile</span>
<span class="go">   10                                           def walk(n):</span>
<span class="go">   11         1         20.0     20.0      0.0      x = np.zeros(n)</span>
<span class="go">   12         1          1.0      1.0      0.0      dx = 1. / n</span>
<span class="go">   13    100000      44279.0      0.4      7.4      for i in range(n - 1):</span>
<span class="go">   14     99999     433303.0      4.3     72.4          x_new = x[i] + dx * step()</span>
<span class="go">   15     99999      53894.0      0.5      9.0          if x_new &gt; 5e-3:</span>
<span class="go">   16                                                       x[i + 1] = 0.</span>
<span class="go">   17                                                   else:</span>
<span class="go">   18     99999      67313.0      0.7     11.2              x[i + 1] = x_new</span>
<span class="go">   19         1          1.0      1.0      0.0      return x</span>
</pre></div>
</div>
</div>
<div class="admonition-the-mistake solution important dropdown admonition" id="solution-1">
<p class="admonition-title">The mistake</p>
<p>The mistake is that the <code class="docutils literal notranslate"><span class="pre">random</span></code> module is loaded inside the <code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code> function
which is called thousands of times! Moving the module import to the top level saves
considerable time.</p>
</div>
</div>
</section>
</section>
<section id="performance-optimization">
<h3>Performance optimization<a class="headerlink" href="#performance-optimization" title="Link to this heading"></a></h3>
<p>Once we have identified the bottlenecks, we need to make the corresponding code go faster.</p>
<section id="algorithm-optimization">
<h4>Algorithm optimization<a class="headerlink" href="#algorithm-optimization" title="Link to this heading"></a></h4>
<p>The first thing to look into is the underlying algorithm you chose: is it optimal?
To answer this question, a good understanding of the maths behind the algorithm helps.
For certain algorithms, many of the bottlenecks will be linear
algebra computations. In these cases, using the right function to solve
the right problem is key. For instance, an eigenvalue problem with a
symmetric matrix is much easier to solve than with a general matrix. Moreover,
most often, you can avoid inverting a matrix and use a less costly
(and more numerically stable) operation. However, it can be as simple as
moving computation or memory allocation outside a loop, and this happens very often as well.</p>
<section id="singular-value-decomposition">
<h5>Singular Value Decomposition<a class="headerlink" href="#singular-value-decomposition" title="Link to this heading"></a></h5>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Singular_value_decomposition">Singular Value Decomposition</a> (SVD)
is quite often used in climate model data analysis.  The computational cost of this algorithm is
roughly <span class="math notranslate nohighlight">\(n^3\)</span> where  <span class="math notranslate nohighlight">\(n\)</span> is the size of the input matrix.
However, in most cases, we are not using all the output of the SVD,
but only the first few rows of its first returned argument. If
we use the <code class="docutils literal notranslate"><span class="pre">svd</span></code> implementation from SciPy, we can ask for an incomplete
version of the SVD. Note that implementations of linear algebra in
SciPy are richer then those in NumPy and should be preferred.
The following example demonstrates the performance benefit for a “slim” array
(i.e. much larger along one axis):</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">4000</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>

<span class="o">%</span><span class="k">timeit</span> np.linalg.svd(data)
<span class="c1"># 1.09 s ± 19.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">linalg</span>

<span class="o">%</span><span class="k">timeit</span> linalg.svd(data)
<span class="c1"># 1.03 s ± 24.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>

<span class="o">%</span><span class="k">timeit</span> linalg.svd(data, full_matrices=False)
<span class="c1"># 21.2 ms ± 716 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>

<span class="o">%</span><span class="k">timeit</span> np.linalg.svd(data, full_matrices=False)
<span class="c1"># 23.8 ms ± 3.06 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
</section>
<section id="the-fibonacci-sequence">
<h5>The Fibonacci sequence<a class="headerlink" href="#the-fibonacci-sequence" title="Link to this heading"></a></h5>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Fibonacci_sequence">Fibonacci sequence</a> is defined by the recurrence relatioin:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}F[0] &amp;= 0 \text{ , } F[1] =1 \\
F[n] &amp;= F[n-1] + F[n-2] \text{ for } n &gt; 1\end{split}\]</div>
</div></blockquote>
<p>The most straightforward version of the Fibonacci sequence is the one using recursion.
However, it turns out that it performs very badly. Things can be improved by using the
iterative version or the cached version.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Recursion</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">Iteration</button><button aria-controls="panel-0-0-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-2" name="0-2" role="tab" tabindex="-1">Cached version</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">fib_rec</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="k">return</span> <span class="n">fib_rec</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">fib_rec</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">fib_iter</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">a</span>
    <span class="k">return</span> <span class="n">a</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-2" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-2" name="0-2" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">fib_cached</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="p">{}):</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">fib_cached</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">fib_cached</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">cache</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>
    <span class="k">return</span> <span class="n">val</span>
</pre></div>
</div>
</div></div>
</section>
</section>
<section id="cpu-usage-optimization">
<h4>CPU usage optimization<a class="headerlink" href="#cpu-usage-optimization" title="Link to this heading"></a></h4>
<section id="vectorization">
<h5>Vectorization<a class="headerlink" href="#vectorization" title="Link to this heading"></a></h5>
<p>Arithmetic is one place where NumPy performance outperforms python list and
the reason is that it uses vectorization. A lot of the data analysis involves
a simple operation being applied to each element of a large dataset.
In such cases, vectorization is key for better performance.
In practice, a vectorised operation means reframing the code in a manner that
completely avoids a loop and instead uses e.g. slicing to apply the operation
on the whole array (slice) at one go. For example, the following code for
calculating the difference of neighbouring elements in an array:</p>
<p>Consider the following code:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">a_dif</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">999</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)):</span>
    <span class="n">a_dif</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># 564 µs ± 25.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<p>How can the <code class="docutils literal notranslate"><span class="pre">for</span></code> loop be vectorized? We need to use clever indexing to get rid of the
loop:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">a_dif</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># 2.12 µs ± 25.8 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)</span>
</pre></div>
</div>
<p>The first brute force approach using a for loop is much slower than the second vectorised form!</p>
<p>So one should consider using <em>vectorized</em> operations whenever possible, not only for
performance but also because the vectorized version can be more convenient.</p>
<p>What if we have a function that only take scalar values as input, but we want to apply it
element-by-element on an array? We can vectorize the function!
Let’s define a simple function <code class="docutils literal notranslate"><span class="pre">f</span></code> which takes scalars input:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>If we pass an array we get an error</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Traceback (most recent call last):</span>
<span class="c1">#   File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span>
<span class="c1">#   File &quot;&lt;stdin&gt;&quot;, line 2, in f</span>
<span class="c1"># TypeError: only size-1 arrays can be converted to Python scalars</span>
</pre></div>
</div>
<p>We could loop over the array:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
    <span class="n">f</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>

<span class="c1"># 49.9 ms ± 3.84 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
<p>However, in order to pass a NumPy array it is better to vectorize the function using <code class="xref py py-meth docutils literal notranslate"><span class="pre">np.vectorize()</span></code>
which takes a nested sequence of objects or NumPy arrays as inputs and returns a single
NumPy array or a tuple of NumPy arrays:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">f_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># benchmark</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> f_numpy(x,x)
<span class="c1"># 4.84 ms ± 75.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</span>
</pre></div>
</div>
<p>For high performance vectorization, another choice is to use Numba.
Adding the decorator in a function, Numba will figure out the rest for you:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">f_numba</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># benchmark</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> f_numba(x,x)

<span class="c1"># 89.2 µs ± 1.74 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)</span>
</pre></div>
</div>
<p>We will learn more about Numba in the next episode.</p>
</section>
</section>
<section id="memory-usage-optimization">
<h4>Memory usage optimization<a class="headerlink" href="#memory-usage-optimization" title="Link to this heading"></a></h4>
<section id="broadcasting">
<h5>Broadcasting<a class="headerlink" href="#broadcasting" title="Link to this heading"></a></h5>
<p>Basic operations of NumPy are elementwise, and the shape of the arrays should be compatible.
However, in practice under certain conditions, it is possible to do operations on arrays of different shapes.
NumPy expands the arrays such that the operation becomes viable.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Broadcasting Rules</p>
<ul class="simple">
<li><p>Dimensions match when they are equal, or when either is 1 or None.</p></li>
<li><p>In the latter case, the dimension of the output array is expanded to the larger of the two.</p></li>
<li><p>Broadcasted arrays are never physically constructed, which saves memory.</p></li>
</ul>
</div>
<div class="admonition-broadcasting exercise important admonition" id="exercise-0">
<p class="admonition-title">Broadcasting</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">1D</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">2D</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/bc_1d.svg" src="_images/bc_1d.svg" />
</figure>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">],[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/bc_2d_1.svg" src="_images/bc_2d_1.svg" />
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="c1"># this does not work</span>
<span class="n">a</span><span class="p">[:,</span><span class="kc">None</span><span class="p">]</span> <span class="o">+</span><span class="n">b</span>
<span class="c1"># or</span>
<span class="n">a</span><span class="p">[:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">+</span><span class="n">b</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="_images/bc_2d_2.svg" src="_images/bc_2d_2.svg" />
</figure>
</div></div>
</div>
</section>
<section id="cache-effects">
<h5>Cache effects<a class="headerlink" href="#cache-effects" title="Link to this heading"></a></h5>
<p>Memory access is cheaper when it is grouped: accessing a big array in a
continuous way is much faster than random access. This implies amongst
other things that <strong>smaller strides are faster</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>

<span class="o">%</span><span class="n">timeit</span> <span class="n">c</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># 1 loops, best of 3: 3.89 s per loop</span>

<span class="o">%</span><span class="n">timeit</span> <span class="n">c</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># 1 loops, best of 3: 188 ms per loop</span>

<span class="n">c</span><span class="o">.</span><span class="n">strides</span>
<span class="c1"># (80000, 8)</span>
</pre></div>
</div>
<p>This is the reason why Fortran ordering or C ordering may make a big
difference on operations.</p>
</section>
<section id="temporary-arrays">
<h5>Temporary arrays<a class="headerlink" href="#temporary-arrays" title="Link to this heading"></a></h5>
<ul class="simple">
<li><p>In complex expressions, NumPy stores intermediate values in
temporary arrays</p></li>
<li><p>Memory consumption can be higher than expected</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>

<span class="c1"># two temporary arrays will be created</span>
<span class="n">c</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">a</span> <span class="o">-</span> <span class="mf">4.5</span> <span class="o">*</span> <span class="n">b</span>

<span class="c1"># four temporary arrays will be created, and from which two are due to unnecessary parenthesis</span>
<span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">a</span> <span class="o">-</span> <span class="mf">4.5</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>

<span class="c1"># solution</span>
<span class="c1"># apply the operation one by one for really large arrays</span>
<span class="n">c</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">a</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">c</span> <span class="o">-</span> <span class="mf">4.5</span> <span class="o">*</span> <span class="n">b</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Broadcasting approaches can lead also to hidden temporary arrays</p>
<ul>
<li><p>Input data M x 3 array</p></li>
<li><p>Output data M x M array</p></li>
<li><p>There is a temporary M x M x 3 array</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="n">X</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">X</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="numexpr">
<h5>Numexpr<a class="headerlink" href="#numexpr" title="Link to this heading"></a></h5>
<ul>
<li><p>Evaluation of complex expressions with one operation at a time can lead
also into suboptimal performance</p>
<blockquote>
<div><ul class="simple">
<li><p>Effectively, one carries out multiple <em>for</em> loops in the NumPy C-code</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Numexpr package provides fast evaluation of array expressions</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numexpr</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ne</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">10000000</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">10000000</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="o">%</span><span class="k">timeit</span> y = ((.25*x + .75)*x - 1.5)*x - 2
<span class="o">%</span><span class="k">timeit</span> y = ne.evaluate(&quot;((.25*x + .75)*x - 1.5)*x - 2&quot;)
</pre></div>
</div>
<ul class="simple">
<li><p>By default, Numexpr tries to use multiple threads</p></li>
<li><p>Number of threads can be queried and set with
<code class="docutils literal notranslate"><span class="pre">numexpr.set_num_threads(nthreads)</span></code></p></li>
<li><p>Supported operators and functions:
+,-,*,/,**, sin, cos, tan, exp, log, sqrt</p></li>
<li><p>Speedups in comparison to NumPy are typically between 0.95 and 4</p></li>
<li><p>Works best on arrays that do not fit in CPU cache</p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Measure and benchmark before you start optimizing</p></li>
<li><p>Optimization can be to change algorithms, optimize memory usage or add
vectorization, or to convert performance-critical functions to Numba or Cython</p></li>
</ul>
</div>
</section>
</section>
</section>
</section>
<span id="document-performance-boosting"></span><section id="performance-boosting">
<span id="boosting"></span><h2>Performance boosting<a class="headerlink" href="#performance-boosting" title="Link to this heading"></a></h2>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Learn how to boost performance using Numba and Cython</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>20 min teaching/type-along</p></li>
<li><p>20 min exercises</p></li>
</ul>
</div>
<p>After benchmarking and optimizing your code, you can start thinking of accelerating
it further with libraries like Cython and Numba to pre-compile performance-critical functions.</p>
<section id="pre-compiling-python">
<h3>Pre-compiling Python<a class="headerlink" href="#pre-compiling-python" title="Link to this heading"></a></h3>
<p>For many (or most) use cases, using NumPy or Pandas is sufficient. However, in some computationally heavy applications,
it is possible to improve the performance by pre-compiling expensive functions.
<a class="reference external" href="https://cython.org/">Cython</a> and <a class="reference external" href="https://numba.pydata.org/">Numba</a>
are among the popular choices and both of them have good support for NumPy arrays.</p>
<section id="cython">
<h4>Cython<a class="headerlink" href="#cython" title="Link to this heading"></a></h4>
<p>Cython is a superset of Python that additionally supports calling C functions and
declaring C types on variables and class attributes. Under Cython, source code gets
translated into optimized C/C++ code and compiled as Python extension modules.</p>
<p>Developers can run the <code class="docutils literal notranslate"><span class="pre">cython</span></code> command-line utility to produce a <code class="docutils literal notranslate"><span class="pre">.c</span></code> file from
a <code class="docutils literal notranslate"><span class="pre">.py</span></code> file which needs to be compiled with a C compiler to an <code class="docutils literal notranslate"><span class="pre">.so</span></code> library
which can then be directly imported in a Python program. There is, however, also an easy
way to use Cython directly from Jupyter notebooks through the <code class="docutils literal notranslate"><span class="pre">%%cython</span></code> magic
command. We will restrict the discussion here to the Jupyter-way. For a full overview
of the capabilities refer to the <a class="reference external" href="https://cython.readthedocs.io/en/latest/">documentation</a>.</p>
<div class="admonition-demo-cython demo admonition" id="demo-0">
<p class="admonition-title">Demo: Cython</p>
<p>Consider the following pure Python code which integrates a function:</p>
<div class="math notranslate nohighlight">
\[\int^{b}_{a}(x^2-x)dx\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="k">def</span><span class="w"> </span><span class="nf">integrate_f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f</span><span class="p">(</span><span class="n">col_a</span><span class="p">,</span> <span class="n">col_b</span><span class="p">,</span> <span class="n">col_N</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div>
<p>We generate a dataframe and apply the <code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_integrate_f()</span></code> function on its columns, timing the execution:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span>
                  <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span>
                  <span class="s2">&quot;N&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="p">(</span><span class="mi">1000</span><span class="p">))})</span>

<span class="o">%</span><span class="k">timeit</span> apply_integrate_f(df[&#39;a&#39;], df[&#39;b&#39;], df[&#39;N&#39;])
<span class="c1"># 321 ms ± 10.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<p>In order to use Cython, we need to import the Cython extension:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> cython
</pre></div>
</div>
<p>As a first cythonization step we add the cython magic command with the
<code class="docutils literal notranslate"><span class="pre">-a,</span> <span class="pre">--annotate</span></code> flag, <code class="docutils literal notranslate"><span class="pre">%%cython</span> <span class="pre">-a</span></code>, to the top of the Jupyter code cell.
The yellow coloring in the output shows us the amount of pure Python:</p>
<figure class="align-default">
<img alt="_images/cython_annotate.png" src="_images/cython_annotate.png" />
</figure>
<p>Our task is to remove as much yellow as possible by <em>static typing</em>, i.e. explicitly declaring arguments, parameters, variables and functions.
We can start by simply compiling the code using Cython without any changes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f_cython</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_cython</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_cython</span><span class="p">(</span><span class="n">col_a</span><span class="p">,</span> <span class="n">col_b</span><span class="p">,</span> <span class="n">col_N</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> apply_integrate_f_cython(df[&#39;a&#39;], df[&#39;b&#39;], df[&#39;N&#39;])
<span class="c1"># 276 ms ± 20.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<p>Simply by using Cython and a copy-and-paste gives us about 10% increase in performance.</p>
<p>Now we can start adding data type annotation to the input variables:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">f_cython_dtype0</span><span class="p">(</span><span class="n">double</span> <span class="n">x</span><span class="p">):</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_cython_dtype0</span><span class="p">(</span><span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">b</span><span class="p">,</span> <span class="n">long</span> <span class="n">N</span><span class="p">):</span>   
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_dtype0</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_cython_dtype0</span><span class="p">(</span><span class="n">double</span><span class="p">[:]</span> <span class="n">col_a</span><span class="p">,</span> <span class="n">double</span><span class="p">[:]</span> <span class="n">col_b</span><span class="p">,</span> <span class="n">long</span><span class="p">[:]</span> <span class="n">col_N</span><span class="p">):</span>  
</span>    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_dtype0</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="c1"># this will not work</span>
<span class="c1">#%timeit apply_integrate_f_cython_dtype0(df[&#39;a&#39;], df[&#39;b&#39;], df[&#39;N&#39;])</span>
<span class="c1"># but rather</span>
<span class="o">%</span><span class="k">timeit</span> apply_integrate_f_cython_dtype0(df[&#39;a&#39;].to_numpy(), df[&#39;b&#39;].to_numpy(), df[&#39;N&#39;].to_numpy())
<span class="c1"># 41.4 ms ± 1.27 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You can not pass a Series directly since the Cython definition is specific to an array.
Instead using the <code class="docutils literal notranslate"><span class="pre">Series.to_numpy()</span></code> to get the underlying NumPy array
which works nicely with Cython.</p>
<p>Cython uses the normal C syntax for types and provides all standard ones, including pointers.
Here is a list of a few examples:</p>
<blockquote>
<div><table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>NumPy dtype</p></td>
<td><p>Cython type identifier</p></td>
<td><p>C type identifier</p></td>
</tr>
<tr class="row-even"><td><p>import numpy as np</p></td>
<td><p>cimport numpy as cnp</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a href="#id1"><span class="problematic" id="id2">np.bool_</span></a></p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even"><td><p><a href="#id3"><span class="problematic" id="id4">np.int_</span></a></p></td>
<td><p>cnp.int_t</p></td>
<td><p>long</p></td>
</tr>
<tr class="row-odd"><td><p>np.intc</p></td>
<td><p>N/A</p></td>
<td><p>int</p></td>
</tr>
<tr class="row-even"><td><p>np.intp</p></td>
<td><p>cnp.intp_t</p></td>
<td><p>ssize_t</p></td>
</tr>
<tr class="row-odd"><td><p>np.int8</p></td>
<td><p>cnp.int8_t</p></td>
<td><p>signed char</p></td>
</tr>
<tr class="row-even"><td><p>np.int16</p></td>
<td><p>cnp.int16_t</p></td>
<td><p>signed short</p></td>
</tr>
<tr class="row-odd"><td><p>np.int32</p></td>
<td><p>cnp.int32_t</p></td>
<td><p>signed int</p></td>
</tr>
<tr class="row-even"><td><p>np.int64</p></td>
<td><p>cnp.int64_t</p></td>
<td><p>signed long long</p></td>
</tr>
<tr class="row-odd"><td><p>np.uint8</p></td>
<td><p>cnp.uint8_t</p></td>
<td><p>unsigned char</p></td>
</tr>
<tr class="row-even"><td><p>np.uint16</p></td>
<td><p>cnp.uint16_t</p></td>
<td><p>unsigned short</p></td>
</tr>
<tr class="row-odd"><td><p>np.uint32</p></td>
<td><p>cnp.uint32_t</p></td>
<td><p>unsigned int</p></td>
</tr>
<tr class="row-even"><td><p>np.uint64</p></td>
<td><p>cnp.uint64_t</p></td>
<td><p>unsigned long</p></td>
</tr>
<tr class="row-odd"><td><p><a href="#id5"><span class="problematic" id="id6">np.float_</span></a></p></td>
<td><p>cnp.float64_t</p></td>
<td><p>double</p></td>
</tr>
<tr class="row-even"><td><p>np.float32</p></td>
<td><p>cnp.float32_t</p></td>
<td><p>float</p></td>
</tr>
<tr class="row-odd"><td><p>np.float64</p></td>
<td><p>cnp.float64_t</p></td>
<td><p>double</p></td>
</tr>
<tr class="row-even"><td><p><a href="#id7"><span class="problematic" id="id8">np.complex_</span></a></p></td>
<td><p>cnp.complex128_t</p></td>
<td><p>double complex</p></td>
</tr>
<tr class="row-odd"><td><p>np.complex64</p></td>
<td><p>cnp.complex64_t</p></td>
<td><p>float complex</p></td>
</tr>
<tr class="row-even"><td><p>np.complex128</p></td>
<td><p>cnp.complex128_t</p></td>
<td><p>double complex</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>Differeces between cimport and import statements</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>cimport</strong> gives access to C functions or attributes</p></li>
<li><p><strong>import</strong> gives access to Python functions or attributes</p></li>
<li><p>it is common to use the following, and Cython will internally handle this ambiguity</p></li>
</ul>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>  <span class="c1"># access to NumPy Python functions</span>
<span class="n">cimport</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span> <span class="c1"># access to NumPy C API</span>
</pre></div>
</div>
</div></blockquote>
</div>
<p>Next step, we can start adding type annotation to the functions.
There are three ways of declaring functions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">def</span></code> - Python style:</p></li>
</ul>
<p>Called by Python or Cython code, and both input/output are Python objects.
Declaring the types of arguments and local types (thus return values) can allow Cython
to generate optimized code which speeds up the execution. Once the types are declared,
a <code class="docutils literal notranslate"><span class="pre">TypeError</span></code> will be raised if the function is passed with the wrong types.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cdef</span></code> - C style:</p></li>
</ul>
<p>Called from Cython and C, but not from Python code.
Cython treats the function as pure C functions, which can take any type of arguments,
including non-Python types, e.g. pointers. It will give you the best performance.
However, one should really take care of the <code class="docutils literal notranslate"><span class="pre">cdef</span></code> declared functions,
since you are actually writing in C.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cpdef</span></code> - Python/C mixed:</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cpdef</span></code> function combines both <code class="docutils literal notranslate"><span class="pre">def</span></code> and <code class="docutils literal notranslate"><span class="pre">cdef</span></code>. Cython will generate a <code class="docutils literal notranslate"><span class="pre">cdef</span></code>
function for C types and a <code class="docutils literal notranslate"><span class="pre">def</span></code> function for Python types. In terms of performance,
<code class="docutils literal notranslate"><span class="pre">cpdef</span></code> functions may be as fast as those using <code class="docutils literal notranslate"><span class="pre">cdef</span></code> and might be as slow as
<code class="docutils literal notranslate"><span class="pre">def</span></code> declared functions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="hll"><span class="n">cdef</span> <span class="n">f_cython_dtype1</span><span class="p">(</span><span class="n">double</span> <span class="n">x</span><span class="p">):</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="n">cpdef</span> <span class="n">integrate_f_cython_dtype1</span><span class="p">(</span><span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">b</span><span class="p">,</span> <span class="n">long</span> <span class="n">N</span><span class="p">):</span>   
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_dtype1</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="hll"><span class="n">cpdef</span> <span class="n">apply_integrate_f_cython_dtype1</span><span class="p">(</span><span class="n">double</span><span class="p">[:]</span> <span class="n">col_a</span><span class="p">,</span> <span class="n">double</span><span class="p">[:]</span> <span class="n">col_b</span><span class="p">,</span> <span class="n">long</span><span class="p">[:]</span> <span class="n">col_N</span><span class="p">):</span>
</span>    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_dtype1</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> apply_integrate_f_cython_dtype1(df[&#39;a&#39;].to_numpy(), df[&#39;b&#39;].to_numpy(), df[&#39;N&#39;].to_numpy())
<span class="c1"># 37.2 ms ± 556 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
<p>Last step, we can add type annotation to the local variables within the functions and the output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="hll"><span class="n">cdef</span> <span class="n">double</span> <span class="n">f_cython_dtype2</span><span class="p">(</span><span class="n">double</span> <span class="n">x</span><span class="p">):</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="n">cpdef</span> <span class="n">double</span> <span class="n">integrate_f_cython_dtype2</span><span class="p">(</span><span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">b</span><span class="p">,</span> <span class="n">long</span> <span class="n">N</span><span class="p">):</span>   
</span><span class="hll">    <span class="n">cdef</span> <span class="n">double</span> <span class="n">s</span><span class="p">,</span> <span class="n">dx</span>
</span><span class="hll">    <span class="n">cdef</span> <span class="n">long</span> <span class="n">i</span>
</span>    
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
<span class="hll">        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_dtype2</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
</span>    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="n">cpdef</span> <span class="n">double</span><span class="p">[:]</span> <span class="n">apply_integrate_f_cython_dtype2</span><span class="p">(</span><span class="n">double</span><span class="p">[:]</span> <span class="n">col_a</span><span class="p">,</span> <span class="n">double</span><span class="p">[:]</span> <span class="n">col_b</span><span class="p">,</span> <span class="n">long</span><span class="p">[:]</span> <span class="n">col_N</span><span class="p">):</span>
<span class="hll">    <span class="n">cdef</span> <span class="n">long</span> <span class="n">n</span><span class="p">,</span><span class="n">i</span>
</span><span class="hll">    <span class="n">cdef</span> <span class="n">double</span><span class="p">[:]</span> <span class="n">res</span>
</span>    
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_dtype2</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> apply_integrate_f_cython_dtype2(df[&#39;a&#39;].to_numpy(), df[&#39;b&#39;].to_numpy(), df[&#39;N&#39;].to_numpy())
<span class="c1"># 696 µs ± 8.71 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</span>
</pre></div>
</div>
<p>Now it is over 400 times faster than the original Python implementation, and all we have done is to add
type declarations! If we add the <code class="docutils literal notranslate"><span class="pre">-a</span></code> annotation flag we indeed see much less Python interaction in the
code.</p>
<figure class="align-default">
<img alt="_images/cython_annotate_2.png" src="_images/cython_annotate_2.png" />
</figure>
</section>
<section id="numba">
<h4>Numba<a class="headerlink" href="#numba" title="Link to this heading"></a></h4>
<p>An alternative to statically compiling Cython code is to use a dynamic just-in-time (JIT) compiler with <a class="reference external" href="https://numba.pydata.org/">Numba</a>.
Numba allows you to write a pure Python function which can be JIT compiled to native machine instructions,
similar in performance to C, C++ and Fortran, by simply adding the decorator <code class="docutils literal notranslate"><span class="pre">&#64;jit</span></code> in your function.
However, the <code class="docutils literal notranslate"><span class="pre">&#64;jit</span></code> compilation will add overhead to the runtime of the function,
i.e. the first time a function is run using Numba engine will be slow as Numba will have the function compiled.
Once the function is JIT compiled and cached, subsequent calls will be fast. So the performance benefits may not be
realized especially when using small datasets.</p>
<p>Numba supports compilation of Python to run on either CPU or GPU hardware and is designed to integrate with
the Python scientific software stack. The optimized machine code is generated by the LLVM compiler infrastructure.</p>
<div class="admonition-demo-numba demo admonition" id="demo-1">
<p class="admonition-title">Demo: Numba</p>
<p>Consider the integration example again using Numba this time:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f_numba</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_numba</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_numba</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_numba</span><span class="p">(</span><span class="n">col_a</span><span class="p">,</span> <span class="n">col_b</span><span class="p">,</span> <span class="n">col_N</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_numba</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="c1"># try passing Pandas Series</span>
<span class="o">%</span><span class="k">timeit</span> apply_integrate_f_numba(df[&#39;a&#39;],df[&#39;b&#39;],df[&#39;N&#39;])
<span class="c1"># 6.02 ms ± 56.5 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
<span class="c1"># try passing NumPy array</span>
<span class="o">%</span><span class="k">timeit</span> apply_integrate_f_numba(df[&#39;a&#39;].to_numpy(),df[&#39;b&#39;].to_numpy(),df[&#39;N&#39;].to_numpy())
<span class="c1"># 625 µs ± 697 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Numba is best at accelerating functions that apply numerical functions to NumPy arrays. When used with Pandas,
pass the underlying NumPy array of <code class="xref py py-class docutils literal notranslate"><span class="pre">Series</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code> (using <code class="docutils literal notranslate"><span class="pre">to_numpy()</span></code>) into the function.
If you try to &#64;jit a function that contains unsupported Python or NumPy code, compilation will fall back to the object mode
which will mostly likely be very slow. If you would prefer that Numba throw an error for such a case,
you can do e.g. <code class="docutils literal notranslate"><span class="pre">&#64;numba.jit(nopython=True)</span></code> or <code class="docutils literal notranslate"><span class="pre">&#64;numba.njit</span></code>.</p>
</div>
<p>We can further add date type, although in this case there is not much performance improvement:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f_numba_dtype</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span><span class="n">numba</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_numba_dtype</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_numba_dtype</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:](</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:],</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:],</span><span class="n">numba</span><span class="o">.</span><span class="n">int64</span><span class="p">[:]))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_numba_dtype</span><span class="p">(</span><span class="n">col_a</span><span class="p">,</span> <span class="n">col_b</span><span class="p">,</span> <span class="n">col_N</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_numba_dtype</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> apply_integrate_f_numba_dtype(df[&#39;a&#39;].to_numpy(),df[&#39;b&#39;].to_numpy(),df[&#39;N&#39;].to_numpy())
<span class="c1"># 625 µs ± 697 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</span>
</pre></div>
</div>
</div>
<div class="admonition-numba-vs-cython callout admonition" id="callout-0">
<p class="admonition-title">Numba vs Cython</p>
<p>Should you use Numba or Cython? Does it matter?</p>
<ul class="simple">
<li><p>Performance is usually very similar and exact results depend on versions of
Python, Cython, Numba and NumPy.</p></li>
<li><p>Numba is generally easier to use (just add <code class="docutils literal notranslate"><span class="pre">&#64;jit</span></code>)</p></li>
<li><p>Cython is more stable and mature, Numba developing faster</p></li>
<li><p>Numba also works for GPUs</p></li>
<li><p>Cython can compile arbitrary Python code and directly call C libraries,
Numba has restrictions</p></li>
<li><p>Numba requires LLVM toolchain, Cython only C compiler.</p></li>
</ul>
<p>Finally:</p>
<p>NumPy is really good at what it does. For simple operations or small data,
Numba or Cython is not going to outperform it. But when things get more complex
these frameworks can save the day!</p>
</div>
</section>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-profile-the-word-autocorrelation-code exercise important admonition" id="exercise-0">
<p class="admonition-title">Profile the word-autocorrelation code</p>
<p>Revisit the word-autocorrelation code. To clone the repository (if you haven’t already):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/word-count-hpda.git
</pre></div>
</div>
<p>To run the code, type:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>word-count-hpda
<span class="gp">$ </span>python<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/pg99.txt<span class="w"> </span>processed_data/pg99.dat
<span class="gp">$ </span>python<span class="w"> </span>source/autocorrelation.py<span class="w"> </span>data/pg99.txt<span class="w"> </span>processed_data/pg99.dat<span class="w"> </span>results/acf_pg99.dat
</pre></div>
</div>
<p>Add <code class="docutils literal notranslate"><span class="pre">&#64;profile</span></code> to the <code class="xref py py-meth docutils literal notranslate"><span class="pre">word_acf()</span></code> function, and run <code class="docutils literal notranslate"><span class="pre">kernprof</span></code>
from the command line. What lines of this function are the most expensive?</p>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kernprof<span class="w"> </span>-l<span class="w"> </span>-v<span class="w"> </span>source/autocorrelation.py<span class="w"> </span>data/pg99.txt<span class="w"> </span>processed_data/pg99.dat<span class="w"> </span>results/acf_pg99.dat
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Wrote profile results to autocorrelation.py.lprof
Timer unit: 1e-06 s

Total time: 15.5976 s
File: source/autocorrelation.py
Function: word_acf at line 24

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    24                                           @profile
    25                                           def word_acf(word, text, timesteps):
    26                                               &quot;&quot;&quot;
    27                                               Calculate word-autocorrelation function for given word
    28                                               in a text. Each word in the text corresponds to one &quot;timestep&quot;.
    29                                               &quot;&quot;&quot;
    30        10       1190.0    119.0      0.0      acf = np.zeros((timesteps,))
    31        10      15722.0   1572.2      0.1      mask = [w==word for w in text]
    32        10       6072.0    607.2      0.0      nwords_chosen = np.sum(mask)
    33        10         14.0      1.4      0.0      nwords_total = len(text)
    34      1010        658.0      0.7      0.0      for t in range(timesteps):
    35  11373500    4675124.0      0.4     30.0          for i in range(1,nwords_total-t):
    36  11372500   10897305.0      1.0     69.9              acf[t] += mask[i]*mask[i+t]
    37      1000       1542.0      1.5      0.0          acf[t] /= nwords_chosen
    38        10         10.0      1.0      0.0      return acf
</pre></div>
</div>
</div>
</div>
<div class="admonition-is-the-meth-word-acf-function-efficient exercise important admonition" id="exercise-1">
<p class="admonition-title">Is the <code class="xref py py-meth docutils literal notranslate"><span class="pre">word_acf()</span></code> function efficient?</p>
<p>Have another look at the <code class="xref py py-meth docutils literal notranslate"><span class="pre">word_acf()</span></code> function from the word-count project.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">word_acf</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate word-autocorrelation function for given word </span>
<span class="sd">    in a text. Each word in the text corresponds to one &quot;timestep&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">==</span><span class="n">word</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
    <span class="n">nwords_chosen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">nwords_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nwords_total</span><span class="o">-</span><span class="n">t</span><span class="p">):</span>
            <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">t</span><span class="p">]</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">/=</span> <span class="n">nwords_chosen</span>      
    <span class="k">return</span> <span class="n">acf</span>
</pre></div>
</div>
<p>Do you think there is any room for improvement? How would you go about optimizing
this function?</p>
<p>Try to implement one faster version!</p>
<div class="admonition-hints solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Hints</p>
<ul class="simple">
<li><p>You can replace the double loop (the manual calculation of an ACF) with an
in-built NumPy function, <code class="xref py py-meth docutils literal notranslate"><span class="pre">np.correlate()</span></code>. NumPy gurus often know which
function to use for which algorithms, but searching the internet also helps.
One typically needs to figure out how to use the in-built function for the
particular use case.</p></li>
<li><p>There are two ways of using Numba, one with <code class="docutils literal notranslate"><span class="pre">nopython=False</span></code> and one with
<code class="docutils literal notranslate"><span class="pre">nopython=True</span></code>. The latter needs a rewrite of the <code class="xref py py-meth docutils literal notranslate"><span class="pre">word_acf()</span></code> function
to accept the <code class="docutils literal notranslate"><span class="pre">mask</span></code> array, since Numba cannot pre-compile the expression
defining <code class="docutils literal notranslate"><span class="pre">mask</span></code>.</p></li>
</ul>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-2">
<p class="admonition-title">Solution</p>
<p>The function uses a Python object (<code class="docutils literal notranslate"><span class="pre">mask</span></code>) inside a double for-loop,
which is guaranteed to be suboptimal. There are a number of ways to speed
it up. One is to use <code class="docutils literal notranslate"><span class="pre">numba</span></code> and just-in-time compilation, as we shall
see below.</p>
<p>Another is to find an in-built vectorized NumPy function which can calculate the
autocorrelation for us! Here are the Numpy and Numba <code class="docutils literal notranslate"><span class="pre">(nopython=False)</span></code> versions:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">NumPy</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">Numba</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">word_acf_numpy</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate word-autocorrelation function for given word </span>
<span class="sd">    in a text using numpy.correlate function. </span>
<span class="sd">    Each word in the text corresponds to one &quot;timestep&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">w</span><span class="o">==</span><span class="n">word</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">correlate</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">acf</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">acf</span><span class="o">.</span><span class="n">size</span><span class="o">/</span><span class="mi">2</span><span class="p">):</span><span class="nb">int</span><span class="p">(</span><span class="n">acf</span><span class="o">.</span><span class="n">size</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="n">timesteps</span><span class="p">]</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">nopython</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">word_acf_numba_py</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate word-autocorrelation function for given word </span>
<span class="sd">    in a text. Each word in the text corresponds to one &quot;timestep&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">acf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,))</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">w</span><span class="o">==</span><span class="n">word</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">nwords_chosen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">nwords_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nwords_total</span><span class="o">-</span><span class="n">t</span><span class="p">):</span>
            <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">t</span><span class="p">]</span>
        <span class="n">acf</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">/=</span> <span class="n">nwords_chosen</span>      
    <span class="k">return</span> <span class="n">acf</span>
</pre></div>
</div>
</div><p>In the <a class="reference external" href="https://github.com/enccs/word-count-hpda/tree/autocorr-numba-numpy">autocorr-numba-numpy branch</a>
of the word-count-hpda repository you
can additionally find a <code class="docutils literal notranslate"><span class="pre">nopython=True</span></code> Numba version as well as benchmarking
of all the versions. Note that the Numba functions use <code class="docutils literal notranslate"><span class="pre">cache=True</span></code> to save the
precompiled code so that subsequent executions of the <code class="docutils literal notranslate"><span class="pre">autocorrelation.py</span></code> script
are faster than the first.</p>
</div>
</div>
</div>
<div class="admonition-pairwise-distance exercise important admonition" id="exercise-2">
<p class="admonition-title">Pairwise distance</p>
<p>Consider the following Python function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dis_python</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
            <span class="n">d</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
                <span class="n">d</span> <span class="o">+=</span> <span class="n">tmp</span> <span class="o">*</span> <span class="n">tmp</span>
            <span class="n">D</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">D</span>
</pre></div>
</div>
<p>Start by profiling it in Jupyter:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">%</span><span class="k">timeit</span> dis_python(X)
</pre></div>
</div>
<p>Now try to speed it up with NumPy (i.e. <em>vectorise</em> the function),
Numba or Cython (depending on what you find most interesting).</p>
<div class="admonition-solution solution important dropdown admonition" id="solution-3">
<p class="admonition-title">Solution</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">NumPy</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">Cython</button><button aria-controls="panel-1-1-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-2" name="1-2" role="tab" tabindex="-1">Numba</button><button aria-controls="panel-1-1-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-3" name="1-3" role="tab" tabindex="-1">SciPy</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dis_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="n">X</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">X</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">%</span><span class="k">timeit</span> dis_numpy(X)
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dis_cython</span><span class="p">(</span><span class="n">double</span><span class="p">[:,:]</span> <span class="n">X</span><span class="p">):</span>
    <span class="n">cdef</span> <span class="n">ssize_t</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">N</span>
    <span class="n">cdef</span> <span class="n">double</span> <span class="n">d</span><span class="p">,</span><span class="n">tmp</span>
    <span class="n">cdef</span> <span class="n">double</span><span class="p">[:,:]</span> <span class="n">D</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
            <span class="n">d</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
                <span class="n">d</span> <span class="o">+=</span> <span class="n">tmp</span> <span class="o">*</span> <span class="n">tmp</span>
            <span class="n">D</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">D</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">%</span><span class="k">timeit</span> dis_cython(X)
</pre></div>
</div>
<p>We can further improve performance by using more C functions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">libc.math</span> <span class="n">cimport</span> <span class="n">sqrt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dis_cython_v1</span><span class="p">(</span><span class="n">double</span><span class="p">[:,:]</span> <span class="n">X</span><span class="p">):</span>
    <span class="n">cdef</span> <span class="n">ssize_t</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">N</span>
    <span class="n">cdef</span> <span class="n">double</span> <span class="n">d</span><span class="p">,</span><span class="n">tmp</span>
    <span class="n">cdef</span> <span class="n">double</span><span class="p">[:,:]</span> <span class="n">D</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
            <span class="n">d</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
                <span class="n">d</span> <span class="o">+=</span> <span class="n">tmp</span> <span class="o">*</span> <span class="n">tmp</span>
            <span class="n">D</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">D</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">%</span><span class="k">timeit</span> dis_cython_v1(X)
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-2" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-2" name="1-2" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">dis_numba</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
            <span class="n">d</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
                <span class="n">d</span> <span class="o">+=</span> <span class="n">tmp</span> <span class="o">*</span> <span class="n">tmp</span>
            <span class="n">D</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">D</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">%</span><span class="k">timeit</span> dis_numba(X)
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-3" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-3" name="1-3" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.spatial.distance</span><span class="w"> </span><span class="kn">import</span> <span class="n">cdist</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">%</span><span class="k">timeit</span> cdist(X, X)
</pre></div>
</div>
</div></div>
</div>
</div>
<div class="admonition-bubble-sort exercise important admonition" id="exercise-3">
<p class="admonition-title">Bubble sort</p>
<p>To make a long story short, in the worse case the time taken by the Bubblesort algorithm is
roughly <span class="math notranslate nohighlight">\(O(n^2)\)</span> where  <span class="math notranslate nohighlight">\(n\)</span> is the number of items being sorted.</p>
<img alt="_images/Bubble-sort-example-300px.gif" src="_images/Bubble-sort-example-300px.gif" />
<p>Here is a function that performs bubble-sort:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bs_python</span><span class="p">(</span><span class="n">a_list</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a_list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="n">i</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">a_list</span>
</pre></div>
</div>
<p>And this is how you can benchmark it:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)]</span>
<span class="o">%</span><span class="k">timeit</span> bs_python(l)
</pre></div>
</div>
<p>Now try to speed it up with Numba or Cython (depending on what you find
most interesting). Make sure that you’re getting the correct result,
and then benchmark it with <code class="docutils literal notranslate"><span class="pre">%timeit</span></code>.</p>
<div class="admonition-solution solution important dropdown admonition" id="solution-4">
<p class="admonition-title">Solution</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">Cython</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">Numba</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span>

<span class="n">cpdef</span> <span class="n">long</span><span class="p">[:]</span> <span class="n">bs_cython</span><span class="p">(</span><span class="n">long</span><span class="p">[:]</span> <span class="n">a_list</span><span class="p">):</span>
    <span class="n">cdef</span> <span class="nb">int</span> <span class="n">N</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a_list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="n">i</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">a_list</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)]</span>
<span class="n">l_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> bs_cython(l_arr)
</pre></div>
</div>
<p>We can further improve performance by using more C/C++ features:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span>

<span class="n">cimport</span> <span class="n">cython</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">libc.stdlib</span> <span class="n">cimport</span> <span class="n">malloc</span><span class="p">,</span> <span class="n">free</span>

<span class="n">cpdef</span> <span class="n">bs_clist</span><span class="p">(</span><span class="n">a_list</span><span class="p">):</span>
    <span class="n">cdef</span> <span class="nb">int</span> <span class="o">*</span><span class="n">c_list</span>
    <span class="n">c_list</span> <span class="o">=</span> <span class="o">&lt;</span><span class="nb">int</span> <span class="o">*&gt;</span><span class="n">malloc</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_list</span><span class="p">)</span><span class="o">*</span><span class="n">cython</span><span class="o">.</span><span class="n">sizeof</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
    <span class="n">cdef</span> <span class="nb">int</span> <span class="n">N</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> 
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a_list</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">c_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="n">i</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">c_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">c_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">c_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">c_list</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">c_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">a_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        
    <span class="n">free</span><span class="p">(</span><span class="n">c_list</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a_list</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)]</span>
<span class="o">%</span><span class="k">timeit</span> bs_clist(l)
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">bs_numba</span><span class="p">(</span><span class="n">a_list</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a_list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="n">i</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">a_list</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">a_list</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)]</span>
<span class="c1"># first try using a list as input</span>
<span class="o">%</span><span class="k">timeit</span> bs_numba(l)
<span class="c1"># try using a NumPy array</span>
<span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)]</span>
<span class="n">l_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> bs_numba(l_arr)
</pre></div>
</div>
</div></div>
</div>
</div>
<div class="admonition-static-typing exercise important admonition" id="exercise-4">
<p class="admonition-title">Static typing</p>
<p>Consider the following example of calculating the squre of an array.
We have a few different versions using Numba. Benchmark them and compare the results.</p>
<blockquote>
<div><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">NumPy</button><button aria-controls="panel-3-3-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-1" name="3-1" role="tab" tabindex="-1">Numba without static typing</button><button aria-controls="panel-3-3-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-2" name="3-2" role="tab" tabindex="-1">Numba with static typing</button><button aria-controls="panel-3-3-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-3" name="3-3" role="tab" tabindex="-1">Numba with static typing and vectorization</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> np.square(X)
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-1" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-1" name="3-1" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">nb_no_typing</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
   <span class="n">res</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">))</span>
   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">)):</span>
       <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
       
   <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> nb_no_typing(X)
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-2" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-2" name="3-2" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:](</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:]))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">nb_typing</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
   <span class="n">res</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">))</span>
   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">)):</span>
       <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
       
   <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> nb_typing(X)
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-3" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-3" name="3-3" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[::</span><span class="mi">1</span><span class="p">](</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[::</span><span class="mi">1</span><span class="p">]))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">nb_typing_vec</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
   <span class="n">res</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">))</span>
   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">)):</span>
       <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
    
   <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> nb_typing_vec(X)
</pre></div>
</div>
</div></div>
</div></blockquote>
<div class="admonition-typing-is-not-a-necessity solution important dropdown admonition" id="solution-5">
<p class="admonition-title">Typing is not a necessity</p>
<p>None of the Numba version will outperform the NumPy version for this simple and small example.</p>
<p>You will see that using static typing actually leads to a decreased performance, since the
input array is not assumed to be continuous and therefore ruling out the vectorization.
By defining the array as continuous, the performace can be recovered.</p>
<p>In principle, such cases where typing does not allow optimizations could happen to Cython codes as well,
so one should always optimize where and when needed.</p>
</div>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>To squeeze the last drop of performance out of your Python code you can
convert performance-critical functions to Numba or Cython</p></li>
<li><p>Both Numba and Cython pre-compile Python code to make it run faster.</p></li>
</ul>
</div>
</section>
</section>
<span id="document-dask"></span><section id="dask-for-scalable-analytics">
<span id="dask"></span><h2>Dask for scalable analytics<a class="headerlink" href="#dask-for-scalable-analytics" title="Link to this heading"></a></h2>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand how Dask achieves parallelism</p></li>
<li><p>Learn a few common workflows with Dask</p></li>
<li><p>Understand lazy execution</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>40 min teaching/type-along</p></li>
<li><p>40 min exercises</p></li>
</ul>
</div>
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h3>
<p>An increasingly common problem faced by researchers and data scientists
today is that datasets are becoming larger and larger and modern data analysis
is thus becoming more and more computationally demanding. The first
difficulty to deal with is when the volume of data exceeds one’s computer’s RAM.
Modern laptops/desktops have about 10 GB of RAM. Beyond this threshold,
some special care is required to carry out data analysis.
The next threshold of difficulty is when the data can not even
fit on the hard drive, which is about a couple of TB on a modern laptop.
In this situation, it is better to use an HPC system or a cloud-based solution,
and Dask is a tool that helps us easily extend our familiar data analysis
tools to work with big data. In addition, Dask can also speeds up
our analysis by using multiple CPU cores which makes our work run
faster on laptop, HPC and cloud platforms.</p>
</section>
<section id="what-is-dask">
<h3>What is Dask?<a class="headerlink" href="#what-is-dask" title="Link to this heading"></a></h3>
<p>Dask is composed of two parts:</p>
<ul class="simple">
<li><p>Dynamic task scheduling optimized for computation. Similar to other workflow
management systems, but optimized for interactive computational workloads.</p></li>
<li><p>“Big Data” collections like parallel arrays, dataframes, and lists that extend
common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory
or distributed environments. These parallel collections run on top of dynamic
task schedulers.</p></li>
</ul>
<figure class="align-default" id="id1">
<img alt="_images/dask-overview.svg" src="_images/dask-overview.svg" />
<figcaption>
<p><span class="caption-text">High level collections are used to generate task graphs which can be executed
by schedulers on a single machine or a cluster. From the
<a class="reference external" href="https://docs.dask.org/en/stable/">Dask documentation</a>.</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="dask-clusters">
<h3>Dask Clusters<a class="headerlink" href="#dask-clusters" title="Link to this heading"></a></h3>
<p>Dask needs computing resources in order to perform parallel computations.
“Dask Clusters” have different names corresponding to different computing environments,
for example:</p>
<blockquote>
<div><ul class="simple">
<li><p><cite>LocalCluster</cite> on laptop/desktop/cluster</p></li>
<li><p><cite>PBSCluster</cite> or <cite>SLURMCluster</cite> on HPC</p></li>
<li><p><cite>Kubernetes</cite> cluster in the cloud</p></li>
</ul>
</div></blockquote>
<p>Each cluster will be allocated with a given number of “workers” associated with
CPU and RAM and the Dask scheduling system automatically maps jobs to each worker.</p>
<p>Dask provides four different schedulers:</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>Type</p></td>
<td><p>Multi-node</p></td>
<td><p>Description</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">threads</span></code></p></td>
<td><p>No</p></td>
<td><p>A single-machine scheduler backed by a thread pool</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">processes</span></code></p></td>
<td><p>No</p></td>
<td><p>A single-machine scheduler backed by a process pool</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">synchronous</span></code></p></td>
<td><p>No</p></td>
<td><p>A single-threaded scheduler, used for debugging</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">distributed</span></code></p></td>
<td><p>yes</p></td>
<td><p>A distributed scheduler for executing on multiple nodes/machines</p></td>
</tr>
</tbody>
</table>
<p>Here we will focus on using a <code class="docutils literal notranslate"><span class="pre">LocalCluster</span></code>, and it is recommended to use
a distributed sceduler <code class="docutils literal notranslate"><span class="pre">dask.distributed</span></code>. It is more sophisticated, offers more features,
but requires minimum effort to set up. It can run locally on a laptop and scale up to a cluster.
We can start a <code class="docutils literal notranslate"><span class="pre">LocalCluster</span></code> scheduler which makes use of all the cores and RAM
we have on the machine by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dask.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">Client</span><span class="p">,</span> <span class="n">LocalCluster</span>
<span class="c1"># create a local cluster</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">LocalCluster</span><span class="p">()</span>
<span class="c1"># connect to the cluster we just created</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>
<span class="n">client</span>
</pre></div>
</div>
<p>Or you can simply lauch a Client() call which is shorthand for what is described above.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dask.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">Client</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">()</span> <span class="c1"># same as Client(processes=True)</span>
<span class="n">client</span>
</pre></div>
</div>
<p>We can also specify the resources to be allocated to a Dask cluster by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dask.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">Client</span><span class="p">,</span> <span class="n">LocalCluster</span>
<span class="c1"># create a local cluster with</span>
<span class="c1"># 4 workers</span>
<span class="c1"># 1 thread per worker</span>
<span class="c1"># 4 GiB memory limit for a worker</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">LocalCluster</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">memory_limit</span><span class="o">=</span><span class="s1">&#39;4GiB&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When setting up the cluster, one should consider the balance between the number of workers
and threads per worker with different workloads by setting the parameter <code class="docutils literal notranslate"><span class="pre">processes</span></code>.
By default <code class="docutils literal notranslate"><span class="pre">processes=True</span></code> and this is a good choice for workloads that have the GIL,
thus it is better to have more workers and fewer threads per worker. Otherwise, when <code class="docutils literal notranslate"><span class="pre">processes=False</span></code>,
in this case all workers run as threads within the same process as the client,
and they share memory resources. This works well for large datasets.</p>
</div>
<p>Cluster managers also provide useful utilities: for example if a cluster manager supports scaling,
you can modify the number of workers manually or automatically based on workload:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cluster</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># Sets the number of workers to 10</span>
<span class="n">cluster</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">minimum</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">maximum</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># Allows the cluster to auto scale to 10 when tasks are computed</span>
</pre></div>
</div>
<p>Dask distributed scheduler also provides live feedback via its interactive dashboard.
A link that redirects to the dashboard will prompt in the terminal
where the scheduler is created, and it is also shown when you create a Client and connect the scheduler.
By default, when starting a scheduler on your local machine the dashboard will be served at
<a class="reference external" href="http://localhost:8787/status">http://localhost:8787/status</a> and can be always queried from commond line by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cluster</span><span class="o">.</span><span class="n">dashboard_link</span>
<span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="mf">127.0.0.1</span><span class="p">:</span><span class="mi">8787</span><span class="o">/</span><span class="n">status</span>
<span class="c1"># or</span>
<span class="n">client</span><span class="o">.</span><span class="n">dashboard_link</span>
</pre></div>
</div>
<p>When everything finishes, you can shut down the connected scheduler and workers
by calling the <code class="xref py py-meth docutils literal notranslate"><span class="pre">shutdown()</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">client</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="dask-collections">
<h3>Dask Collections<a class="headerlink" href="#dask-collections" title="Link to this heading"></a></h3>
<p>Dask provides dynamic parallel task scheduling and
three main high-level collections:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dask.array</span></code>: Parallel NumPy arrays</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dask.dataframe</span></code>: Parallel Pandas DataFrames</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dask.bag</span></code>: Parallel Python Lists</p></li>
</ul>
</div></blockquote>
<section id="dask-arrays">
<h4>Dask Arrays<a class="headerlink" href="#dask-arrays" title="Link to this heading"></a></h4>
<p>A Dask array looks and feels a lot like a NumPy array.
However, a Dask array uses the so-called “lazy” execution mode,
which allows one to build up complex, large calculations symbolically
before turning them over the scheduler for execution.</p>
<div class="admonition-lazy-evaluation callout admonition" id="callout-0">
<p class="admonition-title">Lazy evaluation</p>
<p>Contrary to normal computation, lazy execution mode is when all the computations
needed to generate results are symbolically represented, forming a queue of
tasks mapped over data blocks. Nothing is actually computed until the actual
numerical values are needed, e.g. plotting, to print results to the screen or write to disk.
At that point, data is loaded into memory and computation proceeds in a streaming
fashion, block-by-block. The actual computation is controlled by a multi-processing
or thread pool, which allows Dask to take full advantage of multiple processors
available on the computers.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">4000</span><span class="p">)</span>
<span class="n">ones_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">ones_np</span>
<span class="n">ones_np</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">/</span> <span class="mf">1e6</span>
</pre></div>
</div>
<p>Now let’s create the same array using Dask’s array interface.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask.array</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">da</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">4000</span><span class="p">)</span>
<span class="n">ones</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">ones</span>
</pre></div>
</div>
<p>Although this works, it is not optimized for parallel computation. In order to use all
available computing resources, we also specify the <code class="docutils literal notranslate"><span class="pre">chunks</span></code> argument with Dask,
which describes how the array is split up into sub-arrays:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask.array</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">da</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">4000</span><span class="p">)</span>
<span class="n">chunk_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">ones</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="n">chunk_shape</span><span class="p">)</span>
<span class="n">ones</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this course, we will use a chunk shape, but other ways to specify <code class="docutils literal notranslate"><span class="pre">chunks</span></code> size can be found here
<a class="reference external" href="https://docs.dask.org/en/stable/array-chunks.html#specifying-chunk-shapes">https://docs.dask.org/en/stable/array-chunks.html#specifying-chunk-shapes</a></p>
</div>
<p>Let us further calculate the sum of the dask array:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sum_da</span> <span class="o">=</span> <span class="n">ones</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
<p>So far, it is only a symbolic representation of the array.
One way to trigger the computation is to call <code class="xref py py-meth docutils literal notranslate"><span class="pre">compute()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dask</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">sum_da</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">sum_da</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
<p>We can visualize the symbolic operations by calling <code class="xref py py-meth docutils literal notranslate"><span class="pre">visualize()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dask</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">sum_da</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">sum_da</span><span class="o">.</span><span class="n">visualize</span><span class="p">()</span>
</pre></div>
</div>
<p>You can find additional details and examples here
<a class="reference external" href="https://examples.dask.org/array.html">https://examples.dask.org/array.html</a>.</p>
</section>
<section id="dask-dataframe">
<h4>Dask Dataframe<a class="headerlink" href="#dask-dataframe" title="Link to this heading"></a></h4>
<p>Dask dataframes split a dataframe into partitions along an index and can be used
in situations where one would normally use Pandas, but this fails due to data size or
insufficient computational efficiency. Specifically, you can use Dask dataframes to:</p>
<ul class="simple">
<li><p>manipulate large datasets, even when these don’t fit in memory</p></li>
<li><p>accelerate long computations by using many cores</p></li>
<li><p>perform distributed computing on large datasets with standard Pandas operations
like groupby, join, and time series computations.</p></li>
</ul>
<p>Let us revisit the dataset containing the Titanic passenger list, and now transform it to
a Dask dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dask.dataframe</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dd</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv&quot;</span>
<span class="c1"># read from Pandas DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">&quot;Name&quot;</span><span class="p">)</span>
<span class="n">ddf</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">npartitions</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># &quot;blocksize=None&quot; means a single chunk is used</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">blocksize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Name&#39;</span><span class="p">)</span>
<span class="n">ddf</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">npartitions</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># blocksize=&quot;4MB&quot; or blocksize=4e6</span>
<span class="n">ddf</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">blocksize</span><span class="o">=</span><span class="s2">&quot;4MB&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Name&#39;</span><span class="p">)</span>
<span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span>
<span class="c1"># blocksize=&quot;default&quot; means the chunk is computed based on available memory and cores with a maximum of 64MB</span>
<span class="n">ddf</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">blocksize</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Name&#39;</span><span class="p">)</span>
<span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span>
</pre></div>
</div>
<p>Dask dataframes do not support the entire interface of Pandas dataframes, but
the most <a class="reference external" href="https://docs.dask.org/en/stable/dataframe.html#scope">commonly used methods are available</a>.
For a full listing refer to the
<a class="reference external" href="https://docs.dask.org/en/stable/dataframe-api.html">dask dataframe API</a>.</p>
<p>We can for example perform the group-by operation we did earlier, but this time in parallel:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># add a column</span>
<span class="n">ddf</span><span class="p">[</span><span class="s2">&quot;Child&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ddf</span><span class="p">[</span><span class="s2">&quot;Age&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">12</span>
<span class="n">ddf</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;Sex&quot;</span><span class="p">,</span> <span class="s2">&quot;Child&quot;</span><span class="p">])[</span><span class="s2">&quot;Survived&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
<p>However, for a small dataframe like this the overhead of parallelisation will far
outweigh the benefit.</p>
<p>You can find additional details and examples here
<a class="reference external" href="https://examples.dask.org/dataframe.html">https://examples.dask.org/dataframe.html</a>.</p>
</section>
<section id="dask-bag">
<h4>Dask Bag<a class="headerlink" href="#dask-bag" title="Link to this heading"></a></h4>
<p>A Dask bag enables processing data that can be represented as a sequence of arbitrary
inputs (“messy data”), like in a Python list. Dask Bags are often used to for
preprocessing log files, JSON records, or other user defined Python objects.</p>
<p>We will content ourselves with implementing a dask version of the word-count problem,
specifically the step where we count words in a text.</p>
<div class="admonition-demo-dask-version-of-word-count demo admonition" id="demo-0">
<p class="admonition-title">Demo: Dask version of word-count</p>
<p>First navigate to the <code class="docutils literal notranslate"><span class="pre">word-count-hpda</span></code> directory. The serial version (wrapped in
multiple functions in the <code class="docutils literal notranslate"><span class="pre">source/wordcount.py</span></code> code) looks like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;./data/pg10.txt&#39;</span>
<span class="n">DELIMITERS</span> <span class="o">=</span> <span class="s2">&quot;. , ; : ? $ @ ^ &lt; &gt; # % ` ! * - = ( ) [ ] { } / </span><span class="se">\&quot;</span><span class="s2"> &#39;&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">input_fd</span><span class="p">:</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">input_fd</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>

<span class="n">counts</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">purge</span> <span class="ow">in</span> <span class="n">DELIMITERS</span><span class="p">:</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">purge</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">:</span>
            <span class="n">counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">sorted_counts</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">counts</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">key_value</span><span class="p">:</span> <span class="n">key_value</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">sorted_counts</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
<p>A very compact <code class="docutils literal notranslate"><span class="pre">dask.bag</span></code> version of this code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask.bag</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">db</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;./data/pg10.txt&#39;</span>
<span class="n">DELIMITERS</span> <span class="o">=</span> <span class="s2">&quot;. , ; : ? $ @ ^ &lt; &gt; # % ` ! * - = ( ) [ ] { } / </span><span class="se">\&quot;</span><span class="s2"> &#39;&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">read_text</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="s1">&#39;1MiB&#39;</span><span class="p">)</span>
<span class="n">sorted_counts</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">DELIMITERS</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">frequencies</span><span class="p">()</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">key</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="n">sorted_counts</span>
</pre></div>
</div>
<p>The last two steps of the pipeline could also have been done with a dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">filtered</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">DELIMITERS</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">ddf</span> <span class="o">=</span> <span class="n">filtered</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;words&#39;</span><span class="p">])</span>
<span class="n">ddf</span><span class="p">[</span><span class="s1">&#39;words&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="admonition-when-to-use-dask callout admonition" id="callout-1">
<p class="admonition-title">When to use Dask</p>
<p>There is no benefit from using Dask on small datasets. But imagine we were
analysing a very large text file (all tweets in a year? a genome?). Dask provides
both parallelisation and the ability to utilize RAM on multiple machines.</p>
</div>
</section>
<section id="dask-delayed">
<h4>Dask Delayed<a class="headerlink" href="#dask-delayed" title="Link to this heading"></a></h4>
<p>Sometimes problems don’t fit into one of the collections like
<code class="docutils literal notranslate"><span class="pre">dask.array</span></code> or <code class="docutils literal notranslate"><span class="pre">dask.dataframe</span></code>, they are not as simple as just a big array or dataframe.
In these cases, <code class="docutils literal notranslate"><span class="pre">dask.delayed</span></code> may be the right choice. If the problem is paralellisable,
we can use <code class="docutils literal notranslate"><span class="pre">dask.delayed</span></code> which allows users to make function calls lazy
and thus can be put into a task graph with dependencies.</p>
<p>Consider the following example. The functions are very simple, and they <em>sleep</em>
for a prescribed time to simulate real work:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">def</span><span class="w"> </span><span class="nf">inc</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dec</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">1</span>

<span class="k">def</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
</pre></div>
</div>
<p>Let us run the example first, one after the other in sequence:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="n">x</span> <span class="o">=</span> <span class="n">inc</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dec</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># 902 ms ± 367 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<p>Note that the first two functions <code class="docutils literal notranslate"><span class="pre">inc</span></code> and <code class="docutils literal notranslate"><span class="pre">dec</span></code> don’t depend on each other,
we could have called them in parallel. We can call <code class="docutils literal notranslate"><span class="pre">dask.delayed</span></code> on these funtions
to make them lazy and tasks into a graph which we will run later on parallel hardware.</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>
<span class="n">inc_delay</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">inc</span><span class="p">)</span>
<span class="n">dec_delay</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">dec</span><span class="p">)</span>
<span class="n">add_delay</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">add</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="n">x</span> <span class="o">=</span> <span class="n">inc_delay</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dec_delay</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">add_delay</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># 59.6 µs ± 356 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="n">x</span> <span class="o">=</span> <span class="n">inc_delay</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dec_delay</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">add_delay</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">z</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="c1"># 603 ms ± 181 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<div class="admonition-default-scheduler-for-dask-collections callout admonition" id="callout-2">
<p class="admonition-title">Default scheduler for dask collections</p>
<p><code class="docutils literal notranslate"><span class="pre">dask.array</span></code> and <code class="docutils literal notranslate"><span class="pre">dask.dataframe</span></code> use the <code class="docutils literal notranslate"><span class="pre">threads</span></code> scheduler</p>
<p><code class="docutils literal notranslate"><span class="pre">dask.bag</span></code> uses the <code class="docutils literal notranslate"><span class="pre">processes</span></code> scheduler</p>
<p>In case to change the default scheduler, using <cite>dask.config.set</cite> is recommanded:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="c1"># To set globally</span>
<span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;processes&#39;</span><span class="p">)</span>
<span class="n">x</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="c1"># To set it as a context manager</span>
<span class="k">with</span> <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;threads&#39;</span><span class="p">):</span>
    <span class="n">x</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="comparison-to-spark">
<h3>Comparison to Spark<a class="headerlink" href="#comparison-to-spark" title="Link to this heading"></a></h3>
<p>Dask has much in common with the <a class="reference external" href="https://spark.apache.org/">Apache Spark</a>.
Here are <a class="reference external" href="https://docs.dask.org/en/stable/spark.html">some differences</a>
between the two frameworks:</p>
<ul class="simple">
<li><p>Dask is smaller and more lightweight but is used together with other packages in
the Python ecosystem. Spark is an all-in-one project with its own ecosystem.</p></li>
<li><p>Spark is written in Scala, with some support for Python and R, while Dask is in Python.</p></li>
<li><p>Spark is more focused on business intelligence (SQL, lightweight machine learning) while
Dask is more general and is used more in scientific applications.</p></li>
<li><p>Both Dask and Spark can scale from one to thousands of nodes.</p></li>
<li><p>Dask supports the NumPy model for multidimensional arrays which Spark doesn’t.</p></li>
<li><p>Spark generally expects users to compose computations out of high-level primitives
(map, reduce, groupby, join, etc.), while Dask allows to specify arbitrary task
graphs for more complex and custom systems.</p></li>
</ul>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-chunk-size exercise important admonition" id="exercise-0">
<p class="admonition-title">Chunk size</p>
<p>The following example calculate the mean value of a random generated array.
Run the example and see the performance improvement by using dask.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">NumPy</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">Dask</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="o">%%</span><span class="n">time</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">20000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dask.array</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">da</span>

<span class="o">%%</span><span class="n">time</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">20000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">),</span> <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
</div></div>
<p>But what happens if we use different chunk sizes?
Try out with different chunk sizes:</p>
<ul class="simple">
<li><p>What happens if the dask chunks=(20000,20000)</p></li>
<li><p>What happens if the dask chunks=(250,250)</p></li>
</ul>
<div class="admonition-choice-of-chunk-size solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Choice of chunk size</p>
<p>The choice is problem dependent, but here are a few things to consider:</p>
<p>Each chunk of data should be small enough so that it fits comforably in each worker’s available memory.
Chunk sizes between 10MB-1GB are common, depending on the availability of RAM. Dask will likely
manipulate as many chunks in parallel on one machine as you have cores on that machine.
So if you have a machine with 10 cores and you choose chunks in the 1GB range, Dask is likely to use at least
10 GB of memory. Additionally, there should be enough chunks available so that each worker always has something to work on.</p>
<p>On the otherhand, you also want to avoid chunk sizes that are too small as we see in the exercise.
Every task comes with some overhead which is somewhere between 200us and 1ms. Very large graphs
with millions of tasks will lead to overhead being in the range from minutes to hours which is not recommended.</p>
</div>
</div>
<div class="admonition-dask-delay exercise important admonition" id="exercise-1">
<p class="admonition-title">Dask delay</p>
<p>We extend the previous example a little bit more by applying the function
on a data array using for loop and adding an <em>if</em> condition:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>

<span class="k">def</span><span class="w"> </span><span class="nf">inc</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dec</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">1</span>

<span class="k">def</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>


<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">%</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">inc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">dec</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

<span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>Please add dask.delayed to parallelize the program as much as possible
and check graph visualizations.</p>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>

<span class="k">def</span><span class="w"> </span><span class="nf">inc</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dec</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">1</span>

<span class="k">def</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>


<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">%</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">inc</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">dec</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">add</span><span class="p">)(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

<span class="n">total</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="nb">sum</span><span class="p">)(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-testing-different-schedulers exercise important admonition" id="exercise-2">
<p class="admonition-title">Testing different schedulers</p>
<p>We will test different schedulers and compare the performance on a simple task calculating
the mean of a random generated array.</p>
<p>Here is the code using NumPy:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">calc_mean</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">return</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we run the same code using different schedulers from Dask:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0"><code class="docutils literal notranslate"><span class="pre">serial</span></code></button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1"><code class="docutils literal notranslate"><span class="pre">threads</span></code></button><button aria-controls="panel-1-1-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-2" name="1-2" role="tab" tabindex="-1"><code class="docutils literal notranslate"><span class="pre">processes</span></code></button><button aria-controls="panel-1-1-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-3" name="1-3" role="tab" tabindex="-1"><code class="docutils literal notranslate"><span class="pre">distributed</span></code></button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="o">%%time</span>it
<span class="n">rs</span><span class="o">=</span><span class="p">[</span><span class="n">calc_mean</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
<span class="c1">#352 ms ± 925 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">calc_mean</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">return</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
<span class="n">n</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">calc_mean</span><span class="p">)(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="k">with</span> <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;threads&#39;</span><span class="p">,</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">mt_1</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="c1">#395 ms ± 18.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="k">with</span> <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;threads&#39;</span><span class="p">,</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">mt_2</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="c1">#1.28 s ± 1.46 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="k">with</span> <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;threads&#39;</span><span class="p">,</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">mt_4</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="c1">#1.28 s ± 3.84 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-2" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-2" name="1-2" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">calc_mean</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">return</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
<span class="n">n</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">calc_mean</span><span class="p">)(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="k">with</span> <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;processes&#39;</span><span class="p">,</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">mp_1</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="c1">#990 ms ± 39.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="k">with</span> <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;processes&#39;</span><span class="p">,</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">mp_2</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="c1">#881 ms ± 17.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="k">with</span> <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;processes&#39;</span><span class="p">,</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">mp_4</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="c1">#836 ms ± 10.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-3" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-3" name="1-3" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dask.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">Client</span><span class="p">,</span> <span class="n">LocalCluster</span>

<span class="k">def</span><span class="w"> </span><span class="nf">calc_mean</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">return</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
<span class="n">n</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">dask</span><span class="o">.</span><span class="n">delayed</span><span class="p">(</span><span class="n">calc_mean</span><span class="p">)(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>

<span class="n">cluster</span> <span class="o">=</span> <span class="n">LocalCluster</span><span class="p">(</span><span class="n">n_workers</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> dis_1 = dask.compute(output,n_workers = 1)
<span class="c1">#619 ms ± 253 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">cluster</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> dis_2 = dask.compute(output,n_workers = 2)
<span class="c1">#357 ms ± 131 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">cluster</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> dis_4 = dask.compute(output,n_workers = 4)
<span class="c1">#265 ms ± 53.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">c</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</pre></div>
</div>
</div></div>
<div class="admonition-testing-different-schedulers solution important dropdown admonition" id="solution-2">
<p class="admonition-title">Testing different schedulers</p>
<p>Comparing profiling from mt_1, mt_2 and mt_4: Using <code class="docutils literal notranslate"><span class="pre">threads</span></code> scheduler is limited by the GIL on pure Python code.
In our case, although it is not a pure Python function, it is still limited by GIL, therefore no multi-core speedup</p>
<p>Comparing profiling from mt_1, mp_1 and dis_1: Except for <code class="docutils literal notranslate"><span class="pre">threads</span></code>, the other two schedulers copy data between processes
and this can introduce performance penalties, particularly when the data being transferred between processes is large.</p>
<p>Comparing profiling from serial, mt_1, mp_1 and dis_1: Creating and destroying threads and processes have overheads,
<code class="docutils literal notranslate"><span class="pre">processes</span></code> have even more overhead than <code class="docutils literal notranslate"><span class="pre">threads</span></code></p>
<p>Comparing profiling from mp_1, mp_2 and mp_4: Running multiple processes is only effective when there is enough computational
work to do i.e. CPU-bound tasks. In this very example, most of the time is actually spent on transferring the data
rather than computing the mean</p>
<p>Comparing profiling from <code class="docutils literal notranslate"><span class="pre">processes</span></code> and <code class="docutils literal notranslate"><span class="pre">distributed</span></code>: Using <code class="docutils literal notranslate"><span class="pre">distributed</span></code> scheduler has advantages over <code class="docutils literal notranslate"><span class="pre">processes</span></code>,
this is related to better handling of data copying, i.e. <code class="docutils literal notranslate"><span class="pre">processes</span></code> scheduler copies data for every task, while
<code class="docutils literal notranslate"><span class="pre">distributed</span></code> scheduler copies data for each worker.</p>
</div>
</div>
<div class="admonition-svd-with-large-skinny-matrix-using-distributed-scheduler exercise important admonition" id="exercise-3">
<p class="admonition-title">SVD with large skinny matrix using <code class="docutils literal notranslate"><span class="pre">distributed</span></code> scheduler</p>
<p>We can use dask to compute SVD of a large matrix which does not fit into the memory of a
normal laptop/desktop. While it is computing, you should switch to the Dask dashboard and
watch column “Workers” and “Graph”, so you must run this using <code class="docutils literal notranslate"><span class="pre">distributed</span></code> scheduler</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dask.array</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">da</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">2000000</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="n">X</span>
<span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">dask</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<span class="n">s</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
<p>SVD is only supported for arrays with chunking in one dimension, which requires that the matrix
is either <em>tall-and-skinny</em> or <em>short-and-fat</em>.
If chunking in both dimensions is needed, one should use approximate algorithm.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dask.array</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">da</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">),</span> <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">))</span>
<span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd_compressed</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">dask</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<span class="n">s</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="admonition-memory-management callout admonition" id="callout-3">
<p class="admonition-title">Memory management</p>
<p>You may observe that there are different memory categories showing on the dashboard:</p>
<ul class="simple">
<li><p>process: Overall memory used by the worker process, as measured by the OS</p></li>
<li><p>managed: Size of data that Dask holds in RAM, but most probably inaccurate, excluding spilled data.</p></li>
<li><p>unmanaged: Memory that Dask is not directly aware of, this can be e.g. Python modules,
temporary arrays, memory leasks, memory not yet free()’d by the Python memory manager to the OS</p></li>
<li><p>unmanaged recent: Unmanaged memory that has appeared within the last 30 seconds whch is not included
in the “unmanaged” memory measure</p></li>
<li><p>spilled: Memory spilled to disk</p></li>
</ul>
<p>The sum of managed + unmanaged + unmanaged recent is equal by definition to the process memory.</p>
<p>When the managed memory exceeds 60% of the memory limit (target threshold),
the worker will begin to dump the least recently used data to disk.
Above 70% of the target memory usage based on process memory measurment (spill threshold),
the worker will start dumping unused data to disk.</p>
<p>At 80% process memory load, currently executing tasks continue to run, but no additional tasks
in the worker’s queue will be started.</p>
<p>At 95% process memory load (terminate threshold), all workers will be terminated. Tasks will be cancelled
as well and data on the worker will be lost and need to be recomputed.</p>
</div>
<div class="admonition-benchmarking-dask-dataframes-apply exercise important admonition" id="exercise-4">
<p class="admonition-title">Benchmarking dask.dataframes.apply()</p>
<p>Recall the word-count project that we encountered earlier and the <code class="xref py py-meth docutils literal notranslate"><span class="pre">scipy.optimize.curve_fit()</span></code> function.
The <a class="reference download internal" download="" href="_downloads/674f23c9a1a67a1abbe65e91d831b78e/results.csv"><code class="xref download docutils literal notranslate"><span class="pre">results.csv</span></code></a> file contains word counts of the 10
most frequent words in different texts, and we want to fit a power law to the
individual distributions in each row.</p>
<p>Here are our fitting functions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">curve_fit</span>

<span class="k">def</span><span class="w"> </span><span class="nf">powerlaw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">A</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">fit_powerlaw</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1.0</span>
    <span class="n">params</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">powerlaw</span><span class="p">,</span> <span class="n">xdata</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">ydata</span><span class="o">=</span><span class="n">row</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>Compare the performance of <code class="xref py py-meth docutils literal notranslate"><span class="pre">dask.dataframes.apply()</span></code> with <code class="xref py py-meth docutils literal notranslate"><span class="pre">pandas.dataframes.apply()</span></code>
for the this example. You will probably see a slowdown due to the parallelisation
overhead. But what if you add a <code class="docutils literal notranslate"><span class="pre">time.sleep(0.01)</span></code> inside <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit_powerlaw()</span></code> to
emulate a time-consuming calculation?</p>
<div class="admonition-hints solution important dropdown admonition" id="solution-3">
<p class="admonition-title">Hints</p>
<ul class="simple">
<li><p>You will need to call <code class="xref py py-meth docutils literal notranslate"><span class="pre">apply()</span></code> on the dataframe starting from column 1: <code class="docutils literal notranslate"><span class="pre">dataframe.iloc[:,1:].apply()</span></code></p></li>
<li><p>Remember that both Pandas and Dask have the <code class="xref py py-meth docutils literal notranslate"><span class="pre">read_csv()</span></code> function.</p></li>
<li><p>Try repartitioning the dataframe into 4 partitions with <code class="docutils literal notranslate"><span class="pre">ddf4=ddf.repartition(npartitions=4)</span></code>.</p></li>
<li><p>You will probably get a warning in your Dask version that <cite>You did not provide metadata</cite>.
To remove the warning, add the <code class="docutils literal notranslate"><span class="pre">meta=(None,</span> <span class="pre">&quot;float64&quot;)</span></code> flag to <code class="xref py py-meth docutils literal notranslate"><span class="pre">apply()</span></code>. For the
current data, this does not affect the performance.</p></li>
</ul>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-4">
<p class="admonition-title">Solution</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">Pandas</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">Dask</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">curve_fit</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">def</span><span class="w"> </span><span class="nf">powerlaw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">A</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">fit_powerlaw</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1.0</span>
    <span class="n">params</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">powerlaw</span><span class="p">,</span> <span class="n">xdata</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">ydata</span><span class="o">=</span><span class="n">row</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">))</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/ENCCS/hpda-python/main/content/data/results.csv&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> results = df.iloc[:,1:].apply(fit_powerlaw, axis=1)
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dask.dataframe</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">curve_fit</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">def</span><span class="w"> </span><span class="nf">powerlaw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">A</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">fit_powerlaw</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1.0</span>
    <span class="n">params</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">powerlaw</span><span class="p">,</span> <span class="n">xdata</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">ydata</span><span class="o">=</span><span class="n">row</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">))</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">ddf</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/ENCCS/hpda-python/main/content/data/results.csv&quot;</span><span class="p">)</span>
<span class="n">ddf4</span><span class="o">=</span><span class="n">ddf</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">npartitions</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Note the optional argument ``meta`` which is recommended for dask dataframes. </span>
<span class="c1"># It should contain an empty ``pandas.DataFrame`` or ``pandas.Series`` </span>
<span class="c1"># that matches the dtypes and column names of the output, </span>
<span class="c1"># or a dict of ``{name: dtype}`` or iterable of ``(name, dtype)``.</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">ddf4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fit_powerlaw</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;float64&quot;</span><span class="p">))</span>
<span class="o">%</span><span class="k">timeit</span> results.compute()
<span class="n">results</span><span class="o">.</span><span class="n">visualize</span><span class="p">()</span>
</pre></div>
</div>
</div></div>
</div>
</div>
<div class="admonition-break-down-the-dask-bag-computational-pipeline exercise important admonition" id="exercise-5">
<p class="admonition-title">Break down the dask.bag computational pipeline</p>
<p>Revisit the word-count problem and the implementation with a <code class="docutils literal notranslate"><span class="pre">dask.bag</span></code> that we
saw above.</p>
<ul class="simple">
<li><p>To get a feeling for the computational pipeline, break down the computation into
separate steps and investigate intermediate results using <code class="xref py py-meth docutils literal notranslate"><span class="pre">compute()</span></code>.</p></li>
<li><p>Benchmark the serial and <code class="docutils literal notranslate"><span class="pre">dask.bag</span></code> versions. Do you see any speedup?
What if you have a larger textfile? You can for example concatenate all texts into
a single file: <code class="docutils literal notranslate"><span class="pre">cat</span> <span class="pre">data/*.txt</span> <span class="pre">&gt;</span> <span class="pre">data/all.txt</span></code>.</p></li>
</ul>
</div>
<div class="admonition-climate-simulation-data-using-xarray-and-dask exercise important admonition" id="exercise-6">
<p class="admonition-title">Climate simulation data using Xarray and Dask</p>
<p>This exercise is working with NetCDF files using Xarray. The files contain
monthly global 2m air temperature for 10 years.
Xarray is chosen due to its ability to seamlessly integrate with Dask
to support parallel computations on datasets.</p>
<p>We will first read data with Dask and Xarray. See
<a class="reference external" href="https://xarray.pydata.org/en/stable/dask.html#reading-and-writing-data">https://xarray.pydata.org/en/stable/dask.html#reading-and-writing-data</a> for more details.</p>
<p>Note that the NetCDF files are here <a class="reference external" href="https://github.com/ENCCS/hpda-python/tree/main/content/data">https://github.com/ENCCS/hpda-python/tree/main/content/data</a> ,
you need to download them to your laptop first, then depending on where you put the files,
you may need to adapt the path to the data folder in the Python code.</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dask</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">xarray</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">xr</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">ds</span><span class="o">=</span><span class="n">xr</span><span class="o">.</span><span class="n">open_mfdataset</span><span class="p">(</span><span class="s1">&#39;./data/tas*.nc&#39;</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">use_cftime</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">open_mfdataset()</span></code> is for reading multiple files and will chunk each file into a single Dask array by default.
One could supply the chunks keyword argument to control the size of the resulting Dask arrays.
Passing the keyword argument <code class="docutils literal notranslate"><span class="pre">parallel=True</span></code> to open_mfdataset() will speed up the reading of
large multi-file datasets by executing those read tasks in parallel using <code class="docutils literal notranslate"><span class="pre">dask.delayed</span></code>.</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">ds</span>
<span class="n">ds</span><span class="o">.</span><span class="n">tas</span>
<span class="c1">#dsnew = ds.chunk({&quot;time&quot;: 1,&quot;lat&quot;: 80,&quot;lon&quot;:80})   # you can further rechunk the data</span>
<span class="c1">#dask.visualize(ds.tas) # do not visualize, the graph is too big</span>
<span class="n">ds</span><span class="p">[</span><span class="s1">&#39;tas&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="s1">&#39;tas&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mf">273.15</span>     <span class="c1"># convert from Kelvin to degree Celsius</span>
<span class="n">mean_tas</span><span class="o">=</span><span class="n">ds</span><span class="o">.</span><span class="n">tas</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">)</span>  <span class="c1"># lazy compuation</span>
<span class="n">mean_tas</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu_r</span><span class="p">,</span><span class="n">vmin</span><span class="o">=-</span><span class="mi">50</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span> <span class="c1"># plotting triggers computation</span>
<span class="n">tas_ann</span><span class="o">=</span><span class="n">ds</span><span class="o">.</span><span class="n">tas</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;time.year&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># lazy compuation</span>
<span class="n">tas_sto</span><span class="o">=</span><span class="n">tas_ann</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">lon</span><span class="o">=</span><span class="mf">18.07</span><span class="p">,</span> <span class="n">lat</span><span class="o">=</span><span class="mf">59.33</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>  <span class="c1"># slicing is lazy as well</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tas_sto</span><span class="o">.</span><span class="n">year</span><span class="p">,</span><span class="n">tas_sto</span><span class="p">)</span>  <span class="c1"># plotting trigers computation</span>
</pre></div>
</div>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Dask uses lazy execution</p></li>
<li><p>Only use Dask for processing very large amount of data</p></li>
</ul>
</div>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-setup-eurohpc"></span><section id="installation-in-eurohpc-systems">
<h2>Installation in EuroHPC systems<a class="headerlink" href="#installation-in-eurohpc-systems" title="Link to this heading"></a></h2>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>These instructions may be outdated and were last updated in 2023.</p>
</div>
<p>Here are instructions for accessing the EuroHPC system, setting up the Python environment
and running jobs. Please follow the instructions for the HPC system that will be used
during the workshop that you are attending.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-VmVnYQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-VmVnYQ==" name="VmVnYQ==" role="tab" tabindex="0">Vega</button><button aria-controls="panel-0-S2Fyb2xpbmE=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tab" tabindex="-1">Karolina</button></div><div aria-labelledby="tab-0-VmVnYQ==" class="sphinx-tabs-panel group-tab" id="panel-0-VmVnYQ==" name="VmVnYQ==" role="tabpanel" tabindex="0"><p>Thanks to <a class="reference external" href="https://www.izum.si/en/hpc-en/">IZUM</a> in Slovenia we will have an allocation on the
petascale <a class="reference external" href="https://en-vegadocs.vega.izum.si/">Vega</a> EuroHPC system for the duration of the workshop.
The sustained and peak performance of Vega is 6.9 petaflops and 10.1 petaflops, respectively.</p>
<p><strong>Architecture</strong>:</p>
<p>Vega has both <a class="reference external" href="https://en-vegadocs.vega.izum.si/architecture/">GPU and CPU partititions</a>:</p>
<ul class="simple">
<li><p>CPU partition: Each node has two AMD Epyc 7H12 CPUs, each with 64 cores. 768 nodes with 256 GB,
192 nodes with 1 TB of RAM DDR4-3200, local 1.92 TB M.2 SSD.</p></li>
<li><p>GPU partition: Each node has 4 GPUs NVidia A100 with 40 GB HBMI2 and two AMD Epyc 7H12 CPUs.
In total 60 nodes with 512 GB of RAM DDR4-3200, local 1.92 TB M.2 SSD</p></li>
</ul>
</div><div aria-labelledby="tab-0-S2Fyb2xpbmE=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tabpanel" tabindex="0"><p>Thanks to <a class="reference external" href="https://www.it4i.cz/en">IT4I</a> in the Czech Republic we will have an allocation
on the petascale <a class="reference external" href="https://www.it4i.cz/en/infrastructure/karolina">Karolina supercomputer</a>
for the duration of the workshop. The peak performance of Karolina is 15.7 petaflops.</p>
<p><strong>Architecture</strong>:</p>
<ul class="simple">
<li><p>720x 2x AMD 7H12, 64 cores, 2,6 GHz, 92,160 cores in total</p></li>
<li><p>72x 2x AMD 7763, 64 cores, 2,45 GHz, 9,216 cores in total</p></li>
<li><p>72x 8x NVIDIA A100 GPU, 576 GPU in total</p></li>
<li><p>32x Intel Xeon-SC 8628, 24 cores, 2,9 GHz, 768 cores in total</p></li>
<li><p>36x 2x AMD 7H12, 64 cores, 2,6 GHz, 4,608 cores in total</p></li>
<li><p>2x 2x AMD 7452, 32 cores, 2,35 GHz, 128 cores in total</p></li>
</ul>
</div></div>
<p>Software on the cluster is available through a module system.
First load the Anaconda module to get access to the <code class="docutils literal notranslate"><span class="pre">conda</span></code> package manager:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-VmVnYQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-1-VmVnYQ==" name="VmVnYQ==" role="tab" tabindex="0">Vega</button><button aria-controls="panel-1-S2Fyb2xpbmE=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tab" tabindex="-1">Karolina</button></div><div aria-labelledby="tab-1-VmVnYQ==" class="sphinx-tabs-panel group-tab" id="panel-1-VmVnYQ==" name="VmVnYQ==" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1">#check available Anaconda modules:</span>
<span class="gp">$ </span>ml<span class="w"> </span>av<span class="w"> </span>Anaconda3
<span class="gp">$ </span>ml<span class="w"> </span>add<span class="w"> </span>Anaconda3/2020.11
</pre></div>
</div>
</div><div aria-labelledby="tab-1-S2Fyb2xpbmE=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1">#check available Anaconda modules:</span>
<span class="gp">$ </span>ml<span class="w"> </span>av<span class="w"> </span>Anaconda3
<span class="gp">$ </span>ml<span class="w"> </span>add<span class="w"> </span>Anaconda3/2021.11
</pre></div>
</div>
</div></div>
<p>To be able to create conda environments in your home directory you need to initialize it.
The following command adds the necessary configuration to your <code class="docutils literal notranslate"><span class="pre">.bashrc</span></code> file:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>conda<span class="w"> </span>init<span class="w"> </span>bash
</pre></div>
</div>
<p>You now need to either log in to the cluster again or start a new shell session by typing <code class="docutils literal notranslate"><span class="pre">bash</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>bash
</pre></div>
</div>
<p>Now, either create a new environment with all required dependencies or activate
a pre-existing environment created in a directory you have access to:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">Create new environment in $HOME</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">Activate existing environment</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>conda<span class="w"> </span>env<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>https://raw.githubusercontent.com/ENCCS/hpda-python/main/content/env/environment.yml
</pre></div>
</div>
<p>The installation can take several minutes.
Now activate the environment by:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>conda<span class="w"> </span>activate<span class="w"> </span>pyhpda
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>conda<span class="w"> </span>activate<span class="w"> </span>/path/to/envdir/
</pre></div>
</div>
</div></div>
<section id="mpi4py">
<h3>mpi4py<a class="headerlink" href="#mpi4py" title="Link to this heading"></a></h3>
<p>Additional steps are required to use mpi4py since the Python package needs to be
linked with the system’s MPI libraries.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-VmVnYQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-3-VmVnYQ==" name="VmVnYQ==" role="tab" tabindex="0">Vega</button><button aria-controls="panel-3-S2Fyb2xpbmE=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-3-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tab" tabindex="-1">Karolina</button></div><div aria-labelledby="tab-3-VmVnYQ==" class="sphinx-tabs-panel group-tab" id="panel-3-VmVnYQ==" name="VmVnYQ==" role="tabpanel" tabindex="0"><p>To use mpi4py you need to load a module which contains MPI libraries and then install <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code>
using <code class="docutils literal notranslate"><span class="pre">pip</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ml<span class="w"> </span>add<span class="w"> </span>foss/2020b
<span class="gp">$ </span><span class="nv">CC</span><span class="o">=</span>gcc<span class="w"> </span><span class="nv">MPICC</span><span class="o">=</span>mpicc<span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>mpi4py<span class="w"> </span>--no-binary<span class="o">=</span>mpi4py
</pre></div>
</div>
</div><div aria-labelledby="tab-3-S2Fyb2xpbmE=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-3-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tabpanel" tabindex="0"><p>To use mpi4py you only need to load a module:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ml<span class="w"> </span>add<span class="w"> </span>mpi4py/3.1.1-gompi-2020b
</pre></div>
</div>
</div></div>
</section>
<section id="running-jobs">
<h3>Running jobs<a class="headerlink" href="#running-jobs" title="Link to this heading"></a></h3>
<p>Resources can be allocated both through batch jobs (submitting a script to the scheduler)
and interactively. You will need to provide a project ID when asking for an allocation.
To find out what projects you belong to on the cluster, type:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sacctmgr<span class="w"> </span>-p<span class="w"> </span>show<span class="w"> </span>associations<span class="w"> </span><span class="nv">user</span><span class="o">=</span><span class="nv">$USER</span>
</pre></div>
</div>
<p>The second column of the output contains the project ID.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-VmVnYQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-4-VmVnYQ==" name="VmVnYQ==" role="tab" tabindex="0">Vega</button><button aria-controls="panel-4-S2Fyb2xpbmE=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-4-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tab" tabindex="-1">Karolina</button></div><div aria-labelledby="tab-4-VmVnYQ==" class="sphinx-tabs-panel group-tab" id="panel-4-VmVnYQ==" name="VmVnYQ==" role="tabpanel" tabindex="0"><p>Vega uses the SLURM scheduler.
Use the following command to allocate one interactive node with 8 cores for 1 hour
in the CPU partition. If there is a reservation on the cluster for the workshop,
add <code class="docutils literal notranslate"><span class="pre">--reservation=RESERVATIONNAME</span></code> to the command.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>salloc<span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">8</span><span class="w"> </span>--ntasks-per-core<span class="o">=</span><span class="m">1</span><span class="w"> </span>-A<span class="w"> </span>&lt;PROJECT-ID&gt;<span class="w"> </span>--partition<span class="o">=</span>cpu<span class="w">  </span>-t<span class="w"> </span><span class="m">01</span>:00:00
</pre></div>
</div>
<p>To instead book a GPU node, type (again adding reservation flag if relevant):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>salloc<span class="w"> </span>-N<span class="w"> </span><span class="m">1</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">1</span><span class="w"> </span>--ntasks-per-core<span class="o">=</span><span class="m">1</span><span class="w"> </span>-A<span class="w"> </span>&lt;PROJECT-ID&gt;<span class="w"> </span>--partition<span class="o">=</span>gpu<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>--cpus-per-task<span class="w"> </span><span class="m">1</span><span class="w"> </span>-t<span class="w"> </span><span class="m">01</span>:00:00
</pre></div>
</div>
</div><div aria-labelledby="tab-4-S2Fyb2xpbmE=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-4-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tabpanel" tabindex="0"><p>Karolina uses the PBS scheduler.
To allocate one interactive node for
1 hour on 1 node in the CPU partition and express queue:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>qsub<span class="w"> </span>-A<span class="w"> </span>DD-22-28<span class="w"> </span>-q<span class="w"> </span>qexp<span class="w"> </span>-l<span class="w"> </span><span class="nv">walltime</span><span class="o">=</span><span class="m">01</span>:00:00<span class="w"> </span>-I
</pre></div>
</div>
</div></div>
</section>
<section id="running-jupyter">
<h3>Running Jupyter<a class="headerlink" href="#running-jupyter" title="Link to this heading"></a></h3>
<p>The following procedure starts a Jupyter-Lab server on a compute node, creates an SSH tunnel from
your local machine to the compute node, and then connects to the remote Jupyter-Lab server from your
browser.</p>
<p>First make sure to follow the above instructions to:</p>
<ul class="simple">
<li><p>Allocate an interactive compute node for a sufficiently long time</p></li>
<li><p>Switch to the pyhpda conda environment.</p></li>
</ul>
<p>After allocating an interactive node you will see the name of the node in the output.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-VmVnYQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-5-VmVnYQ==" name="VmVnYQ==" role="tab" tabindex="0">Vega</button><button aria-controls="panel-5-S2Fyb2xpbmE=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-5-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tab" tabindex="-1">Karolina</button></div><div aria-labelledby="tab-5-VmVnYQ==" class="sphinx-tabs-panel group-tab" id="panel-5-VmVnYQ==" name="VmVnYQ==" role="tabpanel" tabindex="0"><p>After allocating an interactive node you will see the name of the node in the
output, e.g. <code class="docutils literal notranslate"><span class="pre">salloc:</span> <span class="pre">Nodes</span> <span class="pre">cn0709</span> <span class="pre">are</span> <span class="pre">ready</span> <span class="pre">for</span> <span class="pre">job</span></code>.</p>
<p>You now need to ssh to that node, switch to the pyhpda
conda environment, and start the Jupyter-Lab server on a particular port
(choose one between 8000 and 9000)
and IP address (the name of the compute node). Also load a module containing
OpenMPI to have access to MPI inside Jupyter:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ssh<span class="w"> </span>cn0709
<span class="gp">$ </span>conda<span class="w"> </span>activate<span class="w"> </span>pyhpda
<span class="gp">$ </span>ml<span class="w"> </span>add<span class="w"> </span>foss/2021b
<span class="gp">$ </span>jupyter-lab<span class="w"> </span>--no-browser<span class="w"> </span>--port<span class="o">=</span><span class="m">8123</span><span class="w"> </span>--ip<span class="o">=</span>cn0709
</pre></div>
</div>
</div><div aria-labelledby="tab-5-S2Fyb2xpbmE=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-5-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tabpanel" tabindex="0"><p>After allocating an interactive node your terminal session will be connected to that node.
Find out the name of your compute node. Your terminal prompt should show it but you can
also run the hostname command. Look only at the node name (e.g. cn012) and disregard
the <code class="docutils literal notranslate"><span class="pre">.karolina.it4i.cz</span></code> part.</p>
<p>Now start the Jupyter-Lab server on a particular port
(choose one between 8000 and 9000)
and IP address (the name of the compute node):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>jupyter-lab<span class="w"> </span>--no-browser<span class="w"> </span>--port<span class="o">=</span><span class="m">8123</span><span class="w"> </span>--ip<span class="o">=</span>cn012
</pre></div>
</div>
</div></div>
<p>Now create an SSH tunnel <strong>from a new terminal on your local machine</strong> to the correct
port and IP:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-6-VmVnYQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-6-VmVnYQ==" name="VmVnYQ==" role="tab" tabindex="0">Vega</button><button aria-controls="panel-6-S2Fyb2xpbmE=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-6-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tab" tabindex="-1">Karolina</button></div><div aria-labelledby="tab-6-VmVnYQ==" class="sphinx-tabs-panel group-tab" id="panel-6-VmVnYQ==" name="VmVnYQ==" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ssh<span class="w"> </span>-TN<span class="w"> </span>-f<span class="w"> </span>YourUsername@login.vega.izum.si<span class="w"> </span>-L<span class="w"> </span>localhost:8123:cn0709:8123<span class="w"> </span>-L<span class="w"> </span>localhost:8787:cn0709:8787
</pre></div>
</div>
</div><div aria-labelledby="tab-6-S2Fyb2xpbmE=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-6-S2Fyb2xpbmE=" name="S2Fyb2xpbmE=" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ssh<span class="w"> </span>-TN<span class="w"> </span>-f<span class="w"> </span>YourUsername@login2.karolina.it4i.cz<span class="w"> </span>-L<span class="w"> </span>localhost:8123:cn012:8123
</pre></div>
</div>
</div></div>
<p>Go back to the terminal running Jupyter-Lab on the compute node, and copy-paste the URL
starting with <code class="docutils literal notranslate"><span class="pre">127.0.0.1</span></code> which contains a long token into your local browser.
If that does not work, try replacing <code class="docutils literal notranslate"><span class="pre">127.0.0.1</span></code> with <code class="docutils literal notranslate"><span class="pre">localhost</span></code>.</p>
<p>If everything is working as it should, you should now be able to create a new Jupyter notebook in your browser
which is connected to the compute node and the <code class="docutils literal notranslate"><span class="pre">pyhpda</span></code> conda environment.</p>
</section>
</section>
<span id="document-pandas-extra"></span><section id="optional-more-on-pandas">
<span id="pandas-extra"></span><h2>Optional: more on Pandas<a class="headerlink" href="#optional-more-on-pandas" title="Link to this heading"></a></h2>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Learn about other data wrangling operations in pandas</p></li>
</ul>
</div>
<p>Begin by defining a new dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
         <span class="p">{</span>
              <span class="s2">&quot;foo&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;one&quot;</span><span class="p">,</span> <span class="s2">&quot;one&quot;</span><span class="p">,</span> <span class="s2">&quot;one&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">]</span> <span class="p">,</span>
              <span class="s2">&quot;bar&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="s2">&quot;C&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
              <span class="s2">&quot;baz&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
              <span class="s2">&quot;zoo&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span><span class="s2">&quot;y&quot;</span><span class="p">,</span><span class="s2">&quot;z&quot;</span><span class="p">,</span><span class="s2">&quot;q&quot;</span><span class="p">,</span><span class="s2">&quot;w&quot;</span><span class="p">,</span><span class="s2">&quot;t&quot;</span><span class="p">]</span>
         <span class="p">}</span>
         <span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
<p>Suppose we would like to represent the table in such a way that
the <code class="docutils literal notranslate"><span class="pre">columns</span></code> are the unique variables from “bar” and the <code class="docutils literal notranslate"><span class="pre">index</span></code> from “foo”.
To reshape the data into this form, we use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">DataFrame.pivot()</span></code>
method (also implemented as a top level function <code class="xref py py-func docutils literal notranslate"><span class="pre">pivot()</span></code>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pivoted</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="s2">&quot;baz&quot;</span><span class="p">)</span>
<span class="n">pivoted</span>
</pre></div>
</div>
<img alt="_images/reshaping_pivot.png" src="_images/reshaping_pivot.png" />
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">pivot()</span></code> will error with a <code class="docutils literal notranslate"><span class="pre">ValueError:</span> <span class="pre">Index</span> <span class="pre">contains</span> <span class="pre">duplicate</span>
<span class="pre">entries,</span> <span class="pre">cannot</span> <span class="pre">reshape</span></code> if the index/column pair is not unique. In this
case, consider using <code class="xref py py-func docutils literal notranslate"><span class="pre">pivot_table()</span></code> which is a generalization
of pivot that can handle duplicate values for one index/column pair.</p>
</div>
<section id="stacking-and-unstacking">
<h3>Stacking and unstacking<a class="headerlink" href="#stacking-and-unstacking" title="Link to this heading"></a></h3>
<p>Closely related to the <code class="xref py py-meth docutils literal notranslate"><span class="pre">pivot()</span></code> method are the related
<code class="xref py py-meth docutils literal notranslate"><span class="pre">stack()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">unstack()</span></code> methods available on Series and DataFrame.
These methods are designed to work together with MultiIndex objects.</p>
<p>The <code class="xref py py-meth docutils literal notranslate"><span class="pre">stack()</span></code> function “compresses” a level in the DataFrame columns to produce either:</p>
<blockquote>
<div><ul class="simple">
<li><p>A Series, in the case of a simple column Index.</p></li>
<li><p>A DataFrame, in the case of a MultiIndex in the columns.</p></li>
</ul>
</div></blockquote>
<p>If the columns have a MultiIndex, you can choose which level to stack.
The stacked level becomes the new lowest level in a MultiIndex on the columns:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tuples</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span>
                       <span class="p">[</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="s2">&quot;baz&quot;</span><span class="p">,</span> <span class="s2">&quot;baz&quot;</span><span class="p">,</span> <span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="s2">&quot;qux&quot;</span><span class="p">,</span> <span class="s2">&quot;qux&quot;</span><span class="p">],</span>
                       <span class="p">[</span><span class="s2">&quot;one&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">,</span> <span class="s2">&quot;one&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">,</span> <span class="s2">&quot;one&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">,</span> <span class="s2">&quot;one&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">],</span>
                        <span class="p">]))</span>
<span class="n">columns</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_tuples</span><span class="p">([</span>
             <span class="p">(</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="s2">&quot;one&quot;</span><span class="p">),</span>
             <span class="p">(</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">),</span>
             <span class="p">(</span><span class="s2">&quot;baz&quot;</span><span class="p">,</span> <span class="s2">&quot;one&quot;</span><span class="p">),</span>
             <span class="p">(</span><span class="s2">&quot;baz&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">),</span>
             <span class="p">(</span><span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="s2">&quot;one&quot;</span><span class="p">),</span>
             <span class="p">(</span><span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">),</span>
             <span class="p">(</span><span class="s2">&quot;qux&quot;</span><span class="p">,</span> <span class="s2">&quot;one&quot;</span><span class="p">),</span>
             <span class="p">(</span><span class="s2">&quot;qux&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">),</span>
         <span class="p">],</span>
         <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;first&quot;</span><span class="p">,</span> <span class="s2">&quot;second&quot;</span><span class="p">])</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_tuples</span><span class="p">(</span><span class="n">tuples</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;first&quot;</span><span class="p">,</span> <span class="s2">&quot;second&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>Note: there are other ways to generate MultiIndex, e.g.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_product</span><span class="p">(</span>
<span class="p">[(</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="s2">&quot;baz&quot;</span><span class="p">,</span> <span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="s2">&quot;qux&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;one&quot;</span><span class="p">,</span> <span class="s2">&quot;two&quot;</span><span class="p">)],</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;first&quot;</span><span class="p">,</span> <span class="s2">&quot;second&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">])</span>
<span class="n">df</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span>
<span class="n">df2</span>
<span class="n">stacked</span><span class="o">=</span><span class="n">df2</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>
</pre></div>
</div>
<img alt="_images/reshaping_stack.png" src="_images/reshaping_stack.png" />
<p>The unstack() method performs the inverse operation of stack(),
and by default unstacks the last level. If the indexes have names,
you can use the level names instead of specifying the level numbers.</p>
<p>stacked.unstack()</p>
<img alt="_images/reshaping_unstack.png" src="_images/reshaping_unstack.png" />
<p>stacked.unstack(1)
or
stacked.unstack(“second”)</p>
<img alt="_images/reshaping_unstack_1.png" src="_images/reshaping_unstack_1.png" />
<img alt="_images/reshaping_unstack_0.png" src="_images/reshaping_unstack_0.png" />
</section>
<section id="aggregation">
<h3>Aggregation<a class="headerlink" href="#aggregation" title="Link to this heading"></a></h3>
<p>Here we will go through the following example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">urllib.request</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">header_url</span> <span class="o">=</span> <span class="s1">&#39;ftp://ftp.ncdc.noaa.gov/pub/data/uscrn/products/daily01/HEADERS.txt&#39;</span>
<span class="k">with</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">header_url</span><span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">headers</span> <span class="o">=</span> <span class="n">lines</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>

<span class="n">ftp_base</span> <span class="o">=</span> <span class="s1">&#39;ftp://ftp.ncdc.noaa.gov/pub/data/uscrn/products/daily01/&#39;</span>
<span class="n">dframes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2016</span><span class="p">,</span> <span class="mi">2019</span><span class="p">):</span>
    <span class="n">data_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">/CRND0103-</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s1">-NY_Millbrook_3_W.txt&#39;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">ftp_base</span> <span class="o">+</span> <span class="n">data_url</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                     <span class="n">names</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span>
                     <span class="n">na_values</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">9999.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">99.0</span><span class="p">])</span>
    <span class="n">dframes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dframes</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;LST_DATE&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;T_DAILY_MEAN&#39;</span><span class="p">]</span> <span class="c1"># or df.T_DAILY_MEAN</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;T_DAILY_MEAN&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">aggregate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">index</span>   <span class="c1"># df.index is a pandas DateTimeIndex object.</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gbyear</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">year</span><span class="p">)</span>
<span class="n">gbyear</span><span class="o">.</span><span class="n">T_DAILY_MEAN</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">gbyear</span><span class="o">.</span><span class="n">T_DAILY_MEAN</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">gbyear</span><span class="o">.</span><span class="n">T_DAILY_MEAN</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">)</span>
<span class="n">gbyear</span><span class="o">.</span><span class="n">T_DAILY_MEAN</span><span class="o">.</span><span class="n">aggregate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">])</span>
</pre></div>
</div>
<p>now let us calculate the monthly mean values</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gb</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">month</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;T_DAILY_MEAN&#39;</span><span class="p">)</span>  <span class="c1"># or  df.groupby(df.T_DAILY_MEAN)</span>
<span class="n">monthly_climatology</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">month</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">monthly_climatology</span>
</pre></div>
</div>
<p>Each row in this new dataframe respresents the average values for the months (1=January, 2=February, etc.)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">monthly_T_climatology</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">month</span><span class="p">)</span><span class="o">.</span><span class="n">aggregate</span><span class="p">({</span><span class="s1">&#39;T_DAILY_MEAN&#39;</span><span class="p">:</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span>
                                                      <span class="s1">&#39;T_DAILY_MAX&#39;</span><span class="p">:</span> <span class="s1">&#39;max&#39;</span><span class="p">,</span>
                                                      <span class="s1">&#39;T_DAILY_MIN&#39;</span><span class="p">:</span> <span class="s1">&#39;min&#39;</span><span class="p">})</span>
<span class="n">monthly_T_climatology</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">daily_T_climatology</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">dayofyear</span><span class="p">)</span><span class="o">.</span><span class="n">aggregate</span><span class="p">({</span><span class="s1">&#39;T_DAILY_MEAN&#39;</span><span class="p">:</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span>
                                                    <span class="s1">&#39;T_DAILY_MAX&#39;</span><span class="p">:</span> <span class="s1">&#39;max&#39;</span><span class="p">,</span>
                                                    <span class="s1">&#39;T_DAILY_MIN&#39;</span><span class="p">:</span> <span class="s1">&#39;min&#39;</span><span class="p">})</span>
<span class="k">def</span><span class="w"> </span><span class="nf">standardize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">anomaly</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">month</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">standardize</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="transformation">
<h3>Transformation<a class="headerlink" href="#transformation" title="Link to this heading"></a></h3>
<p>The key difference between aggregation and transformation is that
aggregation returns a smaller object than the original,
indexed by the group keys, while transformation returns an object
with the same index (and same size) as the original object.</p>
<p>In this example, we standardize the temperature so that
the distribution has zero mean and unit variance.
We do this by first defining a function called standardize
and then passing it to the transform method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">transformed</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">year</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">grouped</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">year</span><span class="p">)</span>
<span class="n">grouped_trans</span> <span class="o">=</span> <span class="n">transformed</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">year</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<span id="document-GPU-computing"></span><section id="gpu-computing">
<span id="id1"></span><h2>GPU computing<a class="headerlink" href="#gpu-computing" title="Link to this heading"></a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>Why use GPUs?</p></li>
<li><p>What is different about GPUs?</p></li>
<li><p>What is the programming model?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand GPU architecture</p></li>
<li><p>Understand GPU programming model</p></li>
<li><p>Understand what types of computation is suitable for GPUs</p></li>
<li><p>Learn the basics of Numba for GPUs</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>70 min teaching/type-along</p></li>
<li><p>40 min exercises</p></li>
</ul>
</div>
<section id="gpu-intro">
<h3>GPU Intro<a class="headerlink" href="#gpu-intro" title="Link to this heading"></a></h3>
<section id="moore-s-law">
<h4>Moore’s law<a class="headerlink" href="#moore-s-law" title="Link to this heading"></a></h4>
<p>The number of transistors in a dense integrated circuit doubles about every two years.
More transistors means smaller size of a single element, so higher core frequency can be achieved.
However, power consumption scales as frequency in third power, so the growth in the core frequency
has slowed down significantly. Higher performance of a single node has to rely on its more complicated structure.</p>
<figure class="align-center" id="id2">
<img alt="_images/microprocessor-trend-data.png" src="_images/microprocessor-trend-data.png" />
<figcaption>
<p><span class="caption-text">The evolution of microprocessors.
The number of transistors per chip increase every 2 years or so.
However it can no longer be explored by the core frequency due to power consumption limits.
Before 2000, the increase in the single core clock frequency was the major source of the increase in the performance.
Mid 2000 mark a transition towards multi-core processors.</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Achieving performance has been based on two main strategies over the years:</p>
<blockquote>
<div><ul class="simple">
<li><p>Increase the single processor performance:</p></li>
<li><p>More recently, increase the number of physical cores.</p></li>
</ul>
</div></blockquote>
</section>
<section id="why-use-gpus">
<h4>Why use GPUs?<a class="headerlink" href="#why-use-gpus" title="Link to this heading"></a></h4>
<p>The Graphics Processing Unit (GPU) have been the most common accelerators
during the last few years. The term <em>GPU</em> sometimes is used interchangeably
with the term <em>accelerator</em>. GPU provides much higher instruction throughput
and memory bandwidth than CPU within a similar price and power envelope.</p>
</section>
<section id="how-do-gpus-differ-from-cpus">
<h4>How do GPUs differ from CPUs?<a class="headerlink" href="#how-do-gpus-differ-from-cpus" title="Link to this heading"></a></h4>
<p>CPUs and GPUs were designed with different goals in mind. While the CPU
is designed to excel at executing a sequence of operations, called a thread,
as fast as possible and can execute a few tens of these threads in parallel,
the GPU is designed to excel at executing many thousands of them in parallel.
GPUs were initially developed for highly-parallel task of graphic processing
and therefore designed such that more transistors are devoted to data processing
rather than data caching and flow control. More transistors dedicated to
data processing is beneficial for highly parallel computations; the GPU can
hide memory access latencies with computation, instead of relying on large data caches
and complex flow control to avoid long memory access latencies,
both of which are expensive in terms of transistors.</p>
<figure class="align-center" id="id3">
<img alt="_images/gpu_vs_cpu.png" src="_images/gpu_vs_cpu.png" />
<figcaption>
<p><span class="caption-text">A comparison of the CPU and GPU architecture.
CPU (left) has complex core structure and pack several cores on a single chip.
GPU cores are very simple in comparison, they also share data and control between each other.
This allows to pack more cores on a single chip, thus achieving very hich compute density.</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>CPU</p></th>
<th class="head"><p>GPU</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>General purpose</p></td>
<td><p>Highly specialized for parallelism</p></td>
</tr>
<tr class="row-odd"><td><p>Good for serial processing</p></td>
<td><p>Good for parallel processing</p></td>
</tr>
<tr class="row-even"><td><p>Great for task parallelism</p></td>
<td><p>Great for data parallelism</p></td>
</tr>
<tr class="row-odd"><td><p>Low latency per thread</p></td>
<td><p>High-throughput</p></td>
</tr>
<tr class="row-even"><td><p>Large area dedicated cache and control</p></td>
<td><p>Hundreds of floating-point execution units</p></td>
</tr>
</tbody>
</table>
</section>
<section id="summary">
<h4>Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>GPUs are highly parallel devices that can execute certain parts of the program in many parallel threads.</p></li>
<li><p>CPU controls the works flow and makes all the allocations and data transfers.</p></li>
<li><p>In order to use the GPU efficiently, one has to split their the problem  in many parts that can run simultaneously.</p></li>
</ul>
</section>
</section>
<section id="python-on-gpu">
<h3>Python on GPU<a class="headerlink" href="#python-on-gpu" title="Link to this heading"></a></h3>
<p>There has been a lot of progress on Pyhton using GPUs, it is still evolving.
There are a couple of options available to work with GPU, but none of them is perfect.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>CUDA is the programming model developed by NVIDIA to work with GPU</p>
</div>
<section id="cupy">
<h4>CuPy<a class="headerlink" href="#cupy" title="Link to this heading"></a></h4>
<p>CuPy is a NumPy/SciPy-compatible data array library used on GPU.
CuPy has a highly compatible interface with NumPy and SciPy, As stated on its official website,
“All you need to do is just replace <em>numpy</em> and <em>scipy</em> with <em>cupy</em> and <em>cupyx.scipy</em> in your Python code.”
If you know NumPy, CuPy is a very easy way to get started on the GPU.</p>
</section>
<section id="cudf">
<h4>cuDF<a class="headerlink" href="#cudf" title="Link to this heading"></a></h4>
<p>RAPIDS is a high level packages collections which implement CUDA functionalities and API with Python bindings.
cuDF belongs to RAPIDS and is the library for manipulating data frames on GPU.
cuDF provides a pandas-like API, so if you are familiar with Pandas, you can accelerate your work
without knowing too much CUDA programming.</p>
</section>
<section id="pycuda">
<h4>PyCUDA<a class="headerlink" href="#pycuda" title="Link to this heading"></a></h4>
<p>PyCUDA is a Python programming environment for CUDA. It allows users to access to NVIDIA’s CUDA API from Python.
PyCUDA is powerful library but only runs on NVIDIA GPUs. Knowledge of CUDA programming is needed.</p>
</section>
<section id="numba">
<h4>Numba<a class="headerlink" href="#numba" title="Link to this heading"></a></h4>
<p>Same as for CPU, Numba allows users to JIT compile Python code to work on GPU as well.
This workshop will focus on Numba only.</p>
</section>
</section>
<section id="numba-for-gpus">
<h3>Numba for GPUs<a class="headerlink" href="#numba-for-gpus" title="Link to this heading"></a></h3>
<section id="terminology">
<h4>Terminology<a class="headerlink" href="#terminology" title="Link to this heading"></a></h4>
<p>Numba supports GPUs from both Nvidia and AMD, but we will use terminology from Nvidia
as examples in the rest of the course.</p>
<p>Several important terms in the topic of GPU programming are listed here:</p>
<ul class="simple">
<li><p><em>host</em>: the CPU</p></li>
<li><p><em>device</em>: the GPU</p></li>
<li><p><em>host memory</em>: the system main memory of the CPU</p></li>
<li><p><em>device memory</em>: GPU onboard memory</p></li>
<li><p><em>kernels</em>: a GPU function launched by the host and executed on the device</p></li>
<li><p><em>device function</em>: a GPU function executed on the device which can only be
called from the device (i.e. from a kernel or another device function)</p></li>
</ul>
<p>Numba supports GPU programming by directly compiling a restricted subset of Python code
into kernels and device functions following the execution model.
Kernels written in Numba appear to have direct access to NumPy arrays.
NumPy arrays are transferred between the CPU and the GPU automatically.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Kernel declaration</p>
<p>A kernel function is a GPU function that is meant to be called from CPU code.
It contains two fundamental characteristics:</p>
<ul class="simple">
<li><p>kernels cannot explicitly return a value; all result data must be
written to an array passed to the function (if computing a scalar,
you will probably pass a one-element array);</p></li>
<li><p>kernels explicitly declare their thread hierarchy when called:
i.e. the number of thread blocks and the number of threads per block
(note that while a kernel is compiled once, it can be called
multiple times with different block sizes or grid sizes).</p></li>
<li><p>Newer GPU devices from NVIDIA support device-side kernel launching;
this feature is called dynamic parallelism but Numba does not support it currently</p></li>
</ul>
</div>
</section>
<section id="ufunc-gufunc-decorator">
<h4>ufunc (gufunc) decorator<a class="headerlink" href="#ufunc-gufunc-decorator" title="Link to this heading"></a></h4>
<p>Using ufuncs (and generalized ufuncs) is the easist way to run on a GPU with Numba,
and it requires minimal understanding of GPU programming. Numba <code class="docutils literal notranslate"><span class="pre">&#64;vectorize</span></code>
will produce a ufunc-like object. This object is a close analog but not fully compatible
with a regular NumPy ufunc. Generating a ufunc for GPU requires the explicit
type signature and  target attribute.</p>
<div class="admonition-demo-numba-ufunc demo admonition" id="demo-0">
<p class="admonition-title">Demo: Numba ufunc</p>
<p>Let’s revisit our example during the episode of optimization.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">python</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">Numba ufunc cpu</button><button aria-controls="panel-0-0-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-2" name="0-2" role="tab" tabindex="-1">Numba ufunc gpu</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">vectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f_numba_cpu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-2" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-2" name="0-2" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">vectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f_numba_gpu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<p>Let’s benchmark</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">python</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">Numba cpu</button><button aria-controls="panel-1-1-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-2" name="1-2" role="tab" tabindex="-1">Numba gpu</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it -r 1
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000000</span><span class="p">):</span>
    <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="c1"># 6.75 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> res=f_numba_cpu(x, x)
<span class="c1"># 734 ms ± 435 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-2" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-2" name="1-2" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> res=f_numba_gpu(x, x)
<span class="c1"># 78.4 ms ± 6.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
</div></div>
</div>
<p>Numba <code class="docutils literal notranslate"><span class="pre">&#64;vectroize</span></code> is limited to scalar arguments in the core function, for multi-dimensional arrays arguments,
<code class="docutils literal notranslate"><span class="pre">&#64;guvectorize</span></code> is used. Consider the following example which does matrix multiplication.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You should never implement such things like matrix multiplication by yourself,
there are plenty of existing libraries available.</p>
</div>
<div class="admonition-demo-numba-gufunc demo admonition" id="demo-1">
<p class="admonition-title">Demo:  Numba gufunc</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">python</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">numba gufunc cpu</button><button aria-controls="panel-2-2-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-2" name="2-2" role="tab" tabindex="-1">numba gufunc gpu</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">matmul_cpu</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span><span class="o">=</span><span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">tmp</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="c1">#@numba.guvectorize([&#39;(float64[:,:], float64[:,:], float64[:,:])&#39;], &#39;(m,l),(l,n)-&gt;(m,n)&#39;, target=&#39;cpu&#39;)</span>
<span class="nd">@numba</span><span class="o">.</span><span class="n">guvectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">void</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:])],</span> <span class="s1">&#39;(m,l),(l,n)-&gt;(m,n)&#39;</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_numba_cpu</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span><span class="o">=</span><span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">tmp</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-2" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-2" name="2-2" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="c1">#@numba.guvectorize([&#39;(float64[:,:], float64[:,:], float64[:,:])&#39;], &#39;(m,l),(l,n)-&gt;(m,n)&#39;, target=&#39;cuda&#39;)</span>
<span class="nd">@numba</span><span class="o">.</span><span class="n">guvectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">void</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:])],</span> <span class="s1">&#39;(m,l),(l,n)-&gt;(m,n)&#39;</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_numba_gpu</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span><span class="o">=</span><span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">tmp</span>
</pre></div>
</div>
</div></div>
<p>benchmark</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">Numba gufunc cpu</button><button aria-controls="panel-3-3-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-1" name="3-1" role="tab" tabindex="-1">Numba gufunc gpu</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> matmul_numba_cpu(A,B,C)
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-1" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-1" name="3-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> matmul_numba_gpu(A,B,C)
</pre></div>
</div>
</div></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Numba automatically did a lot of things for us:</p>
<ul class="simple">
<li><p>Memory was allocated on GPU</p></li>
<li><p>Data was copied from CPU and GPU</p></li>
<li><p>The kernel was configured and launched</p></li>
<li><p>Data was copied back from GPU to CPU</p></li>
</ul>
</div>
<p>Alough it is simple to use ufuncs(gfuncs) to run on GPU, the performance is the price we have to pay.
In addition, not all functions can be written as ufuncs in practice. To have much more flexibility,
one needs to write a kernel on GPU or device function, which requires more understanding of the GPU programming.</p>
</section>
<section id="gpu-programming-model">
<h4>GPU Programming Model<a class="headerlink" href="#gpu-programming-model" title="Link to this heading"></a></h4>
<p>Accelerators are a separate main circuit board with the processor, memory, power management, etc.,
but they can not operate by themselves. They are always part of a system (host) in which
the CPUs run the operating systems and control the programs execution. This is reflected
in the programming model. CPU (host) and GPU (device) codes are mixed. CPU acts as a main processor,
controlling the execution workflow.  The host makes all calls, allocates the memory,
and  handles the memory transfers between CPU and GPU. GPUs run tens of thousands of threads
simultaneously on thousands of cores and does not do much of the data management.
The device code is executed by doing calls to functions (kernels) written specifically
to take advantage of the GPU. The kernel calls are asynchronous, the control is returned
to the host after a kernel calls. All kernels are executed sequentially.</p>
<section id="gpu-autopsy-volta-gpu">
<h5>GPU Autopsy. Volta GPU<a class="headerlink" href="#gpu-autopsy-volta-gpu" title="Link to this heading"></a></h5>
<figure class="align-center" id="id4">
<img alt="_images/volta-architecture.png" src="_images/volta-architecture.png" />
<figcaption>
<p><span class="caption-text">A scheme of NVIDIA Volta GPU.</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>The NVIDIA GPU  architecture is built upon a number of multithreaded Streaming Multiprocessors (SMs),
each SM contains a number of compute units. NVIDIA Volta GPU has 80 SMs.</p>
<p>NVIDIA Volta streaming multiprocessor (SM):</p>
<ul class="simple">
<li><p>64 single precision cores</p></li>
<li><p>32 double precision cores</p></li>
<li><p>64 integer cores</p></li>
<li><p>8 Tensore cores</p></li>
<li><p>128 KB memory block for L1 and shared memory</p>
<ul>
<li><p>0 - 96 KB can be set to user managed shared memory</p></li>
<li><p>The rest is L1</p></li>
</ul>
</li>
<li><p>65536 registers - enables the GPU to run a very large number of threads</p></li>
</ul>
<figure class="align-center" id="id5">
<img alt="_images/volta-sm-architecture.png" src="_images/volta-sm-architecture.png" />
<figcaption>
<p><span class="caption-text">A scheme of NVIDIA Volta streaming multiprocessor.</span><a class="headerlink" href="#id5" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="thread-hierarchy">
<h5>Thread hierarchy<a class="headerlink" href="#thread-hierarchy" title="Link to this heading"></a></h5>
<p>In order to take advantage of the accelerators it is needed to use parallelism.
When a kernel is launched,  tens of thousands of threads are created.
All threads execute the given kernel with each thread executing the same
instructions but on different data (Single Iinstruction Multiple Data
parallel programming model). It is therefore crucial  to know which thread
operates on which array element(s).</p>
<p>In order to know the thread positioning, we need some information about the hierarchy on a software level.
When CPU invokes a kernel, all the threads launched in the given kernel are partitioned/grouped
into the so-called thread blocks and multiple blocks are combined to form a grid.
The thread blocks of the grid are enumerated and distributed to SMs
with available execution capacity. Thread blocks are required to execute independently,
i.e. it must be possible to execute them in any order: in parallel or in series. In other words,
each thread block can be scheduled on any of the available SM within a GPU, in any order,
concurrently or sequentially, so that they can be executed on any number of SMs. Because of the design,
a GPU with more SMs will automatically execute the program in less time than a GPU with fewer SMs.
However, a thread block can not be splitted among the SMs, but in a SM several blocks can be active
at any given moment. As thread blocks terminate, new blocks are launched on the vacated SMs.
Within a thread block, the threads execute concurrently on the same SM, and they can exchange data via
the so called shared memory and can be explicitly synchronized. The blocks can not interact with other blocks.</p>
<figure class="align-center">
<img alt="_images/thread-hierarchy.png" src="_images/thread-hierarchy.png" />
</figure>
<p>Threads can be identified using a one-dimensional, two-dimensional, or three-dimensional
thread index through the buit-in <code class="xref py py-attr docutils literal notranslate"><span class="pre">numba.cuda.threadIdx</span></code> variable,
and this provides a natural way to invoke computation across the elements
in a domain such as a vector, matrix, or volume.  Each block within the grid
can be identified by a one-dimensional, two-dimensional, or three-dimensional
unique index accessible within the kernel through the built-in <code class="xref py py-attr docutils literal notranslate"><span class="pre">numba.cuda.blockIdx</span></code> variable.
The dimension of the thread block is accessible within the kernel through the built-in
<code class="xref py py-attr docutils literal notranslate"><span class="pre">numba.cuda.blockDim</span></code> variable.  The global index of a thread should be
computed from its in-block index, the index of execution block and the block size.
For 1D, it is numba.cuda.threadIdx.x + numba.cuda.blockIdx.x * numba.cuda.blockDim.x.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Compared to an one-dimensional declarations of equivalent sizes,
using multi-dimensional blocks does not change anything to the efficiency
or behaviour of generated code, but can help you write your code in a more natural way.</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">numba.cuda.threadIdx</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">numba.cuda.blockIdx</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">numba.cuda.blockDim</span></code>
are special objects provided by the CUDA backend for the sole purpose of knowing the geometry
of the thread hierarchy and the position of the current thread within that geometry.
These objects can be 1D, 2D or 3D, depending on how the kernel was invoked. To access
the value at each dimension, use the <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code> and <code class="docutils literal notranslate"><span class="pre">z</span></code> attributes of these objects, respectively.</p>
<p>Numba provides simple solution to calculate thread position by calling <code class="xref py py-attr docutils literal notranslate"><span class="pre">numba.cuda.grid(ndim)</span></code>
where <em>ndim</em> is the number of dimensions declared when invoking the kernel.</p>
</div>
<figure class="align-center" id="id6">
<img alt="_images/MappingBlocksToSMs.png" src="_images/MappingBlocksToSMs.png" />
<figcaption>
<p><span class="caption-text">A simple example of the division of threads (green squares) in blocks (cyan rectangles).
The equally-sized blocks contain four threads each. The thread index starts from zero in each block.
Hence the “global” thread index should be computed from the thread index, block index and block size.
This is explained for the thread #3 in block #2 (blue numbers). The thread blocks are mapped to SMs
for execution, with all threads within a block executing on the same device. The number of threads
within one block does not have to be equal to the number of execution units within multiprocessor.
In fact, GPUs can switch between software threads very efficiently, putting threads that
currently wait for the data on hold and releasing the resources for threads that are ready for computations.
For efficient GPU utilization, the number of threads per block has to be couple of factors higher than
the number of computing units on the multiprocessor. Same is true for the number of thread blocks,
which can and should be higher than the number of available multiprocessor in order to
use the GPU computational resources efficiently.</span><a class="headerlink" href="#id6" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>It is important to notice that the total number of threads in a grid is a multiple of the block size.
This is not necessary the case for the problem that we are solving: the length of the vectors
can be non-divisible by selected block size. So we either need to make sure that the threads
with index large than the size of the vector don’t do anything, or add padding to the vectors.
The former is a simple solution, i.e. by adding a condition after the global thread index is computed.</p>
<figure class="align-center" id="id7">
<img alt="_images/BlocksAndThreads2.png" src="_images/BlocksAndThreads2.png" />
<figcaption>
<p><span class="caption-text">The total number of threads that are needed for the execution (N) can often not be
a multiple of the block size and some of the threads will be idling or producing unused data (red blocks).</span><a class="headerlink" href="#id7" title="Link to this image"></a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unless you are really sure that the block size and grid size are a divisor of your array size,
you <strong>must</strong> check boundaries.</p>
</div>
<p>To obtain the best choice of the thread grid is not a simple task, since it depends on
the specific implemented algorithm and GPU computing capability. The total number of threads
is equal to the number of threads per block times the number of blocks per grid.
The number of thread blocks per grid is usually dictated by the size of the data being processed,
and it should be large enough to fully utilize the GPU.</p>
<blockquote>
<div><ul class="simple">
<li><p>start with 20-100 blocks, the number of blocks is usually chosen to be 2x-4x the number of SMs</p></li>
<li><p>the CUDA kernel launch overhead does depend on the number of blocks, so we find it best not to launch with very large number of blocks</p></li>
</ul>
</div></blockquote>
<p>The size of the number of threads per block should be a multiple of 32,
values like 128, 256 or 512 are frequently used</p>
<blockquote>
<div><ul class="simple">
<li><p>it should be lower than 1024 since it determines how many threads share a limited size of the shared memory</p></li>
<li><p>it must be large than the number of available (single precision, double precision or integer operation) cores in a SM to fully occupy the SM</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="data-and-memory-management">
<h4>Data and Memory management<a class="headerlink" href="#data-and-memory-management" title="Link to this heading"></a></h4>
<p>With many cores trying to access the memory simultaneously and with little cache available,
the accelerator can run out of memory very quickly. This makes the data and memory management an essential task on the GPU.</p>
<section id="data-transfer">
<h5>Data transfer<a class="headerlink" href="#data-transfer" title="Link to this heading"></a></h5>
<p>Although Numba could transfer data automatically from/to the device, these data transfers are slow,
sometimes even more than the actual on-device computation.
Therefore explicitly transfering the data is necessary and should be minimised in real applications.</p>
<p>Using numba.cuda functions, one can transfer data from/to device. To transfer data from cpu to gpu,
one could use <code class="docutils literal notranslate"><span class="pre">to_device()</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">d_x</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">d_y</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>the resulting d_x is a <code class="docutils literal notranslate"><span class="pre">DeviceNDArray</span></code>.
To transfer data on the device back to the host, one can use the <code class="docutils literal notranslate"><span class="pre">copy_to_host()</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">d_x</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">h_x</span><span class="p">)</span>
<span class="n">h_y</span> <span class="o">=</span> <span class="n">d_y</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="memory-hierarchy">
<h5>Memory hierarchy<a class="headerlink" href="#memory-hierarchy" title="Link to this heading"></a></h5>
<figure class="align-center">
<img alt="_images/memory-hierarchy.png" src="_images/memory-hierarchy.png" />
</figure>
<p>As shown in the figure,  CUDA threads may access data from different memory spaces
during kernel execution:</p>
<blockquote>
<div><ul class="simple">
<li><p>local memory: Each thread has private local memory.</p></li>
<li><p>shared memory: Each thread block has shared memory visible to all threads of the thread block and with the same lifetime as the block.</p></li>
<li><p>global memory: All threads have access to the same global memory.</p></li>
</ul>
</div></blockquote>
<p>Both local and global memory resides in device memory, so memory accesses have high latency and low bandwidth, i.e. slow access time.
On the other hand, shared memory has much higher bandwidth and much lower latency than local or global memory.
However, only a limited amount of shared memory can be allocated on the device for better performance. One can think it as a manually-managed data cache.</p>
</section>
</section>
<section id="cuda-jit-decorator">
<h4>CUDA JIT decorator<a class="headerlink" href="#cuda-jit-decorator" title="Link to this heading"></a></h4>
<p>CUDA Kernel and device functions are created with the <code class="docutils literal notranslate"><span class="pre">numba.cuda.jit</span></code> decorator on Nvidia GPUs.
We will use Numba function <code class="docutils literal notranslate"><span class="pre">numba.cuda.grid(ndim)</span></code> to calculate the global thread positions.</p>
<div class="admonition-demo-cuda-kernel demo admonition" id="demo-2">
<p class="admonition-title">Demo: CUDA kernel</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-4-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-4-4-0" name="4-0" role="tab" tabindex="0">ufunc gpu</button><button aria-controls="panel-4-4-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-1" name="4-1" role="tab" tabindex="-1">CUDA kernel</button></div><div aria-labelledby="tab-4-4-0" class="sphinx-tabs-panel" id="panel-4-4-0" name="4-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">vectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f_numba_gpu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-1" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-1" name="4-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">math_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span> <span class="c1"># numba.cuda.jit does not return result yet</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">pos</span> <span class="o">&lt;</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span><span class="n">pos</span> <span class="o">&lt;</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">result</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">pos</span><span class="p">],</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">pos</span><span class="p">])</span>
</pre></div>
</div>
</div></div>
<p>benchmark</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-5-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-5-5-0" name="5-0" role="tab" tabindex="0">CUDA kernel</button><button aria-controls="panel-5-5-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-5-5-1" name="5-1" role="tab" tabindex="-1">CUDA kernel without data transfer</button></div><div aria-labelledby="tab-5-5-0" class="sphinx-tabs-panel" id="panel-5-5-0" name="5-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">threadsperblock</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">blockspergrid</span> <span class="o">=</span> <span class="mi">256</span>
<span class="o">%</span><span class="k">timeit</span> math_kernel[threadsperblock, blockspergrid](a, b, c); numba.cuda.synchronize()
<span class="c1"># 103 ms ± 616 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-5-1" class="sphinx-tabs-panel" hidden="true" id="panel-5-5-1" name="5-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10000000</span><span class="p">)</span>
<span class="n">d_a</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">d_b</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">d_c</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="n">threadsperblock</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">blockspergrid</span> <span class="o">=</span> <span class="mi">256</span>
<span class="o">%</span><span class="k">timeit</span> math_kernel[threadsperblock, blockspergrid](d_a, d_b, d_c); numba.cuda.synchronize()
<span class="c1"># 62.3 µs ± 81.2 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)</span>
</pre></div>
</div>
</div></div>
</div>
<div class="admonition-demo-cuda-kernel-matrix-multiplication demo admonition" id="demo-3">
<p class="admonition-title">Demo: CUDA kernel matrix multiplication</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-6-6-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-6-6-0" name="6-0" role="tab" tabindex="0">gufunc gpu</button><button aria-controls="panel-6-6-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-6-6-1" name="6-1" role="tab" tabindex="-1">CUDA kernel</button></div><div aria-labelledby="tab-6-6-0" class="sphinx-tabs-panel" id="panel-6-6-0" name="6-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="c1">#@numba.guvectorize([&#39;(float64[:,:], float64[:,:], float64[:,:])&#39;], &#39;(m,l),(l,n)-&gt;(m,n)&#39;, target=&#39;cuda&#39;)</span>
<span class="nd">@numba</span><span class="o">.</span><span class="n">guvectorize</span><span class="p">([</span><span class="n">numba</span><span class="o">.</span><span class="n">void</span><span class="p">(</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:],</span> <span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">[:,:])],</span> <span class="s1">&#39;(m,l),(l,n)-&gt;(m,n)&#39;</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_numba_gpu</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span><span class="o">=</span><span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">tmp</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-6-6-1" class="sphinx-tabs-panel" hidden="true" id="panel-6-6-1" name="6-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba.cuda</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_kernel</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>


<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_kernel2</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>

    <span class="n">tx</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
    <span class="n">ty</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">y</span>
    <span class="n">bx</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
    <span class="n">by</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">y</span>
    <span class="n">bw</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
    <span class="n">bh</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">y</span>

    <span class="n">i</span> <span class="o">=</span> <span class="n">tx</span> <span class="o">+</span> <span class="n">bx</span> <span class="o">*</span> <span class="n">bw</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">ty</span> <span class="o">+</span> <span class="n">by</span> <span class="o">*</span> <span class="n">bh</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
</pre></div>
</div>
</div></div>
<p>Benchmark:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-7-7-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-7-7-0" name="7-0" role="tab" tabindex="0">NumPy</button><button aria-controls="panel-7-7-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-1" name="7-1" role="tab" tabindex="-1">gufunc gpu</button><button aria-controls="panel-7-7-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-2" name="7-2" role="tab" tabindex="-1">CUDA kernel</button><button aria-controls="panel-7-7-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-7-7-3" name="7-3" role="tab" tabindex="-1">CUDA kernel without data transfer</button></div><div aria-labelledby="tab-7-7-0" class="sphinx-tabs-panel" id="panel-7-7-0" name="7-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    <span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
    <span class="o">%</span><span class="k">timeit</span> C=np.matmul(A,B)
<span class="c1"># 4.65 µs ± 45.9 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-1" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-1" name="7-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>

<span class="c1"># matmul_numba_gpu.max_blocksize = 32 # may need to set it</span>

<span class="o">%</span><span class="k">timeit</span> matmul_numba_gpu(A, B, C)
<span class="c1"># 10.9 ms ± 232 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-2" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-2" name="7-2" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>

<span class="n">TPB</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">threadsperblock</span> <span class="o">=</span> <span class="p">(</span><span class="n">TPB</span><span class="p">,</span> <span class="n">TPB</span><span class="p">)</span>
<span class="n">blockspergrid_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">threadsperblock</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">blockspergrid_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">threadsperblock</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="c1">#blockspergrid = (16,16)</span>

<span class="o">%</span><span class="k">timeit</span> matmul_kernel[blockspergrid, threadsperblock](A, B, C); numba.cuda.synchronize()
<span class="c1"># 914 µs ± 869 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-7-7-3" class="sphinx-tabs-panel" hidden="true" id="panel-7-7-3" name="7-3" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>

<span class="n">d_A</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">d_B</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">d_C</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

<span class="n">TPB</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">threadsperblock</span> <span class="o">=</span> <span class="p">(</span><span class="n">TPB</span><span class="p">,</span> <span class="n">TPB</span><span class="p">)</span>
<span class="n">blockspergrid</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> matmul_kernel[blockspergrid, threadsperblock](d_A, d_B, d_C); numba.cuda.synchronize()
<span class="c1"># 90.9 µs ± 244 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)</span>
</pre></div>
</div>
</div></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">numba.cuda.synchronize()</span></code> is used after the kernel launch to make sure the profiling is correct.</p>
<p>There are times when the gufunc kernel uses too many of a GPU’s resources, which can cause the kernel launch to fail.
The user can explicitly control the maximum size of the thread block by setting the <code class="docutils literal notranslate"><span class="pre">max_blocksize</span></code> attribute on the compiled gufunc object.
e.g. matmul_numba_gpu.max_blocksize = 32</p>
</div>
</section>
</section>
<section id="optimization">
<h3>Optimization<a class="headerlink" href="#optimization" title="Link to this heading"></a></h3>
<p>GPU can be easily misused and which leads to a low performance. One should condiser the following points when programming with GPU:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt>Maximize GPU utilization</dt><dd><ul>
<li><p>input data size to keep GPU busy</p></li>
<li><p>high arithmetic intensity</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Maximize memory throughput</dt><dd><ul>
<li><p>minimizing data transfers between the host and the device</p></li>
<li><p>minimizing redundant data accesses to global memory by using shared memory and cache</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Maximize instruction throughput</dt><dd><ul>
<li><p>Asynchronous execution</p></li>
<li><p>data types: 64bit data types (integer and floating point) have a significant cost when running on GPU compared to 32bit.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<section id="asynchronous-execution">
<h4>Asynchronous execution<a class="headerlink" href="#asynchronous-execution" title="Link to this heading"></a></h4>
<p>Although the evaluation of computation heavy kernels is noticeable quicker on a GPU,
we still have some room for improvement. A typical GPU program that does not explore
the task-based parallelism executed sequentially is shown on the figure below:</p>
<figure class="align-center" id="id8">
<a class="reference internal image-reference" href="_images/ENCCS-OpenACC-CUDA_TaskParallelism_SchemeGPUSequential.png"><img alt="_images/ENCCS-OpenACC-CUDA_TaskParallelism_SchemeGPUSequential.png" src="_images/ENCCS-OpenACC-CUDA_TaskParallelism_SchemeGPUSequential.png" style="width: 189.6px; height: 380.09999999999997px;" />
</a>
<figcaption>
<p><span class="caption-text">All the data transfers and two functions are executed sequentially.</span><a class="headerlink" href="#id8" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>As a result, the execution timeline looks similar to this:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_TimelineGPUSync.png"><img alt="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_TimelineGPUSync.png" src="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_TimelineGPUSync.png" style="width: 211.5px; height: 204.29999999999998px;" />
</a>
</figure>
<p>On a GPU, the host to device copy, kernel evaluation and device to host copy require different resources.
Hence, while the data is being copied, GPU can execute the computational kernel without interfering
with the data copying. To explore the task-based parallelism, we would like to execute the program as below:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/ENCCS-OpenACC-CUDA_TaskParallelism_SchemeGPUParallel.png"><img alt="_images/ENCCS-OpenACC-CUDA_TaskParallelism_SchemeGPUParallel.png" src="_images/ENCCS-OpenACC-CUDA_TaskParallelism_SchemeGPUParallel.png" style="width: 375.0px; height: 225.6px;" />
</a>
</figure>
<p>and the resulting execution timeline looks similar to this:</p>
<figure class="align-center" id="id9">
<a class="reference internal image-reference" href="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_TimelineGPUAsync.png"><img alt="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_TimelineGPUAsync.png" src="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_TimelineGPUAsync.png" style="width: 394.8px; height: 142.2px;" />
</a>
<figcaption>
<p><span class="caption-text">The execution timeline of the asynchronous GPU program. The different tasks will overlap to each other
to a certain extent that they do not interfere with each other.
Note that there are still dependencies between tasks: we can not run the <code class="docutils literal notranslate"><span class="pre">func1(..)</span></code>
before the <code class="docutils literal notranslate"><span class="pre">data1</span></code> is on the GPU and we can not copy the <code class="docutils literal notranslate"><span class="pre">result1</span></code> to the CPU
before the kernel is finished. In order to express such sequential dependencies,
asynchronous executions are used. Tasks that are independent can run simultaneously.</span><a class="headerlink" href="#id9" title="Link to this image"></a></p>
</figcaption>
</figure>
<figure class="align-center" id="id10">
<a class="reference internal image-reference" href="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_SchemeGPUDependency.png"><img alt="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_SchemeGPUDependency.png" src="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_SchemeGPUDependency.png" style="width: 486.49999999999994px; height: 266.7px;" />
</a>
<figcaption>
<p><span class="caption-text">Adding extra dependency between two tasks.</span><a class="headerlink" href="#id10" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Let us look at one step further by adding extra dependency between two tasks. Assume that the <code class="docutils literal notranslate"><span class="pre">func2(..)</span></code>
now needs the result of the <code class="docutils literal notranslate"><span class="pre">func1(..)</span></code> to be evaluated. This is easy to do in the program.</p>
<figure class="align-center" id="id11">
<a class="reference internal image-reference" href="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_TimelineAsyncDependency.png"><img alt="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_TimelineAsyncDependency.png" src="_images/ENCCS-OpenACC-CUDA_TaskParallelism2_TimelineAsyncDependency.png" style="width: 604.8px; height: 166.25px;" />
</a>
<figcaption>
<p><span class="caption-text">Adding extra dependency between two tasks.</span><a class="headerlink" href="#id11" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<div class="admonition-perform-matrix-multiplication-with-single-precision exercise important admonition" id="exercise-0">
<p class="admonition-title">Perform matrix multiplication with single precision</p>
<p>In this exercise, we will compare the performance by using different precisions.
We will run the matrix multiplication CUDA kernel i.e. matmul_kernel using input data with
double and single precisions. Depending on what generation of GPU you are running on,
the performance can be quite different.</p>
<p>One can find more information about different Nvidia GPUs’ throughputs of the arithmetic instructions
<a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#maximize-instruction-throughput">here</a></p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-8-8-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-8-8-0" name="8-0" role="tab" tabindex="0">Interactive mode</button><button aria-controls="panel-8-8-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-8-8-1" name="8-1" role="tab" tabindex="-1">Batch mode</button></div><div aria-labelledby="tab-8-8-0" class="sphinx-tabs-panel" id="panel-8-8-0" name="8-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba.cuda</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_kernel</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>

<span class="c1"># Benchmark</span>

<span class="c1"># first generate double precision input data</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">8192</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>

<span class="c1"># copy them to GPU</span>

<span class="n">d_A</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">d_B</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">d_C</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

<span class="c1"># setup grid and block</span>

<span class="n">threadsperblock</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">blockspergrid</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># benchmark double precision input data</span>

<span class="o">%</span><span class="n">timeit</span> <span class="n">matmul_kernel</span><span class="p">[</span><span class="n">blockspergrid</span><span class="p">,</span> <span class="n">threadsperblock</span><span class="p">](</span><span class="n">d_A</span><span class="p">,</span> <span class="n">d_B</span><span class="p">,</span> <span class="n">d_C</span><span class="p">);</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>

<span class="c1"># then generate single precision input data</span>

<span class="n">d_A32</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">d_B32</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">d_C32</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="c1"># benchmark single precision input data</span>

<span class="o">%</span><span class="n">timeit</span> <span class="n">matmul_kernel</span><span class="p">[</span><span class="n">blockspergrid</span><span class="p">,</span> <span class="n">threadsperblock</span><span class="p">](</span><span class="n">d_A32</span><span class="p">,</span> <span class="n">d_B32</span><span class="p">,</span> <span class="n">d_C32</span><span class="p">);</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-8-8-1" class="sphinx-tabs-panel" hidden="true" id="panel-8-8-1" name="8-1" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba.cuda</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_kernel</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>

<span class="c1"># Benchmark</span>

<span class="c1"># first generate double precision input data</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">8192</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>

<span class="c1"># copy them to GPU</span>

<span class="n">d_A</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">d_B</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">d_C</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

<span class="c1"># setup grid and block</span>

<span class="n">threadsperblock</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">blockspergrid</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># create array to save profiling information</span>
<span class="n">n_loop</span><span class="o">=</span><span class="mi">20</span>
<span class="n">test1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_loop</span><span class="p">)</span>
<span class="n">test2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_loop</span><span class="p">)</span>


<span class="c1"># benchmark double precision input data</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_loop</span><span class="p">):</span>
    <span class="n">t_s</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">matmul_kernel</span><span class="p">[</span><span class="n">blockspergrid</span><span class="p">,</span> <span class="n">threadsperblock</span><span class="p">](</span><span class="n">d_A</span><span class="p">,</span> <span class="n">d_B</span><span class="p">,</span> <span class="n">d_C</span><span class="p">);</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="n">t_e</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">test1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">t_e</span> <span class="o">-</span> <span class="n">t_s</span>

<span class="c1"># then generate single precision input data</span>

<span class="n">d_A32</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">d_B32</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">d_C32</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="c1"># benchmark single precision input data</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_loop</span><span class="p">):</span>
    <span class="n">t_s</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">matmul_kernel</span><span class="p">[</span><span class="n">blockspergrid</span><span class="p">,</span> <span class="n">threadsperblock</span><span class="p">](</span><span class="n">d_A32</span><span class="p">,</span> <span class="n">d_B32</span><span class="p">,</span> <span class="n">d_C32</span><span class="p">);</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="n">t_e</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">test2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">t_e</span> <span class="o">-</span> <span class="n">t_s</span>


<span class="c1"># calculate mean runtime</span>

<span class="n">record</span> <span class="o">=</span> <span class="n">test1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;matmul_kernel dtype64 Runtime&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;average </span><span class="si">{:.5f}</span><span class="s2"> second (except 1st run)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">record</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>

<span class="n">record</span> <span class="o">=</span> <span class="n">test2</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;matmul_kernel dtype32 Runtime&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;average </span><span class="si">{:.5f}</span><span class="s2"> second (except 1st run)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">record</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</pre></div>
</div>
</div></div>
<div class="admonition-test-using-batch-mode solution important dropdown admonition" id="solution-0">
<p class="admonition-title">TEST USING BATCH MODE!!!</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --job-name=&quot;test&quot;</span>
<span class="c1">#SBATCH --time=00:10:00</span>
<span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --gres=gpu:1</span>
<span class="c1">#SBATCH --ntasks-per-core=1</span>
<span class="c1">#SBATCH --ntasks-per-node=1</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>
<span class="c1">#SBATCH --partition=gpu</span>
<span class="c1">#SBATCH --mem=4GB</span>
<span class="c1">#SBATCH --account=d2021-135-users</span>
<span class="c1">#SBATCH --reservation=ENCCS-HPDA-Workshop</span>

module<span class="w"> </span>add<span class="w"> </span>Anaconda3/2020.11
<span class="c1">#conda activate pyhpda</span>
conda<span class="w"> </span>activate<span class="w"> </span>/ceph/hpc/home/euqiamgl/.conda/envs/pyhpda

python<span class="w"> </span><span class="nv">$1</span><span class="w"> </span>&gt;<span class="w"> </span><span class="nv">$1</span>.out

<span class="nb">exit</span><span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Save the solution in a Python script called <code class="docutils literal notranslate"><span class="pre">sbatch_matmul_dtype.py</span></code></p></li>
<li><p>Save the above template file <a class="reference download internal" download="" href="_downloads/c8f50ceaa5b7579d1206d7d8c48bc088/job.sh"><code class="xref download docutils literal notranslate"><span class="pre">job.sh</span></code></a> in the same folder as <code class="docutils literal notranslate"><span class="pre">sbatch_matmul_dtype.py</span></code></p></li>
<li><p>Submit the job by following the instructions below</p></li>
<li><p>The output will be written in <em>sbatch_matmul_dtype.py.out</em></p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>go<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>directory<span class="w"> </span>where<span class="w"> </span>the<span class="w"> </span>files<span class="w"> </span>job.sh<span class="w"> </span>and<span class="w"> </span>sbatch_matmul_dtype.py<span class="w"> </span>are
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>/path/to/somewhere
<span class="gp">$ </span>sbatch<span class="w"> </span>job.sh<span class="w"> </span>sbatch_matmul_dtype.py
</pre></div>
</div>
</div>
</div>
<div class="admonition-perform-matrix-multiplication-with-shared-memory exercise important admonition" id="exercise-1">
<p class="admonition-title">Perform matrix multiplication with shared memory</p>
<p>We will start from one implementation of the square matrix multiplication using shared memory.
This implementation is taken from Numba official document, however there is arguably at least one error in it.
Try to find where the error is and fix it:</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="n">TPB</span> <span class="o">=</span> <span class="mi">16</span>
<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_sm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="c1"># Define an array in the shared memory</span>
    <span class="c1"># The size and type of the arrays must be known at compile time</span>
    <span class="n">sA</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">TPB</span><span class="p">,</span> <span class="n">TPB</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">sB</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">TPB</span><span class="p">,</span> <span class="n">TPB</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">tx</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
    <span class="n">ty</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">y</span>
    <span class="n">bpg</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">gridDim</span><span class="o">.</span><span class="n">x</span>    <span class="c1"># blocks per grid</span>

    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">y</span> <span class="o">&gt;=</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="k">return</span>

    <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bpg</span><span class="p">):</span>
        <span class="n">sA</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">ty</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">TPB</span><span class="p">]</span>
        <span class="n">sB</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">TPB</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
        <span class="c1"># Wait until all threads finish preloading</span>
        <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TPB</span><span class="p">):</span>
            <span class="n">tmp</span> <span class="o">+=</span> <span class="n">sA</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">sB</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span>

        <span class="c1"># Wait until all threads finish computing</span>
        <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>

    <span class="n">C</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
</pre></div>
</div>
<div class="admonition-hint solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Hint</p>
<ul class="simple">
<li><p>data range check: we require neither x nor y is out of range. The <strong>and</strong> should have been an <strong>or</strong>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">numba.cuda.syncthreads()</span></code> in conditional code: __syncthreads() is allowed in conditional code but only if
the conditional evaluates identically across the entire thread block, otherwise the code execution is
likely to hang or produce unintended side effects.</p></li>
</ul>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-2">
<p class="admonition-title">Solution</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="n">TPB</span> <span class="o">=</span> <span class="mi">16</span>
<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">matmul_sm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="c1"># Define an array in the shared memory</span>
    <span class="c1"># The size and type of the arrays must be known at compile time</span>
    <span class="n">sA</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">TPB</span><span class="p">,</span> <span class="n">TPB</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">sB</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">TPB</span><span class="p">,</span> <span class="n">TPB</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numba</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">tx</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
    <span class="n">ty</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">y</span>
    <span class="n">bpg</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">gridDim</span><span class="o">.</span><span class="n">x</span>    <span class="c1"># blocks per grid</span>

    <span class="c1"># Each thread computes one element in the result matrix.</span>
    <span class="c1"># The dot product is chunked into dot products of TPB-long vectors.</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bpg</span><span class="p">):</span>
        <span class="c1"># Preload data into shared memory</span>
        <span class="n">sA</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">sB</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="p">(</span><span class="n">ty</span><span class="o">+</span><span class="n">i</span><span class="o">*</span><span class="n">TPB</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
          <span class="n">sA</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">ty</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">TPB</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="p">(</span><span class="n">tx</span><span class="o">+</span><span class="n">i</span><span class="o">*</span><span class="n">TPB</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
          <span class="n">sB</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">TPB</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>

        <span class="c1"># Wait until all threads finish preloading</span>
        <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>

        <span class="c1"># Computes partial product on the shared memory</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TPB</span><span class="p">):</span>
            <span class="n">tmp</span> <span class="o">+=</span> <span class="n">sA</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">sB</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span>

        <span class="c1"># Wait until all threads finish computing</span>
        <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">C</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
</pre></div>
</div>
</div>
<div class="admonition-benchmark solution important dropdown admonition" id="solution-3">
<p class="admonition-title">Benchmark</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba.cuda</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">8192</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>

<span class="n">d_A</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">d_B</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">d_C</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

<span class="n">threadsperblock</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">blockspergrid</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>

<span class="n">n_loop</span><span class="o">=</span><span class="mi">20</span>
<span class="n">test3</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_loop</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_loop</span><span class="p">):</span>
    <span class="n">t_s</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">matmul_sm</span><span class="p">[</span><span class="n">blockspergrid</span><span class="p">,</span> <span class="n">threadsperblock</span><span class="p">](</span><span class="n">d_A</span><span class="p">,</span> <span class="n">d_B</span><span class="p">,</span> <span class="n">d_C</span><span class="p">);</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="n">t_e</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">test3</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">t_e</span> <span class="o">-</span> <span class="n">t_s</span>


<span class="n">record</span> <span class="o">=</span> <span class="n">test3</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;matmul_sm Runtime&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;average </span><span class="si">{:.5f}</span><span class="s2"> second (except 1st run)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">record</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="admonition-run-this solution important dropdown admonition" id="solution-4">
<p class="admonition-title">RUN THIS!!!</p>
<ul class="simple">
<li><p>Save the solution and add benchmark part as well in a Python script called <code class="docutils literal notranslate"><span class="pre">sbatch_matmul_sm.py</span></code></p></li>
<li><p>Copy or download <a class="reference download internal" download="" href="_downloads/c8f50ceaa5b7579d1206d7d8c48bc088/job.sh"><code class="xref download docutils literal notranslate"><span class="pre">job.sh</span></code></a> to the same folder as <code class="docutils literal notranslate"><span class="pre">sbatch_matmul_sm.py</span></code></p></li>
<li><p>Submit the job by following the instructions below</p></li>
<li><p>The output will be written in <em>sbatch_matmul_sm.py.out</em></p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>go<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>directory<span class="w"> </span>where<span class="w"> </span>job.sh<span class="w"> </span>and<span class="w"> </span>sbatch_matmul_sm.py<span class="w"> </span>are
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>/path/to/somewhere
<span class="gp">$ </span>sbatch<span class="w"> </span>job.sh<span class="w"> </span>sbatch_matmul_sm.py
</pre></div>
</div>
</div>
</div></blockquote>
</div>
<div class="admonition-discrete-laplace-operator exercise important admonition" id="exercise-2">
<p class="admonition-title">Discrete Laplace Operator</p>
<p>In this exercise, we will work with the discrete Laplace operator.
It has a wide applications including numerical analysis, physics problems, image processing and machine learning as well.
Here we consider a simple two-dimensional implementation with finite-difference formula i.e. the five-point stencil, which reads:</p>
<div class="math notranslate nohighlight">
\[u_{out}(i,j) = 0.25*[ u(i-1,j) + u(i+1,j) + u(i,j-1) + u(i,j+1) ]\]</div>
<p>where <span class="math notranslate nohighlight">\(u(i,j)\)</span> refers to the input at location with
integer index <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> within the domain.</p>
<p>You will start with a naive implementation in Python and you should
optimize it to run on both CPU and GPU using what we learned so far.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-9-9-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-9-9-0" name="9-0" role="tab" tabindex="0">The Laplace code</button><button aria-controls="panel-9-9-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-9-9-1" name="9-1" role="tab" tabindex="-1">Benchmark</button></div><div aria-labelledby="tab-9-9-0" class="sphinx-tabs-panel" id="panel-9-9-0" name="9-0" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">lap2d</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span>     
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>             
            <span class="n">unew</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="p">(</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-9-9-1" class="sphinx-tabs-panel" hidden="true" id="panel-9-9-1" name="9-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">M</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">4096</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">unew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> lap2d(u, unew)
</pre></div>
</div>
</div></div>
<div class="admonition-solution solution important dropdown admonition" id="solution-5">
<p class="admonition-title">Solution</p>
<p>Optimization on CPU</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-10-10-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-10-10-0" name="10-0" role="tab" tabindex="0">numpy</button><button aria-controls="panel-10-10-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-10-10-1" name="10-1" role="tab" tabindex="-1">numba gufunc</button><button aria-controls="panel-10-10-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-10-10-2" name="10-2" role="tab" tabindex="-1">numba JIT</button></div><div aria-labelledby="tab-10-10-0" class="sphinx-tabs-panel" id="panel-10-10-0" name="10-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">lap2d_numpy</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">unew</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="mf">0.25</span><span class="o">*</span><span class="p">(</span><span class="n">u</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">u</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">u</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="n">u</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">:])</span>          


<span class="c1"># Benchmark</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">M</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">4096</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">unew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> lap2d_numpy(u, unew)
</pre></div>
</div>
</div><div aria-labelledby="tab-10-10-1" class="sphinx-tabs-panel" hidden="true" id="panel-10-10-1" name="10-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">guvectorize</span><span class="p">([</span><span class="s1">&#39;void(float64[:,:],float64[:,:])&#39;</span><span class="p">],</span><span class="s1">&#39;(m,n)-&gt;(m,n)&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lap2d_numba_gu_cpu</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span>   
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>  
            <span class="n">unew</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="p">(</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>   


<span class="c1"># Benchmark</span>

<span class="n">M</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">4096</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">unew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> lap2d_numba_gu_cpu(u, unew)
</pre></div>
</div>
</div><div aria-labelledby="tab-10-10-2" class="sphinx-tabs-panel" hidden="true" id="panel-10-10-2" name="10-2" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span> 

<span class="nd">@numba</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lap2d_numba_jit_cpu</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span>   
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>             
            <span class="n">unew</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="p">(</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>     


<span class="c1"># Benchmark</span>

<span class="n">M</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">4096</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">unew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> lap2d_numba_jit_cpu(u, unew)
</pre></div>
</div>
</div></div>
<p>Optimization on GPU</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-11-11-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-11-11-0" name="11-0" role="tab" tabindex="0">numba gufunc</button><button aria-controls="panel-11-11-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-11-11-1" name="11-1" role="tab" tabindex="-1">numba CUDA kernel</button><button aria-controls="panel-11-11-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-11-11-2" name="11-2" role="tab" tabindex="-1">RUN THIS!!!</button></div><div aria-labelledby="tab-11-11-0" class="sphinx-tabs-panel" id="panel-11-11-0" name="11-0" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">guvectorize</span><span class="p">([</span><span class="s1">&#39;void(float64[:,:],float64[:,:])&#39;</span><span class="p">],</span><span class="s1">&#39;(m,n)-&gt;(m,n)&#39;</span><span class="p">,</span><span class="n">target</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lap2d_numba_gu_gpu</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span>   
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>  
            <span class="n">unew</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="p">(</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>   


<span class="c1"># Benchmark</span>

<span class="n">M</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">4096</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">unew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> lap2d_numba_gu_gpu(u, unew)
</pre></div>
</div>
</div><div aria-labelledby="tab-11-11-1" class="sphinx-tabs-panel" hidden="true" id="panel-11-11-1" name="11-1" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba.cuda</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lap2d_cuda</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span>     
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;=</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">M</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&gt;=</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span>
        <span class="n">unew</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="p">(</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>   
 

<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lap2d_cuda2</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span>     
    <span class="n">i</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">y</span>

    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;=</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">M</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&gt;=</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span>
        <span class="n">unew</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="p">(</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>


<span class="c1"># Benchmark</span>

<span class="n">M</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">4096</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">unew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> lap2d_cuda[(16,16),(16,16)](u, unew); numba.cuda.synchronize()
</pre></div>
</div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="c1"># Benchmark properly</span>
<span class="o">%%time</span>it 
<span class="n">d_u</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="n">d_unew</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">unew</span><span class="p">)</span>
<span class="n">lap2d_cuda</span><span class="p">[(</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">),(</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">)](</span><span class="n">d_u</span><span class="p">,</span> <span class="n">d_unew</span><span class="p">);</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="n">d_unew</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">unew</span><span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-11-11-2" class="sphinx-tabs-panel" hidden="true" id="panel-11-11-2" name="11-2" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numba.cuda</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="nd">@numba</span><span class="o">.</span><span class="n">guvectorize</span><span class="p">([</span><span class="s1">&#39;void(float64[:,:],float64[:,:])&#39;</span><span class="p">],</span><span class="s1">&#39;(m,n)-&gt;(m,n)&#39;</span><span class="p">,</span><span class="n">target</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lap2d_numba_gu_gpu</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">unew</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="p">(</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>


<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lap2d_cuda</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;=</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">M</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&gt;=</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span>
        <span class="n">unew</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="p">(</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>


<span class="nd">@numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">jit</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lap2d_cuda2</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">):</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">y</span>

    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;=</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">M</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&gt;=</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span>
        <span class="n">unew</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="p">(</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>



<span class="n">M</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">4096</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">unew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>



<span class="n">n_loop</span><span class="o">=</span><span class="mi">20</span>
<span class="n">test1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_loop</span><span class="p">)</span>
<span class="n">test2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_loop</span><span class="p">)</span>
<span class="n">test3</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_loop</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_loop</span><span class="p">):</span>
    <span class="n">t_s</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">lap2d_numba_gu_gpu</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">)</span>
    <span class="n">t_e</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">test1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">t_e</span> <span class="o">-</span> <span class="n">t_s</span>


<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_loop</span><span class="p">):</span>
    <span class="n">t_s</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">lap2d_cuda</span><span class="p">[(</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">),(</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">)](</span><span class="n">u</span><span class="p">,</span> <span class="n">unew</span><span class="p">);</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="n">t_e</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">test2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">t_e</span> <span class="o">-</span> <span class="n">t_s</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_loop</span><span class="p">):</span>
    <span class="n">t_s</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">d_u</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">d_unew</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">unew</span><span class="p">)</span>
    <span class="n">lap2d_cuda</span><span class="p">[(</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">),(</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">)](</span><span class="n">d_u</span><span class="p">,</span> <span class="n">d_unew</span><span class="p">);</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="n">d_unew</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">unew</span><span class="p">)</span>
    <span class="n">t_e</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">test3</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">t_e</span> <span class="o">-</span> <span class="n">t_s</span>



<span class="n">record</span> <span class="o">=</span> <span class="n">test1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Numba gufunc Runtime&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;average </span><span class="si">{:.5f}</span><span class="s2"> second (except 1st run)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">record</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>

<span class="n">record</span> <span class="o">=</span> <span class="n">test2</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Numba CUDA without explicit data transfer Runtime&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;average </span><span class="si">{:.5f}</span><span class="s2"> second (except 1st run)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">record</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>

<span class="n">record</span> <span class="o">=</span> <span class="n">test3</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Numba CUDA with explicit data transfer Runtime&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;average </span><span class="si">{:.5f}</span><span class="s2"> second (except 1st run)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">record</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</pre></div>
</div>
</div></div>
</div>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Numba gufuncs are easy to use on GPU</p></li>
<li><p>Always consider input data size, compute complexity,
host/device data copy and data type when programing with GPU</p></li>
</ul>
</div>
</section>
</section>
<span id="document-parallel-computing_opt"></span><section id="more-on-parallel-computing">
<h2>More on parallel computing<a class="headerlink" href="#more-on-parallel-computing" title="Link to this heading"></a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>on some HPC systems you might need <code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">-n</span> <span class="pre">4</span></code> instead of <code class="docutils literal notranslate"><span class="pre">mpirun</span> <span class="pre">-np</span> <span class="pre">4</span></code>
on Vega, add this module for MPI libraries: <code class="docutils literal notranslate"><span class="pre">ml</span> <span class="pre">add</span> <span class="pre">foss/2020b</span></code></p>
</div>
<div class="admonition-mpi-libraries callout admonition" id="callout-0">
<p class="admonition-title">MPI libraries</p>
<p>A number of available MPI libraries have been developed (<a class="reference external" href="https://www.open-mpi.org/">OpenMPI</a>,
<a class="reference external" href="https://www.mpich.org/">MPICH</a>, <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/mpi-library.html#gs.up6uyn">IntelMPI</a>,
<a class="reference external" href="http://mvapich.cse.ohio-state.edu/">MVAPICH</a>) and HPC centers normally offer one or more of these for users
to compile/run MPI code.</p>
<p>For example, on Vega one can load the GNU compiler suite along with OpenMPI using:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ml<span class="w"> </span>add<span class="w"> </span>foss/2021b
</pre></div>
</div>
</div>
<section id="parallel-workflows-with-snakemake">
<h3>Parallel workflows with Snakemake<a class="headerlink" href="#parallel-workflows-with-snakemake" title="Link to this heading"></a></h3>
<p>Many scientific problems involve complicated workflows with multiple interdependent steps.
If the workflow involves performing the same analysis on many different datasets we can
use the inherent (“embarrassing”) parallelism of the problem and perform these simultaneously.</p>
<p>Let us have a look at a toy example which many of us can hopefully relate to.</p>
<div class="admonition-demo-the-word-count-project demo admonition" id="demo-0">
<p class="admonition-title">Demo: The word-count project</p>
<p>Head over to <a class="reference external" href="https://github.com/enccs/word-count-hpda">https://github.com/enccs/word-count-hpda</a> and clone the repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/word-count-hpda.git
</pre></div>
</div>
<p>This project is about counting words in a given text and print out the 10 most common
words which can be used to test <a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf’s law</a>.
The <code class="docutils literal notranslate"><span class="pre">data</span></code> directory contains 64 public domain books from <a class="reference external" href="https://www.gutenberg.org/">Project Gutenberg</a>
and source files under <code class="docutils literal notranslate"><span class="pre">source</span></code> can be used to count words:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1"># count words in two books</span>
<span class="gp">$ </span>python<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/pg10.txt<span class="w"> </span>processed_data/pg10.dat
<span class="gp">$ </span>python<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/pg65.txt<span class="w"> </span>processed_data/pg65.dat

<span class="gp">$ </span><span class="c1"># print frequency of 10 most frequent words in both books to file</span>
<span class="gp">$ </span>python<span class="w"> </span>source/zipf_test.py<span class="w"> </span><span class="m">10</span><span class="w"> </span>processed_data/pg10.dat<span class="w"> </span>processed_data/pg65.dat<span class="w"> </span>&gt;<span class="w"> </span>results/results.csv
</pre></div>
</div>
<p>This workflow is encoded in the <code class="docutils literal notranslate"><span class="pre">Snakefile</span></code> which can be used to run
through all data files:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1"># run workflow in serial</span>
<span class="gp">$ </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">1</span>
</pre></div>
</div>
<p>The workflow can be visualised in a directed-acyclic graph:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1"># requires dot from Graphviz</span>
<span class="gp">$ </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">1</span><span class="w"> </span>--dag<span class="w"> </span><span class="p">|</span><span class="w"> </span>dot<span class="w"> </span>-Tpng<span class="w">  </span>&gt;<span class="w"> </span>dag.png
</pre></div>
</div>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/dag.png"><img alt="_images/dag.png" src="_images/dag.png" style="width: 474.40000000000003px; height: 200.8px;" />
</a>
</figure>
<p>The workflow can be parallelized to utilize multiple cores:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">  $ </span><span class="c1"># first clear all output</span>
<span class="gp">  $ </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">1</span><span class="w"> </span>--delete-all-output
<span class="gp">  $ </span><span class="c1"># run in parallel on 4 processes</span>
<span class="gp">  $ </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">4</span>

<span class="go">For embarrassingly parallel work one can achieve significant speedup with parallel Snakemake execution.</span>
</pre></div>
</div>
</div>
<p>The Snakefile describes the workflow in declarative style, i.e. we describe
the dependencies but let Snakemake figure out the series of steps to produce
results (targets). This is how the Snakefile looks:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># a list of all the books we are analyzing</span>
<span class="n">DATA</span> <span class="o">=</span> <span class="n">glob_wildcards</span><span class="p">(</span><span class="s1">&#39;data/</span><span class="si">{book}</span><span class="s1">.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">book</span>

<span class="c1"># the default rule</span>
<span class="n">rule</span> <span class="nb">all</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="s1">&#39;results/results.csv&#39;</span>

<span class="c1"># count words in one of our books</span>
<span class="c1"># logfiles from each run are put in .log files&quot;</span>
<span class="n">rule</span> <span class="n">count_words</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">wc</span><span class="o">=</span><span class="s1">&#39;source/wordcount.py&#39;</span><span class="p">,</span>
        <span class="n">book</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{file}</span><span class="s1">.txt&#39;</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.dat&#39;</span>
    <span class="n">log</span><span class="p">:</span> <span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.log&#39;</span>
    <span class="n">shell</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">            python {input.wc} {input.book} {output} &gt;&gt; {log} 2&gt;&amp;1</span>
<span class="sd">        &#39;&#39;&#39;</span>

<span class="c1"># generate results table</span>
<span class="n">rule</span> <span class="n">zipf_test</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">zipf</span><span class="o">=</span><span class="s1">&#39;source/zipf_test.py&#39;</span><span class="p">,</span>
        <span class="n">books</span><span class="o">=</span><span class="n">expand</span><span class="p">(</span><span class="s1">&#39;processed_data/</span><span class="si">{book}</span><span class="s1">.dat&#39;</span><span class="p">,</span> <span class="n">book</span><span class="o">=</span><span class="n">DATA</span><span class="p">)</span>
    <span class="n">params</span><span class="p">:</span>
        <span class="n">nwords</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;results/results.csv&#39;</span>
    <span class="n">shell</span><span class="p">:</span>  <span class="s1">&#39;python </span><span class="si">{input.zipf}</span><span class="s1"> </span><span class="si">{params.nwords}</span><span class="s1"> </span><span class="si">{input.books}</span><span class="s1"> &gt; </span><span class="si">{output}</span><span class="s1">&#39;</span>
</pre></div>
</div>
</section>
<section id="ipyparallel">
<h3>ipyparallel<a class="headerlink" href="#ipyparallel" title="Link to this heading"></a></h3>
<p><a class="reference external" href="https://ipyparallel.readthedocs.io/en/latest/">ipyparallel</a>, also known as IPython Parallel,
is yet another tool for parallel computing in Python. However, it’s more than just parallel Python,
it’s parallel <em>IPython</em>, and this adds interactivity to parallel computing.</p>
<p>The architecture of ipyparallel for parallel and distributed computing abstracts out parallelism in a
general way and this enables many different styles of parallelism, including:</p>
<ul class="simple">
<li><p>Single program, multiple data (SPMD) parallelism</p></li>
<li><p>Multiple program, multiple data (MPMD) parallelism</p></li>
<li><p>Message passing using MPI</p></li>
<li><p>Task farming</p></li>
<li><p>Data parallel</p></li>
<li><p>Combinations of these approaches</p></li>
<li><p>Custom user-defined approaches</p></li>
</ul>
<p>This is similar to Dask which will be covered in a later episode.</p>
<p>Let’s explore how ipyparallel can be used together with MPI.
The following code will initialize an IPython Cluster with 8 MPI engines in one of two ways:</p>
<ul class="simple">
<li><p>Inside a context manager to automatically manage starting and stopping engines.</p></li>
<li><p>In a terminal and connect to it from a Jupyter notebook.</p></li>
</ul>
<p>After initializing the cluster, we create a “broadcast view” to the engines, and finally
use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_sync()</span></code> function to run the <code class="xref py py-meth docutils literal notranslate"><span class="pre">mpi_example()</span></code> function on the engines:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Context manager</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">In terminal with <code class="docutils literal notranslate"><span class="pre">ipcluster</span></code></button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><p>Define function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mpi_example</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>
    <span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Hello World from rank </span><span class="si">{</span><span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">. Total ranks=</span><span class="si">{</span><span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>Start cluster in context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">ipyparallel</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ipp</span>
<span class="c1"># request an MPI cluster with 4 engines</span>
<span class="k">with</span> <span class="n">ipp</span><span class="o">.</span><span class="n">Cluster</span><span class="p">(</span><span class="n">engines</span><span class="o">=</span><span class="s1">&#39;mpi&#39;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="k">as</span> <span class="n">cluster</span><span class="p">:</span>
   <span class="c1"># get a broadcast_view on the cluster which is best suited for MPI style computation</span>
   <span class="n">view</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">broadcast_view</span><span class="p">()</span>
   <span class="c1"># run the mpi_example function on all engines in parallel</span>
   <span class="n">r</span> <span class="o">=</span> <span class="n">view</span><span class="o">.</span><span class="n">apply_sync</span><span class="p">(</span><span class="n">mpi_example</span><span class="p">)</span>

<span class="c1"># Retrieve and print the result from the engines</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><p>Define function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mpi_example</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>
    <span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Hello World from rank </span><span class="si">{</span><span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">. Total ranks=</span><span class="si">{</span><span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>Start engines in terminal:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1"># load module with MPI</span>
<span class="gp">$ </span>ml<span class="w"> </span>add<span class="w"> </span>foss/2021b
<span class="gp">$ </span>ipcluster<span class="w"> </span>start<span class="w"> </span>-n<span class="w"> </span><span class="m">8</span><span class="w"> </span>--engines<span class="o">=</span>MPI
</pre></div>
</div>
<p>Connect from a code cell in Jupyter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">ipyparallel</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ipp</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">ipp</span><span class="o">.</span><span class="n">Client</span><span class="p">()</span>
<span class="c1"># print engine indices</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cluster</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
<span class="n">view</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">broadcast_view</span><span class="p">()</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">view</span><span class="o">.</span><span class="n">apply_sync</span><span class="p">(</span><span class="n">mpi_example</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
</pre></div>
</div>
</div></div>
<p>In an exercise below you can practice using ipyparallel for running an interactive MPI job in Jupyter
for the word-count project.</p>
<div class="admonition-measure-snakemake-parallelisation-efficiency exercise important admonition" id="exercise-0">
<p class="admonition-title">Measure Snakemake parallelisation efficiency</p>
<p>Explore the parallel efficiency of Snakemake for the word-count project.</p>
<p>First clone the repo:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/word-count-hpda.git
</pre></div>
</div>
<p>Run the workflow on one core and time it:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">time</span><span class="w"> </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">1</span>
</pre></div>
</div>
<p>Now compare the execution time when using more processes. How much improvement can be obtained?</p>
<p>The more time-consuming each job in the workflow is, the larger will be the parallel efficiency,
as you will see if you get to the last exercise below!</p>
</div>
<div class="admonition-use-the-mpi-version-of-word-autocorrelation-with-ipyparallel exercise important admonition" id="exercise-1">
<p class="admonition-title">Use the MPI version of word-autocorrelation with ipyparallel</p>
<p>Now try to use the MPI version of the autocorrelation.py script inside Jupyter
using ipyparallel! Of course, you can also use the provided MPI solution above.</p>
<p>Start by creating a new Jupyter notebook <code class="file docutils literal notranslate"><span class="pre">autocorrelation.ipynb</span></code>
in the <code class="file docutils literal notranslate"><span class="pre">word-count-hpda/source/</span></code> directory.</p>
<p>Then start the IPython cluster with e.g. 8 cores in a Jupyter <strong>terminal</strong>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ipcluster<span class="w"> </span>start<span class="w"> </span>-n<span class="w"> </span><span class="m">8</span><span class="w"> </span>--engines<span class="o">=</span>MPI
</pre></div>
</div>
<p>Now create a cluster in Jupyter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">ipyparallel</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ipp</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">ipp</span><span class="o">.</span><span class="n">Client</span><span class="p">()</span>
</pre></div>
</div>
<p>Instead of copying functions from <code class="file docutils literal notranslate"><span class="pre">autocorrelation.py</span></code> to your notebook, you can
import them <em>on each engine</em>. But you may first need to change the current working
directory (CWD) if your Jupyter session was started in the <code class="file docutils literal notranslate"><span class="pre">word-count-hpda/</span></code> directory:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="c1"># create a direct view to be able to change CWD on engines</span>
<span class="n">dview</span> <span class="o">=</span> <span class="n">rc</span><span class="o">.</span><span class="n">direct_view</span><span class="p">()</span>
<span class="c1"># print CWD on each engine</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dview</span><span class="o">.</span><span class="n">apply_sync</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">))</span>
<span class="c1"># set correct CWD, adapt if needed (run %pwd to find full path)</span>
<span class="n">dview</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;/full/path/to/word-count-hpda/source&#39;</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">cluster</span><span class="p">))</span>
</pre></div>
</div>
<p>Now you need to import all needed functions explicitly on the engines:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">view</span><span class="o">.</span><span class="n">sync_imports</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">autocorrelation</span><span class="w"> </span><span class="kn">import</span> <span class="n">preprocess_text</span><span class="p">,</span> <span class="n">setup</span><span class="p">,</span> <span class="n">word_acf</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">autocorrelation</span><span class="w"> </span><span class="kn">import</span> <span class="n">ave_word_acf_gather</span><span class="p">,</span> <span class="n">ave_word_acf_p2p</span><span class="p">,</span> <span class="n">mpi_acf</span>
</pre></div>
</div>
<p>Finally you’re ready to run MPI code on the engines! The following code uses
<code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_sync()</span></code> to run the <code class="xref py py-meth docutils literal notranslate"><span class="pre">mpi_acf()</span></code> function on all engines with given
input arguments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># run the mpi_example function on all engines in parallel</span>
<span class="n">book</span> <span class="o">=</span> <span class="s2">&quot;../data/pg99.txt&quot;</span>
<span class="n">wc_book</span> <span class="o">=</span> <span class="s2">&quot;../processed_data/pg99.dat&quot;</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">view</span><span class="o">.</span><span class="n">apply_sync</span><span class="p">(</span><span class="n">mpi_acf</span><span class="p">,</span> <span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">)</span>

<span class="c1"># Print the result from the engines</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>Tasks:</p>
<ul class="simple">
<li><p>Time the execution of the last code cell by adding <code class="docutils literal notranslate"><span class="pre">%%time</span></code> at the top of the cell.</p></li>
<li><p>Stop the cluster in terminal (CTRL-c), and start a new cluster with a different number
of MPI engines. Time the cell again to explore the parallel efficiency.</p></li>
<li><p>Instead of running through only one data file (book), create a loop to run through
them all.</p></li>
</ul>
</div>
<div class="admonition-extend-the-snakefile exercise important admonition" id="exercise-2">
<p class="admonition-title">Extend the Snakefile</p>
<p>Extend the Snakefile in the word-count repository to compute the autocorrelation function for all
books! If you are running on a cluster you can add e.g. <code class="docutils literal notranslate"><span class="pre">threads:</span> <span class="pre">4</span></code> to the rule and run a parallel
version of the <code class="docutils literal notranslate"><span class="pre">autocorrelation.py</span></code> script that you wrote in an earlier exercise.</p>
<div class="admonition-hints solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Hints</p>
<p>Apart from adding a new rule for computing the autocorrelation functions, you will need to add dependencies
to the top-level <code class="docutils literal notranslate"><span class="pre">all</span></code> rule in order to instruct Snakemake to run your new rule. For instance, you
can replace it with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rule</span> <span class="nb">all</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="s1">&#39;results/results.txt&#39;</span><span class="p">,</span> <span class="n">expand</span><span class="p">(</span><span class="s1">&#39;results/acf_</span><span class="si">{book}</span><span class="s1">.dat&#39;</span><span class="p">,</span> <span class="n">book</span><span class="o">=</span><span class="n">DATA</span><span class="p">)</span>
</pre></div>
</div>
<p>Make sure to name the <code class="docutils literal notranslate"><span class="pre">output</span></code> files accordingly in your new rule.</p>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># a list of all the books we are analyzing</span>
<span class="n">DATA</span> <span class="o">=</span> <span class="n">glob_wildcards</span><span class="p">(</span><span class="s1">&#39;data/</span><span class="si">{book}</span><span class="s1">.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">book</span>

<span class="c1"># the default rule</span>
<span class="n">rule</span> <span class="nb">all</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="s1">&#39;results/results.txt&#39;</span><span class="p">,</span> <span class="n">expand</span><span class="p">(</span><span class="s1">&#39;results/acf_</span><span class="si">{book}</span><span class="s1">.dat&#39;</span><span class="p">,</span> <span class="n">book</span><span class="o">=</span><span class="n">DATA</span><span class="p">)</span>

<span class="c1"># count words in one of our books</span>
<span class="c1"># logfiles from each run are put in .log files&quot;</span>
<span class="n">rule</span> <span class="n">count_words</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">wc</span><span class="o">=</span><span class="s1">&#39;source/wordcount.py&#39;</span><span class="p">,</span>
        <span class="n">book</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{file}</span><span class="s1">.txt&#39;</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.dat&#39;</span>
    <span class="n">log</span><span class="p">:</span> <span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.log&#39;</span>
    <span class="n">shell</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">            python {input.wc} {input.book} {output} &gt;&gt; {log} 2&gt;&amp;1</span>
<span class="sd">        &#39;&#39;&#39;</span>

<span class="n">rule</span> <span class="n">word_acf</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">acf</span><span class="o">=</span><span class="s1">&#39;source/autocorrelation.py&#39;</span><span class="p">,</span>
        <span class="n">book</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{file}</span><span class="s1">.txt&#39;</span><span class="p">,</span>
        <span class="n">wcdata</span><span class="o">=</span><span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.dat&#39;</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;results/acf_</span><span class="si">{file}</span><span class="s1">.dat&#39;</span>
    <span class="n">threads</span><span class="p">:</span> <span class="mi">4</span>
    <span class="n">log</span><span class="p">:</span> <span class="s1">&#39;processed_data/acf_</span><span class="si">{file}</span><span class="s1">.log&#39;</span>    
    <span class="n">shell</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">            python {input.acf} {input.book} {input.wcdata} {output} &gt;&gt; {log} 2&gt;&amp;1</span>
<span class="sd">        &#39;&#39;&#39;</span>


<span class="c1"># generate results table</span>
<span class="n">rule</span> <span class="n">zipf_test</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">zipf</span><span class="o">=</span><span class="s1">&#39;source/zipf_test.py&#39;</span><span class="p">,</span>
        <span class="n">books</span><span class="o">=</span><span class="n">expand</span><span class="p">(</span><span class="s1">&#39;processed_data/</span><span class="si">{book}</span><span class="s1">.dat&#39;</span><span class="p">,</span> <span class="n">book</span><span class="o">=</span><span class="n">DATA</span><span class="p">)</span>
    <span class="n">params</span><span class="p">:</span>
        <span class="n">nwords</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;results/results.txt&#39;</span>
    <span class="n">shell</span><span class="p">:</span>  <span class="s1">&#39;python </span><span class="si">{input.zipf}</span><span class="s1"> </span><span class="si">{params.nwords}</span><span class="s1"> </span><span class="si">{input.books}</span><span class="s1"> &gt; </span><span class="si">{output}</span><span class="s1">&#39;</span>

</pre></div>
</div>
</div>
</div>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-guide"></span><section id="instructor-s-guide">
<h2>Instructor’s guide<a class="headerlink" href="#instructor-s-guide" title="Link to this heading"></a></h2>
<section id="why-teach-this-lesson">
<h3>Why teach this lesson<a class="headerlink" href="#why-teach-this-lesson" title="Link to this heading"></a></h3>
<p>Python has traditionally not been used in high performance computing environments
due to its inherent performance bottlenecks - i.e. being an interpreted language
and having an in-built mechanism (the global interpreter lock) which prohibits many
forms of parallelisation. At the same time, Python is enormously popular across scientific disciplines and
application domains in both academia in industry, and there are by now a number of mature
libraries for accelerating and parallelising Python code. Although better performance
and parallel scalability will invariably be obtained by writing code in traditional HPC
languages (C and Fortran), teaching researchers and engineers to write performant, parallel
and GPU-ported code in a high-level language like Python can save substantial development time,
make HPC resources more accessible to a wider range of researchers, and lead to better
overall utilisation of available HPC computing power.</p>
</section>
<section id="intended-learning-outcomes">
<h3>Intended learning outcomes<a class="headerlink" href="#intended-learning-outcomes" title="Link to this heading"></a></h3>
<p>By the end of a workshop covering this lesson, learners should:</p>
<ul class="simple">
<li><p>Have a good overview of available tools and libraries for improving performance in Python</p></li>
<li><p>Know what libraries are available for efficiently storing, reading and writing large data</p></li>
<li><p>Be comfortable working with NumPy arrays and Pandas dataframes</p></li>
<li><p>Be able to explain why Python code is often slow</p></li>
<li><p>Understand the concept of vectorisation</p></li>
<li><p>Understand the importance of measuring performance and profiling code before optimizing</p></li>
<li><p>Be able to describe the difference between “embarrasing”, shared-memory and distributed-memory parallelism</p></li>
<li><p>Know the basics of parallel workflows, multiprocessing, multithreading and MPI</p></li>
<li><p>Understand pre-compilation and know basic usage of Numba and Cython</p></li>
<li><p>Have a mental model of how Dask achieves parallelism</p></li>
<li><p>Remember key hardware differences between CPUs and GPUs</p></li>
<li><p>Be able to create simple GPU kernels with Numba</p></li>
</ul>
</section>
<section id="schedule-for-3-half-day-workshop">
<h3>Schedule for 3 half-day workshop<a class="headerlink" href="#schedule-for-3-half-day-workshop" title="Link to this heading"></a></h3>
<p><strong>Day 1</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Time</p></th>
<th class="head"><p>Episode</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>09:00 - 09:20</p></td>
<td><p><a class="reference internal" href="#document-motivation"><span class="doc">Motivation</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>09:20 - 10:00</p></td>
<td><p><a class="reference internal" href="#document-scientific-data"><span class="doc">Scientific data</span></a></p></td>
</tr>
<tr class="row-even"><td><p>10:00 - 10:20</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-odd"><td><p>10:20 - 11:00</p></td>
<td><p><a class="reference internal" href="#document-stack"><span class="doc">Efficient array computing</span></a></p></td>
</tr>
<tr class="row-even"><td><p>11:00 - 11:20</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-odd"><td><p>11:20 - 12:00</p></td>
<td><p><a class="reference internal" href="#document-stack"><span class="doc">Efficient array computing</span></a></p></td>
</tr>
</tbody>
</table>
<p><strong>Day 2:</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Time</p></th>
<th class="head"><p>Episode</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>09:00 - 09:40</p></td>
<td><p><a class="reference internal" href="#document-parallel-computing"><span class="doc">Parallel computing</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>09:40 - 09:50</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>09:50 - 10:20</p></td>
<td><p><a class="reference internal" href="#document-parallel-computing"><span class="doc">Parallel computing</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>10:20 - 10:40</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>10:40 - 11:20</p></td>
<td><p><a class="reference internal" href="#document-optimization"><span class="doc">Profiling and optimizing</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>11:20 - 11:30</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>11:30 - 12:00</p></td>
<td><p><a class="reference internal" href="#document-optimization"><span class="doc">Profiling and optimizing</span></a></p></td>
</tr>
</tbody>
</table>
<p><strong>Day 3:</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Time</p></th>
<th class="head"><p>Episode</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>09:00 - 09:40</p></td>
<td><p><a class="reference internal" href="#document-performance-boosting"><span class="doc">Performance boosting</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>09:40 - 09:50</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>09:50 - 10:20</p></td>
<td><p><a class="reference internal" href="#document-performance-boosting"><span class="doc">Performance boosting</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>10:20 - 10:40</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>10:40 - 11:20</p></td>
<td><p><a class="reference internal" href="#document-dask"><span class="doc">Dask for scalable analytics</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>11:20 - 11:30</p></td>
<td><p>Break</p></td>
</tr>
<tr class="row-even"><td><p>11:30 - 12:00</p></td>
<td><p><a class="reference internal" href="#document-dask"><span class="doc">Dask for scalable analytics</span></a></p></td>
</tr>
</tbody>
</table>
</section>
</section>
</div>
<section id="who-is-the-course-for">
<span id="learner-personas"></span><h2>Who is the course for?<a class="headerlink" href="#who-is-the-course-for" title="Link to this heading"></a></h2>
<p>This material is for all researchers and engineers who work with large or small
datasets and who want to learn powerful tools and best practices for writing more
performant, parallelised, robust and reproducible data analysis pipelines.</p>
</section>
<section id="about-the-course">
<h2>About the course<a class="headerlink" href="#about-the-course" title="Link to this heading"></a></h2>
<p>This lesson material is developed by the <a class="reference external" href="https://enccs.se/">EuroCC National Competence Center
Sweden (ENCCS)</a> and taught in ENCCS workshops.
Each lesson episode has clearly defined objectives that will be addressed and
includes multiple exercises along with solutions, and is therefore also useful for
self-learning. The lesson material is licensed under <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">CC-BY-4.0</a> and can be reused in any form
(with appropriate credit) in other courses and workshops.
Instructors who wish to teach this lesson can refer to the <a class="reference internal" href="#document-guide"><span class="doc">Instructor’s guide</span></a> for
practical advice.</p>
</section>
<section id="see-also">
<h2>See also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h2>
<p>Each lesson episode has a “See also” section at the end which lists
recommended further learning material.</p>
</section>
<section id="credits">
<h2>Credits<a class="headerlink" href="#credits" title="Link to this heading"></a></h2>
<p>The lesson file structure and browsing layout is inspired by and derived from
<a class="reference external" href="https://github.com/coderefinery/sphinx-lesson">work</a> by <a class="reference external" href="https://coderefinery.org/">CodeRefinery</a> licensed under the <a class="reference external" href="http://opensource.org/licenses/mit-license.html">MIT license</a>. We have copied and adapted
most of their license text.</p>
<p>Several examples and formulations are inspired by other open source
educational material, in particular:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://aaltoscicomp.github.io/python-for-scicomp/">Python for Scientific Computing</a></p></li>
<li><p><a class="reference external" href="https://aaltoscicomp.github.io/data-analysis-workflows-course/">Data analysis workflows with R and Python</a></p></li>
<li><p><a class="reference external" href="https://github.com/csc-training/hpc-python">Python in High Performance Computing</a></p></li>
<li><p><a class="reference external" href="https://github.com/mynameisfiber/high_performance_python_2e">Code examples from High Performance Python</a></p></li>
<li><p><a class="reference external" href="http://www.hpc-carpentry.org/hpc-python/">HPC Carpentry’s Introduction to High-Performance Computing in Python</a></p></li>
<li><p><a class="reference external" href="https://jakevdp.github.io/PythonDataScienceHandbook/index.html">Python Data Science Handbook</a></p></li>
<li><p><a class="reference external" href="https://earth-env-data-science.github.io/">An Introduction to Earth and Environmental Data Science</a></p></li>
<li><p><a class="reference external" href="https://github.com/vcodreanu/SURFsara-PTC-Python-Parallel-and-GPU-Programming/tree/master/gpu_programming/">Parallel and GPU Programming in Python</a></p></li>
<li><p><a class="reference external" href="https://git.ichec.ie/training/studentresources/hpc-python/march-2021/">Python in HPC</a></p></li>
<li><p><a class="reference external" href="https://gitlab.jsc.fz-juelich.de/sdlbio-courses/hpc-python/">High-performance computing with Python</a></p></li>
<li><p><a class="reference external" href="https://github.com/NBISweden/workshop-advanced-python/">Advanced Python for data science in biology</a></p></li>
<li><p><a class="reference external" href="https://nyu-cds.github.io/python-numba/">Introduction to Numba</a></p></li>
<li><p><a class="reference external" href="https://github.com/wesm/pydata-book/">Python for Data Analysis</a></p></li>
<li><p><a class="reference external" href="https://github.com/ContinuumIO/gtc2017-numba/">GTC2017-numba</a></p></li>
<li><p><a class="reference external" href="https://ipython-books.github.io/">IPython Cookbook</a></p></li>
<li><p><a class="reference external" href="https://scipy-lectures.org/">Scipy Lecture Notes</a></p></li>
<li><p><a class="reference external" href="https://sebastianraschka.com/notebooks/ml-notebooks/">Machine Learning and Data Science Notebooks</a></p></li>
<li><p><a class="reference external" href="https://github.com/elegant-scipy/notebooks/">Elegant SciPy</a></p></li>
<li><p><a class="reference external" href="https://axil.github.io/a-comprehensive-guide-to-numpy-data-types.html">A Comprehensive Guide to NumPy Data Types</a></p></li>
</ul>
<section id="instructional-material">
<h3>Instructional Material<a class="headerlink" href="#instructional-material" title="Link to this heading"></a></h3>
<p>This instructional material is made available under the
<a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution license (CC-BY-4.0)</a>.
The following is a human-readable summary of (and not a substitute for) the
<a class="reference external" href="https://creativecommons.org/licenses/by/4.0/legalcode">full legal text of the CC-BY-4.0 license</a>.
You are free to:</p>
<ul class="simple">
<li><p><strong>share</strong> - copy and redistribute the material in any medium or format</p></li>
<li><p><strong>adapt</strong> - remix, transform, and build upon the material for any purpose,
even commercially.</p></li>
</ul>
<p>The licensor cannot revoke these freedoms as long as you follow these license terms:</p>
<ul class="simple">
<li><p><strong>Attribution</strong> - You must give appropriate credit (mentioning that your work
is derived from work that is Copyright (c) HPDA-Python and individual contributors and, where practical, linking
to <a class="reference external" href="https://enccs.se">https://enccs.se</a>), provide a <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">link to the license</a>, and indicate if changes were
made. You may do so in any reasonable manner, but not in any way that suggests
the licensor endorses you or your use.</p></li>
<li><p><strong>No additional restrictions</strong> - You may not apply legal terms or
technological measures that legally restrict others from doing anything the
license permits.</p></li>
</ul>
<p>With the understanding that:</p>
<ul class="simple">
<li><p>You do not have to comply with the license for elements of the material in
the public domain or where your use is permitted by an applicable exception
or limitation.</p></li>
<li><p>No warranties are given. The license may not give you all of the permissions
necessary for your intended use. For example, other rights such as
publicity, privacy, or moral rights may limit how you use the material.</p></li>
</ul>
</section>
<section id="software">
<h3>Software<a class="headerlink" href="#software" title="Link to this heading"></a></h3>
<p>Except where otherwise noted, the example programs and other software provided
with this repository are made available under the <a class="reference external" href="http://opensource.org/">OSI</a>-approved
<a class="reference external" href="https://opensource.org/licenses/mit-license.html">MIT license</a>.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, ENCCS and individual contributors..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>