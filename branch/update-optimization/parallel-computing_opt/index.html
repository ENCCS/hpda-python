

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Parallel Computing (II) &mdash; HPDA-Python  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_lesson.css?v=e9df6548" />
      <link rel="stylesheet" type="text/css" href="../_static/term_role_formatting.css?v=4194e21c" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_rtd_theme_ext_color_contrast.css?v=8e8ea19f" />
      <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/sphinx_rtd_theme.css?v=3234e928" />
      <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=a5c4661c" />
      <link rel="stylesheet" type="text/css" href="../_static/overrides.css?v=c88db32d" />

  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=187304be"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=35a8b989"></script>
      <script src="../_static/minipres.js?v=a0d29692"></script>
      <script src="../_static/js/hoverxref.js"></script>
      <script src="../_static/js/tooltipster.bundle.min.js"></script>
      <script src="../_static/js/micromodal.min.js"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../_static/tabs.js?v=3030b3cb"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="next" title="Benchmarking, profiling and optimizing (II)" href="../optimization_opt/" />
    <link rel="prev" title="GPU Computing" href="../GPU-computing/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../" class="icon icon-home">
            HPDA-Python
              <img src="../_static/ENCCS.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Preparation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../setup/">Installation and LUMI Access</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../motivation/">Motivation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scientific-data/">Scientific Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stack/">Efficient Array Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel-computing/">Parallel Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/">Benchmarking, profiling and optimizing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance-boosting/">Performance Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dask/">Dask for Scalable Analytics</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Optional material</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../setup-eurohpc/">Installation in EuroHPC Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pandas-extra/">Pandas (II)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GPU-computing/">GPU Computing</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Parallel Computing (II)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#parallel-workflows-with-snakemake">Parallel workflows with Snakemake</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ipyparallel">ipyparallel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../optimization_opt/">Benchmarking, profiling and optimizing (II)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/">Instructor’s Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../">HPDA-Python</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Parallel Computing (II)</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ENCCS/hpda-python/blob/main/content/parallel-computing_opt.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="parallel-computing-ii">
<h1>Parallel Computing (II)<a class="headerlink" href="#parallel-computing-ii" title="Link to this heading"></a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>on some HPC systems you might need <code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">-n</span> <span class="pre">4</span></code> instead of <code class="docutils literal notranslate"><span class="pre">mpirun</span> <span class="pre">-np</span> <span class="pre">4</span></code>
on Vega, add this module for MPI libraries: <code class="docutils literal notranslate"><span class="pre">ml</span> <span class="pre">add</span> <span class="pre">foss/2020b</span></code></p>
</div>
<div class="admonition-mpi-libraries callout admonition" id="callout-0">
<p class="admonition-title">MPI libraries</p>
<p>A number of available MPI libraries have been developed (<a class="reference external" href="https://www.open-mpi.org/">OpenMPI</a>,
<a class="reference external" href="https://www.mpich.org/">MPICH</a>, <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/mpi-library.html#gs.up6uyn">IntelMPI</a>,
<a class="reference external" href="http://mvapich.cse.ohio-state.edu/">MVAPICH</a>) and HPC centers normally offer one or more of these for users
to compile/run MPI code.</p>
<p>For example, on Vega one can load the GNU compiler suite along with OpenMPI using:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ml<span class="w"> </span>add<span class="w"> </span>foss/2021b
</pre></div>
</div>
</div>
<section id="parallel-workflows-with-snakemake">
<h2>Parallel workflows with Snakemake<a class="headerlink" href="#parallel-workflows-with-snakemake" title="Link to this heading"></a></h2>
<p>Many scientific problems involve complicated workflows with multiple interdependent steps.
If the workflow involves performing the same analysis on many different datasets we can
use the inherent (“embarrassing”) parallelism of the problem and perform these simultaneously.</p>
<p>Let us have a look at a toy example which many of us can hopefully relate to.</p>
<div class="admonition-demo-the-word-count-project demo admonition" id="demo-0">
<p class="admonition-title">Demo: The word-count project</p>
<p>Head over to <a class="reference external" href="https://github.com/enccs/word-count-hpda">https://github.com/enccs/word-count-hpda</a> and clone the repository:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/word-count-hpda.git
</pre></div>
</div>
<p>This project is about counting words in a given text and print out the 10 most common
words which can be used to test <a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf’s law</a>.
The <code class="docutils literal notranslate"><span class="pre">data</span></code> directory contains 64 public domain books from <a class="reference external" href="https://www.gutenberg.org/">Project Gutenberg</a>
and source files under <code class="docutils literal notranslate"><span class="pre">source</span></code> can be used to count words:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1"># count words in two books</span>
<span class="gp">$ </span>python<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/pg10.txt<span class="w"> </span>processed_data/pg10.dat
<span class="gp">$ </span>python<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/pg65.txt<span class="w"> </span>processed_data/pg65.dat

<span class="gp">$ </span><span class="c1"># print frequency of 10 most frequent words in both books to file</span>
<span class="gp">$ </span>python<span class="w"> </span>source/zipf_test.py<span class="w"> </span><span class="m">10</span><span class="w"> </span>processed_data/pg10.dat<span class="w"> </span>processed_data/pg65.dat<span class="w"> </span>&gt;<span class="w"> </span>results/results.csv
</pre></div>
</div>
<p>This workflow is encoded in the <code class="docutils literal notranslate"><span class="pre">Snakefile</span></code> which can be used to run
through all data files:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1"># run workflow in serial</span>
<span class="gp">$ </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">1</span>
</pre></div>
</div>
<p>The workflow can be visualised in a directed-acyclic graph:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1"># requires dot from Graphviz</span>
<span class="gp">$ </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">1</span><span class="w"> </span>--dag<span class="w"> </span><span class="p">|</span><span class="w"> </span>dot<span class="w"> </span>-Tpng<span class="w">  </span>&gt;<span class="w"> </span>dag.png
</pre></div>
</div>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/dag.png"><img alt="../_images/dag.png" src="../_images/dag.png" style="width: 474.40000000000003px; height: 200.8px;" />
</a>
</figure>
<p>The workflow can be parallelized to utilize multiple cores:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">  $ </span><span class="c1"># first clear all output</span>
<span class="gp">  $ </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">1</span><span class="w"> </span>--delete-all-output
<span class="gp">  $ </span><span class="c1"># run in parallel on 4 processes</span>
<span class="gp">  $ </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">4</span>

<span class="go">For embarrassingly parallel work one can achieve significant speedup with parallel Snakemake execution.</span>
</pre></div>
</div>
</div>
<p>The Snakefile describes the workflow in declarative style, i.e. we describe
the dependencies but let Snakemake figure out the series of steps to produce
results (targets). This is how the Snakefile looks:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># a list of all the books we are analyzing</span>
<span class="n">DATA</span> <span class="o">=</span> <span class="n">glob_wildcards</span><span class="p">(</span><span class="s1">&#39;data/</span><span class="si">{book}</span><span class="s1">.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">book</span>

<span class="c1"># the default rule</span>
<span class="n">rule</span> <span class="nb">all</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="s1">&#39;results/results.csv&#39;</span>

<span class="c1"># count words in one of our books</span>
<span class="c1"># logfiles from each run are put in .log files&quot;</span>
<span class="n">rule</span> <span class="n">count_words</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">wc</span><span class="o">=</span><span class="s1">&#39;source/wordcount.py&#39;</span><span class="p">,</span>
        <span class="n">book</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{file}</span><span class="s1">.txt&#39;</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.dat&#39;</span>
    <span class="n">log</span><span class="p">:</span> <span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.log&#39;</span>
    <span class="n">shell</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">            python {input.wc} {input.book} {output} &gt;&gt; {log} 2&gt;&amp;1</span>
<span class="sd">        &#39;&#39;&#39;</span>

<span class="c1"># generate results table</span>
<span class="n">rule</span> <span class="n">zipf_test</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">zipf</span><span class="o">=</span><span class="s1">&#39;source/zipf_test.py&#39;</span><span class="p">,</span>
        <span class="n">books</span><span class="o">=</span><span class="n">expand</span><span class="p">(</span><span class="s1">&#39;processed_data/</span><span class="si">{book}</span><span class="s1">.dat&#39;</span><span class="p">,</span> <span class="n">book</span><span class="o">=</span><span class="n">DATA</span><span class="p">)</span>
    <span class="n">params</span><span class="p">:</span>
        <span class="n">nwords</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;results/results.csv&#39;</span>
    <span class="n">shell</span><span class="p">:</span>  <span class="s1">&#39;python </span><span class="si">{input.zipf}</span><span class="s1"> </span><span class="si">{params.nwords}</span><span class="s1"> </span><span class="si">{input.books}</span><span class="s1"> &gt; </span><span class="si">{output}</span><span class="s1">&#39;</span>
</pre></div>
</div>
</section>
<section id="ipyparallel">
<h2>ipyparallel<a class="headerlink" href="#ipyparallel" title="Link to this heading"></a></h2>
<p><a class="reference external" href="https://ipyparallel.readthedocs.io/en/latest/">ipyparallel</a>, also known as IPython Parallel,
is yet another tool for parallel computing in Python. However, it’s more than just parallel Python,
it’s parallel <em>IPython</em>, and this adds interactivity to parallel computing.</p>
<p>The architecture of ipyparallel for parallel and distributed computing abstracts out parallelism in a
general way and this enables many different styles of parallelism, including:</p>
<ul class="simple">
<li><p>Single program, multiple data (SPMD) parallelism</p></li>
<li><p>Multiple program, multiple data (MPMD) parallelism</p></li>
<li><p>Message passing using MPI</p></li>
<li><p>Task farming</p></li>
<li><p>Data parallel</p></li>
<li><p>Combinations of these approaches</p></li>
<li><p>Custom user-defined approaches</p></li>
</ul>
<p>This is similar to Dask which will be covered in a later episode.</p>
<p>Let’s explore how ipyparallel can be used together with MPI.
The following code will initialize an IPython Cluster with 8 MPI engines in one of two ways:</p>
<ul class="simple">
<li><p>Inside a context manager to automatically manage starting and stopping engines.</p></li>
<li><p>In a terminal and connect to it from a Jupyter notebook.</p></li>
</ul>
<p>After initializing the cluster, we create a “broadcast view” to the engines, and finally
use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_sync()</span></code> function to run the <code class="xref py py-meth docutils literal notranslate"><span class="pre">mpi_example()</span></code> function on the engines:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Context manager</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">In terminal with <code class="docutils literal notranslate"><span class="pre">ipcluster</span></code></button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><p>Define function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mpi_example</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>
    <span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Hello World from rank </span><span class="si">{</span><span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">. Total ranks=</span><span class="si">{</span><span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>Start cluster in context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">ipyparallel</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ipp</span>
<span class="c1"># request an MPI cluster with 4 engines</span>
<span class="k">with</span> <span class="n">ipp</span><span class="o">.</span><span class="n">Cluster</span><span class="p">(</span><span class="n">engines</span><span class="o">=</span><span class="s1">&#39;mpi&#39;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="k">as</span> <span class="n">cluster</span><span class="p">:</span>
   <span class="c1"># get a broadcast_view on the cluster which is best suited for MPI style computation</span>
   <span class="n">view</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">broadcast_view</span><span class="p">()</span>
   <span class="c1"># run the mpi_example function on all engines in parallel</span>
   <span class="n">r</span> <span class="o">=</span> <span class="n">view</span><span class="o">.</span><span class="n">apply_sync</span><span class="p">(</span><span class="n">mpi_example</span><span class="p">)</span>

<span class="c1"># Retrieve and print the result from the engines</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><p>Define function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mpi_example</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>
    <span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Hello World from rank </span><span class="si">{</span><span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">. Total ranks=</span><span class="si">{</span><span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>Start engines in terminal:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="c1"># load module with MPI</span>
<span class="gp">$ </span>ml<span class="w"> </span>add<span class="w"> </span>foss/2021b
<span class="gp">$ </span>ipcluster<span class="w"> </span>start<span class="w"> </span>-n<span class="w"> </span><span class="m">8</span><span class="w"> </span>--engines<span class="o">=</span>MPI
</pre></div>
</div>
<p>Connect from a code cell in Jupyter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">ipyparallel</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ipp</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">ipp</span><span class="o">.</span><span class="n">Client</span><span class="p">()</span>
<span class="c1"># print engine indices</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cluster</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
<span class="n">view</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">broadcast_view</span><span class="p">()</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">view</span><span class="o">.</span><span class="n">apply_sync</span><span class="p">(</span><span class="n">mpi_example</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
</pre></div>
</div>
</div></div>
<p>In an exercise below you can practice using ipyparallel for running an interactive MPI job in Jupyter
for the word-count project.</p>
<div class="admonition-measure-snakemake-parallelisation-efficiency exercise important admonition" id="exercise-0">
<p class="admonition-title">Measure Snakemake parallelisation efficiency</p>
<p>Explore the parallel efficiency of Snakemake for the word-count project.</p>
<p>First clone the repo:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/word-count-hpda.git
</pre></div>
</div>
<p>Run the workflow on one core and time it:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">time</span><span class="w"> </span>snakemake<span class="w"> </span>-j<span class="w"> </span><span class="m">1</span>
</pre></div>
</div>
<p>Now compare the execution time when using more processes. How much improvement can be obtained?</p>
<p>The more time-consuming each job in the workflow is, the larger will be the parallel efficiency,
as you will see if you get to the last exercise below!</p>
</div>
<div class="admonition-use-the-mpi-version-of-word-autocorrelation-with-ipyparallel exercise important admonition" id="exercise-1">
<p class="admonition-title">Use the MPI version of word-autocorrelation with ipyparallel</p>
<p>Now try to use the MPI version of the autocorrelation.py script inside Jupyter
using ipyparallel! Of course, you can also use the provided MPI solution above.</p>
<p>Start by creating a new Jupyter notebook <code class="file docutils literal notranslate"><span class="pre">autocorrelation.ipynb</span></code>
in the <code class="file docutils literal notranslate"><span class="pre">word-count-hpda/source/</span></code> directory.</p>
<p>Then start the IPython cluster with e.g. 8 cores in a Jupyter <strong>terminal</strong>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ipcluster<span class="w"> </span>start<span class="w"> </span>-n<span class="w"> </span><span class="m">8</span><span class="w"> </span>--engines<span class="o">=</span>MPI
</pre></div>
</div>
<p>Now create a cluster in Jupyter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">ipyparallel</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ipp</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">ipp</span><span class="o">.</span><span class="n">Client</span><span class="p">()</span>
</pre></div>
</div>
<p>Instead of copying functions from <code class="file docutils literal notranslate"><span class="pre">autocorrelation.py</span></code> to your notebook, you can
import them <em>on each engine</em>. But you may first need to change the current working
directory (CWD) if your Jupyter session was started in the <code class="file docutils literal notranslate"><span class="pre">word-count-hpda/</span></code> directory:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="c1"># create a direct view to be able to change CWD on engines</span>
<span class="n">dview</span> <span class="o">=</span> <span class="n">rc</span><span class="o">.</span><span class="n">direct_view</span><span class="p">()</span>
<span class="c1"># print CWD on each engine</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dview</span><span class="o">.</span><span class="n">apply_sync</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">))</span>
<span class="c1"># set correct CWD, adapt if needed (run %pwd to find full path)</span>
<span class="n">dview</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;/full/path/to/word-count-hpda/source&#39;</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">cluster</span><span class="p">))</span>
</pre></div>
</div>
<p>Now you need to import all needed functions explicitly on the engines:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">view</span><span class="o">.</span><span class="n">sync_imports</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">autocorrelation</span><span class="w"> </span><span class="kn">import</span> <span class="n">preprocess_text</span><span class="p">,</span> <span class="n">setup</span><span class="p">,</span> <span class="n">word_acf</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">autocorrelation</span><span class="w"> </span><span class="kn">import</span> <span class="n">ave_word_acf_gather</span><span class="p">,</span> <span class="n">ave_word_acf_p2p</span><span class="p">,</span> <span class="n">mpi_acf</span>
</pre></div>
</div>
<p>Finally you’re ready to run MPI code on the engines! The following code uses
<code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_sync()</span></code> to run the <code class="xref py py-meth docutils literal notranslate"><span class="pre">mpi_acf()</span></code> function on all engines with given
input arguments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># run the mpi_example function on all engines in parallel</span>
<span class="n">book</span> <span class="o">=</span> <span class="s2">&quot;../data/pg99.txt&quot;</span>
<span class="n">wc_book</span> <span class="o">=</span> <span class="s2">&quot;../processed_data/pg99.dat&quot;</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">view</span><span class="o">.</span><span class="n">apply_sync</span><span class="p">(</span><span class="n">mpi_acf</span><span class="p">,</span> <span class="n">book</span><span class="p">,</span> <span class="n">wc_book</span><span class="p">)</span>

<span class="c1"># Print the result from the engines</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>Tasks:</p>
<ul class="simple">
<li><p>Time the execution of the last code cell by adding <code class="docutils literal notranslate"><span class="pre">%%time</span></code> at the top of the cell.</p></li>
<li><p>Stop the cluster in terminal (CTRL-c), and start a new cluster with a different number
of MPI engines. Time the cell again to explore the parallel efficiency.</p></li>
<li><p>Instead of running through only one data file (book), create a loop to run through
them all.</p></li>
</ul>
</div>
<div class="admonition-extend-the-snakefile exercise important admonition" id="exercise-2">
<p class="admonition-title">Extend the Snakefile</p>
<p>Extend the Snakefile in the word-count repository to compute the autocorrelation function for all
books! If you are running on a cluster you can add e.g. <code class="docutils literal notranslate"><span class="pre">threads:</span> <span class="pre">4</span></code> to the rule and run a parallel
version of the <code class="docutils literal notranslate"><span class="pre">autocorrelation.py</span></code> script that you wrote in an earlier exercise.</p>
<div class="admonition-hints solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Hints</p>
<p>Apart from adding a new rule for computing the autocorrelation functions, you will need to add dependencies
to the top-level <code class="docutils literal notranslate"><span class="pre">all</span></code> rule in order to instruct Snakemake to run your new rule. For instance, you
can replace it with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rule</span> <span class="nb">all</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="s1">&#39;results/results.txt&#39;</span><span class="p">,</span> <span class="n">expand</span><span class="p">(</span><span class="s1">&#39;results/acf_</span><span class="si">{book}</span><span class="s1">.dat&#39;</span><span class="p">,</span> <span class="n">book</span><span class="o">=</span><span class="n">DATA</span><span class="p">)</span>
</pre></div>
</div>
<p>Make sure to name the <code class="docutils literal notranslate"><span class="pre">output</span></code> files accordingly in your new rule.</p>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># a list of all the books we are analyzing</span>
<span class="n">DATA</span> <span class="o">=</span> <span class="n">glob_wildcards</span><span class="p">(</span><span class="s1">&#39;data/</span><span class="si">{book}</span><span class="s1">.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">book</span>

<span class="c1"># the default rule</span>
<span class="n">rule</span> <span class="nb">all</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="s1">&#39;results/results.txt&#39;</span><span class="p">,</span> <span class="n">expand</span><span class="p">(</span><span class="s1">&#39;results/acf_</span><span class="si">{book}</span><span class="s1">.dat&#39;</span><span class="p">,</span> <span class="n">book</span><span class="o">=</span><span class="n">DATA</span><span class="p">)</span>

<span class="c1"># count words in one of our books</span>
<span class="c1"># logfiles from each run are put in .log files&quot;</span>
<span class="n">rule</span> <span class="n">count_words</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">wc</span><span class="o">=</span><span class="s1">&#39;source/wordcount.py&#39;</span><span class="p">,</span>
        <span class="n">book</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{file}</span><span class="s1">.txt&#39;</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.dat&#39;</span>
    <span class="n">log</span><span class="p">:</span> <span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.log&#39;</span>
    <span class="n">shell</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">            python {input.wc} {input.book} {output} &gt;&gt; {log} 2&gt;&amp;1</span>
<span class="sd">        &#39;&#39;&#39;</span>

<span class="n">rule</span> <span class="n">word_acf</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">acf</span><span class="o">=</span><span class="s1">&#39;source/autocorrelation.py&#39;</span><span class="p">,</span>
        <span class="n">book</span><span class="o">=</span><span class="s1">&#39;data/</span><span class="si">{file}</span><span class="s1">.txt&#39;</span><span class="p">,</span>
        <span class="n">wcdata</span><span class="o">=</span><span class="s1">&#39;processed_data/</span><span class="si">{file}</span><span class="s1">.dat&#39;</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;results/acf_</span><span class="si">{file}</span><span class="s1">.dat&#39;</span>
    <span class="n">threads</span><span class="p">:</span> <span class="mi">4</span>
    <span class="n">log</span><span class="p">:</span> <span class="s1">&#39;processed_data/acf_</span><span class="si">{file}</span><span class="s1">.log&#39;</span>    
    <span class="n">shell</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">            python {input.acf} {input.book} {input.wcdata} {output} &gt;&gt; {log} 2&gt;&amp;1</span>
<span class="sd">        &#39;&#39;&#39;</span>


<span class="c1"># generate results table</span>
<span class="n">rule</span> <span class="n">zipf_test</span><span class="p">:</span>
    <span class="nb">input</span><span class="p">:</span>
        <span class="n">zipf</span><span class="o">=</span><span class="s1">&#39;source/zipf_test.py&#39;</span><span class="p">,</span>
        <span class="n">books</span><span class="o">=</span><span class="n">expand</span><span class="p">(</span><span class="s1">&#39;processed_data/</span><span class="si">{book}</span><span class="s1">.dat&#39;</span><span class="p">,</span> <span class="n">book</span><span class="o">=</span><span class="n">DATA</span><span class="p">)</span>
    <span class="n">params</span><span class="p">:</span>
        <span class="n">nwords</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">output</span><span class="p">:</span> <span class="s1">&#39;results/results.txt&#39;</span>
    <span class="n">shell</span><span class="p">:</span>  <span class="s1">&#39;python </span><span class="si">{input.zipf}</span><span class="s1"> </span><span class="si">{params.nwords}</span><span class="s1"> </span><span class="si">{input.books}</span><span class="s1"> &gt; </span><span class="si">{output}</span><span class="s1">&#39;</span>

</pre></div>
</div>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../GPU-computing/" class="btn btn-neutral float-left" title="GPU Computing" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../optimization_opt/" class="btn btn-neutral float-right" title="Benchmarking, profiling and optimizing (II)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, ENCCS and individual contributors..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>